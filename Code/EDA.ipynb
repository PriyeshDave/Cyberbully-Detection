{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from textblob import TextBlob\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../Datasets/Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Annotation</th>\n",
       "      <th>oh_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.74948705591165E+017</td>\n",
       "      <td>5.74948705591165E+017</td>\n",
       "      <td>@halalflaws @biebervalue @greenlinerzjm I read...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.71917888690393E+017</td>\n",
       "      <td>5.71917888690393E+017</td>\n",
       "      <td>@ShreyaBafna3 Now you idiots claim that people...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.90255841338601E+017</td>\n",
       "      <td>3.90255841338601E+017</td>\n",
       "      <td>RT @Mooseoftorment Call me sexist, but when I ...</td>\n",
       "      <td>sexism</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.68208850655916E+017</td>\n",
       "      <td>5.68208850655916E+017</td>\n",
       "      <td>@g0ssipsquirrelx Wrong, ISIS follows the examp...</td>\n",
       "      <td>racism</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.75596338802373E+017</td>\n",
       "      <td>5.75596338802373E+017</td>\n",
       "      <td>#mkr No No No No No No</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16846</th>\n",
       "      <td>5.75606766236475E+017</td>\n",
       "      <td>5.75606766236475E+017</td>\n",
       "      <td>Feeling so sorry for the girls, they should be...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16847</th>\n",
       "      <td>5.72333822886326E+017</td>\n",
       "      <td>5.72333822886326E+017</td>\n",
       "      <td>#MKR 'pretty good dishes we're happy with' - O...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16848</th>\n",
       "      <td>5.72326950057845E+017</td>\n",
       "      <td>5.72326950057845E+017</td>\n",
       "      <td>RT @colonelkickhead: Deconstructed lemon tart!...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16849</th>\n",
       "      <td>5.74799612642357E+017</td>\n",
       "      <td>5.74799612642357E+017</td>\n",
       "      <td>@versacezaynx @nyazpolitics @greenlinerzjm You...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16850</th>\n",
       "      <td>5.68826121153684E+017</td>\n",
       "      <td>5.68826121153684E+017</td>\n",
       "      <td>And before you protest that you're *not* mad, ...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16851 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       index                     id  \\\n",
       "0      5.74948705591165E+017  5.74948705591165E+017   \n",
       "1      5.71917888690393E+017  5.71917888690393E+017   \n",
       "2      3.90255841338601E+017  3.90255841338601E+017   \n",
       "3      5.68208850655916E+017  5.68208850655916E+017   \n",
       "4      5.75596338802373E+017  5.75596338802373E+017   \n",
       "...                      ...                    ...   \n",
       "16846  5.75606766236475E+017  5.75606766236475E+017   \n",
       "16847  5.72333822886326E+017  5.72333822886326E+017   \n",
       "16848  5.72326950057845E+017  5.72326950057845E+017   \n",
       "16849  5.74799612642357E+017  5.74799612642357E+017   \n",
       "16850  5.68826121153684E+017  5.68826121153684E+017   \n",
       "\n",
       "                                                    Text Annotation  oh_label  \n",
       "0      @halalflaws @biebervalue @greenlinerzjm I read...       none       0.0  \n",
       "1      @ShreyaBafna3 Now you idiots claim that people...       none       0.0  \n",
       "2      RT @Mooseoftorment Call me sexist, but when I ...     sexism       1.0  \n",
       "3      @g0ssipsquirrelx Wrong, ISIS follows the examp...     racism       1.0  \n",
       "4                                 #mkr No No No No No No       none       0.0  \n",
       "...                                                  ...        ...       ...  \n",
       "16846  Feeling so sorry for the girls, they should be...       none       0.0  \n",
       "16847  #MKR 'pretty good dishes we're happy with' - O...       none       0.0  \n",
       "16848  RT @colonelkickhead: Deconstructed lemon tart!...       none       0.0  \n",
       "16849  @versacezaynx @nyazpolitics @greenlinerzjm You...       none       0.0  \n",
       "16850  And before you protest that you're *not* mad, ...       none       0.0  \n",
       "\n",
       "[16851 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    11501\n",
       "1.0     5347\n",
       "Name: oh_label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['oh_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Annotation</th>\n",
       "      <th>oh_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@halalflaws @biebervalue @greenlinerzjm I read...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ShreyaBafna3 Now you idiots claim that people...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @Mooseoftorment Call me sexist, but when I ...</td>\n",
       "      <td>sexism</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@g0ssipsquirrelx Wrong, ISIS follows the examp...</td>\n",
       "      <td>racism</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#mkr No No No No No No</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16846</th>\n",
       "      <td>Feeling so sorry for the girls, they should be...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16847</th>\n",
       "      <td>#MKR 'pretty good dishes we're happy with' - O...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16848</th>\n",
       "      <td>RT @colonelkickhead: Deconstructed lemon tart!...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16849</th>\n",
       "      <td>@versacezaynx @nyazpolitics @greenlinerzjm You...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16850</th>\n",
       "      <td>And before you protest that you're *not* mad, ...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16851 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text Annotation  oh_label\n",
       "0      @halalflaws @biebervalue @greenlinerzjm I read...       none       0.0\n",
       "1      @ShreyaBafna3 Now you idiots claim that people...       none       0.0\n",
       "2      RT @Mooseoftorment Call me sexist, but when I ...     sexism       1.0\n",
       "3      @g0ssipsquirrelx Wrong, ISIS follows the examp...     racism       1.0\n",
       "4                                 #mkr No No No No No No       none       0.0\n",
       "...                                                  ...        ...       ...\n",
       "16846  Feeling so sorry for the girls, they should be...       none       0.0\n",
       "16847  #MKR 'pretty good dishes we're happy with' - O...       none       0.0\n",
       "16848  RT @colonelkickhead: Deconstructed lemon tart!...       none       0.0\n",
       "16849  @versacezaynx @nyazpolitics @greenlinerzjm You...       none       0.0\n",
       "16850  And before you protest that you're *not* mad, ...       none       0.0\n",
       "\n",
       "[16851 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset[['Text','Annotation', 'oh_label']]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "none      11501\n",
       "sexism     3377\n",
       "racism     1970\n",
       "Name: Annotation, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Annotation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Priyesh Dave\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:4901: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "dataset.drop('Annotation', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text        1\n",
       "oh_label    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Priyesh Dave\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>oh_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@halalflaws @biebervalue @greenlinerzjm I read...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ShreyaBafna3 Now you idiots claim that people...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @Mooseoftorment Call me sexist, but when I ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@g0ssipsquirrelx Wrong, ISIS follows the examp...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#mkr No No No No No No</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  oh_label\n",
       "0  @halalflaws @biebervalue @greenlinerzjm I read...       0.0\n",
       "1  @ShreyaBafna3 Now you idiots claim that people...       0.0\n",
       "2  RT @Mooseoftorment Call me sexist, but when I ...       1.0\n",
       "3  @g0ssipsquirrelx Wrong, ISIS follows the examp...       1.0\n",
       "4                             #mkr No No No No No No       0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@halalflaws @biebervalue @greenlinerzjm I read them in context.No change in meaning. The history of Islamic slavery. https://t.co/xWJzpSodGj'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.loc[0]['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeTags(sentence):\n",
    "  return ' '.join([word for word in sentence.split(' ') if not word.__contains__('@')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanData(sentence):\n",
    "  sentence = str(sentence)\n",
    "  sentence = sentence.lower()\n",
    "\n",
    "  # Removing @tags from sentences\n",
    "  sentence = removeTags(sentence)\n",
    "\n",
    "  # Removing twitter handles urls\n",
    "  sentence = ' '.join([word if not word.__contains__('https:') else '' for word in sentence.split(' ')])\n",
    "\n",
    "  # Removing twitter handles urls\n",
    "  sentence = ' '.join([word if not word.__contains__('http:') else '' for word in sentence.split(' ')])\n",
    "\n",
    "  # Removing #MKR from tweets\n",
    "  sentence = ' '.join([word if not word.__contains__('#mkr') else '' for word in sentence.split(' ')])\n",
    "\n",
    "  # Removing stopwords and lemmatizing \n",
    "  sentence = ' '.join([lm.lemmatize(word) for word in sentence.split(' ') if not word in sw])\n",
    "  \n",
    "  #Removing special characters\n",
    "  sentence = re.sub(\"[^a-z ]\", \" \", sentence)\n",
    "\n",
    "  # Removing single characters\n",
    "  sentence = ' '.join([word if not len(word) == 1 else '' for word in sentence.split(' ')])\n",
    "\n",
    "  # Removing extra spaces\n",
    "  sentence = re.sub(\" +\", \" \", sentence)\n",
    "\n",
    "  return sentence.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Models/Lemmatizer.pkl']"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(lm, '../Models/Lemmatizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Priyesh Dave\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n"
     ]
    }
   ],
   "source": [
    "dataset['Cleaned Text'] = dataset['Text'].apply(cleanData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>oh_label</th>\n",
       "      <th>Cleaned Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@halalflaws @biebervalue @greenlinerzjm I read...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>read context no change meaning history islamic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ShreyaBafna3 Now you idiots claim that people...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>idiot claim people tried stop becoming terrori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @Mooseoftorment Call me sexist, but when I ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rt call sexist go auto place rather talk guy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@g0ssipsquirrelx Wrong, ISIS follows the examp...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>wrong isi follows example mohammed quran exactly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#mkr No No No No No No</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16846</th>\n",
       "      <td>Feeling so sorry for the girls, they should be...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>feeling sorry girls safe kat andre going home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16847</th>\n",
       "      <td>#MKR 'pretty good dishes we're happy with' - O...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pretty good dish we re happy with ok well neve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16848</th>\n",
       "      <td>RT @colonelkickhead: Deconstructed lemon tart!...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rt deconstructed lemon tart can please go one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16849</th>\n",
       "      <td>@versacezaynx @nyazpolitics @greenlinerzjm You...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stupid talk to blocked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16850</th>\n",
       "      <td>And before you protest that you're *not* mad, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>protest not mad there much reason tweeting wom...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16848 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  oh_label  \\\n",
       "0      @halalflaws @biebervalue @greenlinerzjm I read...       0.0   \n",
       "1      @ShreyaBafna3 Now you idiots claim that people...       0.0   \n",
       "2      RT @Mooseoftorment Call me sexist, but when I ...       1.0   \n",
       "3      @g0ssipsquirrelx Wrong, ISIS follows the examp...       1.0   \n",
       "4                                 #mkr No No No No No No       0.0   \n",
       "...                                                  ...       ...   \n",
       "16846  Feeling so sorry for the girls, they should be...       0.0   \n",
       "16847  #MKR 'pretty good dishes we're happy with' - O...       0.0   \n",
       "16848  RT @colonelkickhead: Deconstructed lemon tart!...       0.0   \n",
       "16849  @versacezaynx @nyazpolitics @greenlinerzjm You...       0.0   \n",
       "16850  And before you protest that you're *not* mad, ...       0.0   \n",
       "\n",
       "                                            Cleaned Text  \n",
       "0      read context no change meaning history islamic...  \n",
       "1      idiot claim people tried stop becoming terrori...  \n",
       "2           rt call sexist go auto place rather talk guy  \n",
       "3       wrong isi follows example mohammed quran exactly  \n",
       "4                                                         \n",
       "...                                                  ...  \n",
       "16846      feeling sorry girls safe kat andre going home  \n",
       "16847  pretty good dish we re happy with ok well neve...  \n",
       "16848  rt deconstructed lemon tart can please go one ...  \n",
       "16849                             stupid talk to blocked  \n",
       "16850  protest not mad there much reason tweeting wom...  \n",
       "\n",
       "[16848 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text            0\n",
       "oh_label        0\n",
       "Cleaned Text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get length of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Priyesh Dave\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n"
     ]
    }
   ],
   "source": [
    "dataset['Length'] = [len(sentence) for sentence in dataset['Cleaned Text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>oh_label</th>\n",
       "      <th>Cleaned Text</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@halalflaws @biebervalue @greenlinerzjm I read...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>read context no change meaning history islamic...</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ShreyaBafna3 Now you idiots claim that people...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>idiot claim people tried stop becoming terrori...</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @Mooseoftorment Call me sexist, but when I ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rt call sexist go auto place rather talk guy</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@g0ssipsquirrelx Wrong, ISIS follows the examp...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>wrong isi follows example mohammed quran exactly</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#mkr No No No No No No</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16846</th>\n",
       "      <td>Feeling so sorry for the girls, they should be...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>feeling sorry girls safe kat andre going home</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16847</th>\n",
       "      <td>#MKR 'pretty good dishes we're happy with' - O...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pretty good dish we re happy with ok well neve...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16848</th>\n",
       "      <td>RT @colonelkickhead: Deconstructed lemon tart!...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rt deconstructed lemon tart can please go one ...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16849</th>\n",
       "      <td>@versacezaynx @nyazpolitics @greenlinerzjm You...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stupid talk to blocked</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16850</th>\n",
       "      <td>And before you protest that you're *not* mad, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>protest not mad there much reason tweeting wom...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16848 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  oh_label  \\\n",
       "0      @halalflaws @biebervalue @greenlinerzjm I read...       0.0   \n",
       "1      @ShreyaBafna3 Now you idiots claim that people...       0.0   \n",
       "2      RT @Mooseoftorment Call me sexist, but when I ...       1.0   \n",
       "3      @g0ssipsquirrelx Wrong, ISIS follows the examp...       1.0   \n",
       "4                                 #mkr No No No No No No       0.0   \n",
       "...                                                  ...       ...   \n",
       "16846  Feeling so sorry for the girls, they should be...       0.0   \n",
       "16847  #MKR 'pretty good dishes we're happy with' - O...       0.0   \n",
       "16848  RT @colonelkickhead: Deconstructed lemon tart!...       0.0   \n",
       "16849  @versacezaynx @nyazpolitics @greenlinerzjm You...       0.0   \n",
       "16850  And before you protest that you're *not* mad, ...       0.0   \n",
       "\n",
       "                                            Cleaned Text  Length  \n",
       "0      read context no change meaning history islamic...      54  \n",
       "1      idiot claim people tried stop becoming terrori...      86  \n",
       "2           rt call sexist go auto place rather talk guy      44  \n",
       "3       wrong isi follows example mohammed quran exactly      48  \n",
       "4                                                              0  \n",
       "...                                                  ...     ...  \n",
       "16846      feeling sorry girls safe kat andre going home      45  \n",
       "16847  pretty good dish we re happy with ok well neve...      60  \n",
       "16848  rt deconstructed lemon tart can please go one ...     100  \n",
       "16849                             stupid talk to blocked      22  \n",
       "16850  protest not mad there much reason tweeting wom...      57  \n",
       "\n",
       "[16848 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>oh_label</th>\n",
       "      <th>Cleaned Text</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#mkr No No No No No No</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>@JillWetzler I ❤️ u</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>@dankmtl @PeaceNotHate_ http://t.co/HxgNJvWoqG</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>@Assiye61 http://t.co/dduX3ZbMtE</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>@98Halima @BilalIGhumman @johnnygjokaj @cdnKha...</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16576</th>\n",
       "      <td>@olaoliv http://t.co/6PmFc7kdYh</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16719</th>\n",
       "      <td>@iAmCaticorn @CherguiaMbark http://t.co/igBq14...</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16771</th>\n",
       "      <td>@ROJNAME_english http://t.co/Ej5MsCentH</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16778</th>\n",
       "      <td>@98Halima @BilalIGhumman @johnnygjokaj @cdnKha...</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16813</th>\n",
       "      <td>@randi_ebooks @desertfox899 what</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>263 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  oh_label  \\\n",
       "4                                 #mkr No No No No No No       0.0   \n",
       "149                                  @JillWetzler I ❤️ u       0.0   \n",
       "179       @dankmtl @PeaceNotHate_ http://t.co/HxgNJvWoqG       0.0   \n",
       "211                     @Assiye61 http://t.co/dduX3ZbMtE       0.0   \n",
       "240    @98Halima @BilalIGhumman @johnnygjokaj @cdnKha...       0.0   \n",
       "...                                                  ...       ...   \n",
       "16576                    @olaoliv http://t.co/6PmFc7kdYh       0.0   \n",
       "16719  @iAmCaticorn @CherguiaMbark http://t.co/igBq14...       0.0   \n",
       "16771            @ROJNAME_english http://t.co/Ej5MsCentH       0.0   \n",
       "16778  @98Halima @BilalIGhumman @johnnygjokaj @cdnKha...       0.0   \n",
       "16813                   @randi_ebooks @desertfox899 what       0.0   \n",
       "\n",
       "      Cleaned Text  Length  \n",
       "4                        0  \n",
       "149                      0  \n",
       "179                      0  \n",
       "211                      0  \n",
       "240                      0  \n",
       "...            ...     ...  \n",
       "16576                    0  \n",
       "16719                    0  \n",
       "16771                    0  \n",
       "16778                    0  \n",
       "16813                    0  \n",
       "\n",
       "[263 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After cleaning the text some cleaned text has no words so will have to remove those records\n",
    "dataset[dataset['Length'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_words_index = dataset[dataset['Length'] == 0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Priyesh Dave\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:4901: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "dataset.drop(zero_words_index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>oh_label</th>\n",
       "      <th>Cleaned Text</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@halalflaws @biebervalue @greenlinerzjm I read...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>read context no change meaning history islamic...</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ShreyaBafna3 Now you idiots claim that people...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>idiot claim people tried stop becoming terrori...</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @Mooseoftorment Call me sexist, but when I ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rt call sexist go auto place rather talk guy</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@g0ssipsquirrelx Wrong, ISIS follows the examp...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>wrong isi follows example mohammed quran exactly</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RT @TRobinsonNewEra: http://t.co/nkkCbpcHEo Sa...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rt saudi preacher raped tortured five year old...</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16846</th>\n",
       "      <td>Feeling so sorry for the girls, they should be...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>feeling sorry girls safe kat andre going home</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16847</th>\n",
       "      <td>#MKR 'pretty good dishes we're happy with' - O...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pretty good dish we re happy with ok well neve...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16848</th>\n",
       "      <td>RT @colonelkickhead: Deconstructed lemon tart!...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rt deconstructed lemon tart can please go one ...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16849</th>\n",
       "      <td>@versacezaynx @nyazpolitics @greenlinerzjm You...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stupid talk to blocked</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16850</th>\n",
       "      <td>And before you protest that you're *not* mad, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>protest not mad there much reason tweeting wom...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16585 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  oh_label  \\\n",
       "0      @halalflaws @biebervalue @greenlinerzjm I read...       0.0   \n",
       "1      @ShreyaBafna3 Now you idiots claim that people...       0.0   \n",
       "2      RT @Mooseoftorment Call me sexist, but when I ...       1.0   \n",
       "3      @g0ssipsquirrelx Wrong, ISIS follows the examp...       1.0   \n",
       "5      RT @TRobinsonNewEra: http://t.co/nkkCbpcHEo Sa...       0.0   \n",
       "...                                                  ...       ...   \n",
       "16846  Feeling so sorry for the girls, they should be...       0.0   \n",
       "16847  #MKR 'pretty good dishes we're happy with' - O...       0.0   \n",
       "16848  RT @colonelkickhead: Deconstructed lemon tart!...       0.0   \n",
       "16849  @versacezaynx @nyazpolitics @greenlinerzjm You...       0.0   \n",
       "16850  And before you protest that you're *not* mad, ...       0.0   \n",
       "\n",
       "                                            Cleaned Text  Length  \n",
       "0      read context no change meaning history islamic...      54  \n",
       "1      idiot claim people tried stop becoming terrori...      86  \n",
       "2           rt call sexist go auto place rather talk guy      44  \n",
       "3       wrong isi follows example mohammed quran exactly      48  \n",
       "5      rt saudi preacher raped tortured five year old...      70  \n",
       "...                                                  ...     ...  \n",
       "16846      feeling sorry girls safe kat andre going home      45  \n",
       "16847  pretty good dish we re happy with ok well neve...      60  \n",
       "16848  rt deconstructed lemon tart can please go one ...     100  \n",
       "16849                             stupid talk to blocked      22  \n",
       "16850  protest not mad there much reason tweeting wom...      57  \n",
       "\n",
       "[16585 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Priyesh Dave\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:4901: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>oh_label</th>\n",
       "      <th>Cleaned Text</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@halalflaws @biebervalue @greenlinerzjm I read...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>read context no change meaning history islamic...</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ShreyaBafna3 Now you idiots claim that people...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>idiot claim people tried stop becoming terrori...</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @Mooseoftorment Call me sexist, but when I ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rt call sexist go auto place rather talk guy</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@g0ssipsquirrelx Wrong, ISIS follows the examp...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>wrong isi follows example mohammed quran exactly</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @TRobinsonNewEra: http://t.co/nkkCbpcHEo Sa...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rt saudi preacher raped tortured five year old...</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16580</th>\n",
       "      <td>Feeling so sorry for the girls, they should be...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>feeling sorry girls safe kat andre going home</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16581</th>\n",
       "      <td>#MKR 'pretty good dishes we're happy with' - O...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pretty good dish we re happy with ok well neve...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16582</th>\n",
       "      <td>RT @colonelkickhead: Deconstructed lemon tart!...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rt deconstructed lemon tart can please go one ...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16583</th>\n",
       "      <td>@versacezaynx @nyazpolitics @greenlinerzjm You...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stupid talk to blocked</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16584</th>\n",
       "      <td>And before you protest that you're *not* mad, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>protest not mad there much reason tweeting wom...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16585 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  oh_label  \\\n",
       "0      @halalflaws @biebervalue @greenlinerzjm I read...       0.0   \n",
       "1      @ShreyaBafna3 Now you idiots claim that people...       0.0   \n",
       "2      RT @Mooseoftorment Call me sexist, but when I ...       1.0   \n",
       "3      @g0ssipsquirrelx Wrong, ISIS follows the examp...       1.0   \n",
       "4      RT @TRobinsonNewEra: http://t.co/nkkCbpcHEo Sa...       0.0   \n",
       "...                                                  ...       ...   \n",
       "16580  Feeling so sorry for the girls, they should be...       0.0   \n",
       "16581  #MKR 'pretty good dishes we're happy with' - O...       0.0   \n",
       "16582  RT @colonelkickhead: Deconstructed lemon tart!...       0.0   \n",
       "16583  @versacezaynx @nyazpolitics @greenlinerzjm You...       0.0   \n",
       "16584  And before you protest that you're *not* mad, ...       0.0   \n",
       "\n",
       "                                            Cleaned Text  Length  \n",
       "0      read context no change meaning history islamic...      54  \n",
       "1      idiot claim people tried stop becoming terrori...      86  \n",
       "2           rt call sexist go auto place rather talk guy      44  \n",
       "3       wrong isi follows example mohammed quran exactly      48  \n",
       "4      rt saudi preacher raped tortured five year old...      70  \n",
       "...                                                  ...     ...  \n",
       "16580      feeling sorry girls safe kat andre going home      45  \n",
       "16581  pretty good dish we re happy with ok well neve...      60  \n",
       "16582  rt deconstructed lemon tart can please go one ...     100  \n",
       "16583                             stupid talk to blocked      22  \n",
       "16584  protest not mad there much reason tweeting wom...      57  \n",
       "\n",
       "[16585 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.reset_index(inplace=True)\n",
    "dataset.drop('index', axis=1, inplace=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordDict = dict()\n",
    "wordsList = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getwordsCount(sentence):\n",
    "  wordsList = sentence.split(' ')\n",
    "  for word in wordsList:\n",
    "    wordDict[word] = wordDict.get(word, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        None\n",
       "1        None\n",
       "2        None\n",
       "3        None\n",
       "4        None\n",
       "         ... \n",
       "16580    None\n",
       "16581    None\n",
       "16582    None\n",
       "16583    None\n",
       "16584    None\n",
       "Name: Cleaned Text, Length: 16585, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Cleaned Text'].apply(getwordsCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedDict = dict(sorted(wordDict.items(), key = lambda x: x[1], reverse=True))\n",
    "#sortedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rt</th>\n",
       "      <td>3683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kat</th>\n",
       "      <td>1103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sexist</th>\n",
       "      <td>1097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woman</th>\n",
       "      <td>992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>islam</th>\n",
       "      <td>924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people</th>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>muslim</th>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get</th>\n",
       "      <td>694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amp</th>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>think</th>\n",
       "      <td>575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>andre</th>\n",
       "      <td>548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would</th>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>girl</th>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>know</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go</th>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>want</th>\n",
       "      <td>454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make</th>\n",
       "      <td>452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>can</th>\n",
       "      <td>448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>really</th>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>men</th>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>say</th>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>see</th>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>going</th>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>look</th>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>need</th>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ve</th>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thing</th>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>even</th>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isi</th>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>call</th>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oh</th>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>never</th>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>way</th>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hate</th>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>still</th>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>well</th>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>women</th>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>back</th>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuck</th>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>re</th>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Count\n",
       "Word         \n",
       "rt       3683\n",
       "kat      1103\n",
       "sexist   1097\n",
       "like     1024\n",
       "woman     992\n",
       "islam     924\n",
       "people    708\n",
       "muslim    701\n",
       "get       694\n",
       "amp       691\n",
       "one       664\n",
       "think     575\n",
       "andre     548\n",
       "it        523\n",
       "would     512\n",
       "girl      504\n",
       "know      500\n",
       "that      496\n",
       "go        468\n",
       "want      454\n",
       "make      452\n",
       "time      452\n",
       "can       448\n",
       "really    400\n",
       "good      399\n",
       "men       384\n",
       "say       373\n",
       "see       365\n",
       "going     358\n",
       "look      358\n",
       "need      352\n",
       "ve        328\n",
       "right     327\n",
       "thing     327\n",
       "even      312\n",
       "isi       308\n",
       "call      303\n",
       "oh        302\n",
       "you       300\n",
       "never     292\n",
       "female    288\n",
       "way       281\n",
       "hate      281\n",
       "still     275\n",
       "well      259\n",
       "no        258\n",
       "women     246\n",
       "back      245\n",
       "fuck      243\n",
       "re        243"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsCount = pd.DataFrame(sortedDict.values(), index=sortedDict.keys(), columns=['Count'])\n",
    "wordsCount.index.name = 'Word'\n",
    "wordsCount.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "Count=%{x}<br>Word=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "h",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": [
          243,
          243,
          245,
          246,
          258,
          259,
          275,
          281,
          281,
          288,
          292,
          300,
          302,
          303,
          308,
          312,
          327,
          327,
          328,
          352,
          358,
          358,
          365,
          373,
          384,
          399,
          400,
          448,
          452,
          452,
          454,
          468,
          496,
          500,
          504,
          512,
          523,
          548,
          575,
          664,
          691,
          694,
          701,
          708,
          924,
          992,
          1024,
          1097,
          1103,
          3683
         ],
         "xaxis": "x",
         "y": [
          "re",
          "fuck",
          "back",
          "women",
          "no",
          "well",
          "still",
          "hate",
          "way",
          "female",
          "never",
          "you",
          "oh",
          "call",
          "isi",
          "even",
          "thing",
          "right",
          "ve",
          "need",
          "look",
          "going",
          "see",
          "say",
          "men",
          "good",
          "really",
          "can",
          "time",
          "make",
          "want",
          "go",
          "that",
          "know",
          "girl",
          "would",
          "it",
          "andre",
          "think",
          "one",
          "amp",
          "get",
          "muslim",
          "people",
          "islam",
          "woman",
          "like",
          "sexist",
          "kat",
          "rt"
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "height": 1000,
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Most common words"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Count"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Word"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "px.bar(data_frame = wordsCount.head(50).sort_values(by='Count', ascending=True), x='Count', height=1000, title='Most common words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Length of Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x221804ac790>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(dataset['Length'], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>oh_label</th>\n",
       "      <th>Cleaned Text</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@halalflaws @biebervalue @greenlinerzjm I read...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>read context no change meaning history islamic...</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ShreyaBafna3 Now you idiots claim that people...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>idiot claim people tried stop becoming terrori...</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @Mooseoftorment Call me sexist, but when I ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rt call sexist go auto place rather talk guy</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@g0ssipsquirrelx Wrong, ISIS follows the examp...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>wrong isi follows example mohammed quran exactly</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @TRobinsonNewEra: http://t.co/nkkCbpcHEo Sa...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rt saudi preacher raped tortured five year old...</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16580</th>\n",
       "      <td>Feeling so sorry for the girls, they should be...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>feeling sorry girls safe kat andre going home</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16581</th>\n",
       "      <td>#MKR 'pretty good dishes we're happy with' - O...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pretty good dish we re happy with ok well neve...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16582</th>\n",
       "      <td>RT @colonelkickhead: Deconstructed lemon tart!...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rt deconstructed lemon tart can please go one ...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16583</th>\n",
       "      <td>@versacezaynx @nyazpolitics @greenlinerzjm You...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stupid talk to blocked</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16584</th>\n",
       "      <td>And before you protest that you're *not* mad, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>protest not mad there much reason tweeting wom...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16585 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  oh_label  \\\n",
       "0      @halalflaws @biebervalue @greenlinerzjm I read...       0.0   \n",
       "1      @ShreyaBafna3 Now you idiots claim that people...       0.0   \n",
       "2      RT @Mooseoftorment Call me sexist, but when I ...       1.0   \n",
       "3      @g0ssipsquirrelx Wrong, ISIS follows the examp...       1.0   \n",
       "4      RT @TRobinsonNewEra: http://t.co/nkkCbpcHEo Sa...       0.0   \n",
       "...                                                  ...       ...   \n",
       "16580  Feeling so sorry for the girls, they should be...       0.0   \n",
       "16581  #MKR 'pretty good dishes we're happy with' - O...       0.0   \n",
       "16582  RT @colonelkickhead: Deconstructed lemon tart!...       0.0   \n",
       "16583  @versacezaynx @nyazpolitics @greenlinerzjm You...       0.0   \n",
       "16584  And before you protest that you're *not* mad, ...       0.0   \n",
       "\n",
       "                                            Cleaned Text  Length  \n",
       "0      read context no change meaning history islamic...      54  \n",
       "1      idiot claim people tried stop becoming terrori...      86  \n",
       "2           rt call sexist go auto place rather talk guy      44  \n",
       "3       wrong isi follows example mohammed quran exactly      48  \n",
       "4      rt saudi preacher raped tortured five year old...      70  \n",
       "...                                                  ...     ...  \n",
       "16580      feeling sorry girls safe kat andre going home      45  \n",
       "16581  pretty good dish we re happy with ok well neve...      60  \n",
       "16582  rt deconstructed lemon tart can please go one ...     100  \n",
       "16583                             stupid talk to blocked      22  \n",
       "16584  protest not mad there much reason tweeting wom...      57  \n",
       "\n",
       "[16585 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>onscreen</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>definitive</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ruling</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sherry</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cocktail</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frikin</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nina</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gratitude</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ancestor</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wankers</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reallyaone</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>harrypotter</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lookalike</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faruq</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wome</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fava</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aggressor</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>titles</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unborn</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hopped</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enthusiastic</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subconsciously</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>norah</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vincent</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restrict</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unbridled</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>failures</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>philharmonic</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toward</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whitefeminists</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anidifranco</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>donor</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sioa</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unsw</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>potty</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workout</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ceeeeeeeebs</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mcculloch</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indicting</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>darrenwilson</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delaying</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reb</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hoover</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>connections</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumors</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overdramatic</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apocalypse</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>myaunt</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>casters</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yesss</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>protestors</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mn</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shutitdown</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>icantbreathe</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angle</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labours</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pacify</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>having</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mykitchenmistake</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Count\n",
       "Word                   \n",
       "onscreen              1\n",
       "definitive            1\n",
       "ruling                1\n",
       "sherry                1\n",
       "cocktail              1\n",
       "frikin                1\n",
       "nina                  1\n",
       "gratitude             1\n",
       "ancestor              1\n",
       "wankers               1\n",
       "reallyaone            1\n",
       "harrypotter           1\n",
       "lookalike             1\n",
       "faruq                 1\n",
       "wome                  1\n",
       "fava                  1\n",
       "aggressor             1\n",
       "titles                1\n",
       "unborn                1\n",
       "hopped                1\n",
       "enthusiastic          1\n",
       "subconsciously        1\n",
       "norah                 1\n",
       "vincent               1\n",
       "restrict              1\n",
       "unbridled             1\n",
       "failures              1\n",
       "philharmonic          1\n",
       "toward                1\n",
       "whitefeminists        1\n",
       "anidifranco           1\n",
       "donor                 1\n",
       "sioa                  1\n",
       "unsw                  1\n",
       "potty                 1\n",
       "workout               1\n",
       "ceeeeeeeebs           1\n",
       "mcculloch             1\n",
       "indicting             1\n",
       "darrenwilson          1\n",
       "delaying              1\n",
       "reb                   1\n",
       "hoover                1\n",
       "connections           1\n",
       "rumors                1\n",
       "overdramatic          1\n",
       "feat                  1\n",
       "apocalypse            1\n",
       "myaunt                1\n",
       "casters               1\n",
       "yesss                 1\n",
       "protestors            1\n",
       "mn                    1\n",
       "shutitdown            1\n",
       "icantbreathe          1\n",
       "angle                 1\n",
       "labours               1\n",
       "pacify                1\n",
       "having                1\n",
       "mykitchenmistake      1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsCount.tail(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing & Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative_df = dataset[dataset['oh_label'] == 0 ].sample(5300)\n",
    "# positive_df = dataset[dataset['oh_label'] == 1 ].sample(5300)\n",
    "\n",
    "# dataset = pd.concat([negative_df, positive_df], axis=0)\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16585, 15258)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tfidf.fit_transform(dataset['Cleaned Text']).toarray()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve, auc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, dataset['oh_label'], test_size=.33, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    7505\n",
       "1.0    3606\n",
       "Name: oh_label, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    3737\n",
       "1.0    1737\n",
       "Name: oh_label, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Accuracy Score:  0.8515885158851588\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.98      0.90      7505\n",
      "         1.0       0.94      0.58      0.72      3606\n",
      "\n",
      "    accuracy                           0.85     11111\n",
      "   macro avg       0.89      0.78      0.81     11111\n",
      "weighted avg       0.87      0.85      0.84     11111\n",
      "\n",
      "[[7382  123]\n",
      " [1526 2080]]\n",
      "==================================\n",
      "Test\n",
      "Accuracy Score:  0.7849835586408477\n",
      "AUC:  0.6841517298347957\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.96      0.86      3737\n",
      "         1.0       0.83      0.41      0.55      1737\n",
      "\n",
      "    accuracy                           0.78      5474\n",
      "   macro avg       0.80      0.68      0.70      5474\n",
      "weighted avg       0.79      0.78      0.76      5474\n",
      "\n",
      "[[3588  149]\n",
      " [1028  709]]\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'MultinomialNaiveBayes'\n",
    "mnb.fit(X_train, y_train)\n",
    "\n",
    "train_pred = mnb.predict(X_train)\n",
    "test_pred = mnb.predict(X_test)\n",
    "\n",
    "\n",
    "print('Training')\n",
    "print('Accuracy Score: ',accuracy_score(y_train, train_pred))\n",
    "print(classification_report(y_train, train_pred))\n",
    "print(confusion_matrix(y_train, train_pred))\n",
    "\n",
    "print('==================================')\n",
    "\n",
    "print('Test')\n",
    "score = accuracy_score(y_test, test_pred)\n",
    "auc_score = roc_auc_score(y_test, test_pred)\n",
    "print('Accuracy Score: ',score)\n",
    "print('AUC: ', auc_score)\n",
    "print(classification_report(y_test, test_pred))\n",
    "print(confusion_matrix(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Models/MultinomialNaiveBayes_78.5_68.42.pkl']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(mnb, '../Models/{}_{}_{}.pkl'.format(MODEL_NAME, round(score*100, 2), round(auc_score*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding (Word2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>oh_label</th>\n",
       "      <th>Cleaned Text</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@halalflaws @biebervalue @greenlinerzjm I read...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>read context no change meaning history islamic...</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ShreyaBafna3 Now you idiots claim that people...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>idiot claim people tried stop becoming terrori...</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @Mooseoftorment Call me sexist, but when I ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rt call sexist go auto place rather talk guy</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@g0ssipsquirrelx Wrong, ISIS follows the examp...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>wrong isi follows example mohammed quran exactly</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @TRobinsonNewEra: http://t.co/nkkCbpcHEo Sa...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rt saudi preacher raped tortured five year old...</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16580</th>\n",
       "      <td>Feeling so sorry for the girls, they should be...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>feeling sorry girls safe kat andre going home</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16581</th>\n",
       "      <td>#MKR 'pretty good dishes we're happy with' - O...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pretty good dish we re happy with ok well neve...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16582</th>\n",
       "      <td>RT @colonelkickhead: Deconstructed lemon tart!...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rt deconstructed lemon tart can please go one ...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16583</th>\n",
       "      <td>@versacezaynx @nyazpolitics @greenlinerzjm You...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stupid talk to blocked</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16584</th>\n",
       "      <td>And before you protest that you're *not* mad, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>protest not mad there much reason tweeting wom...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16585 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  oh_label  \\\n",
       "0      @halalflaws @biebervalue @greenlinerzjm I read...       0.0   \n",
       "1      @ShreyaBafna3 Now you idiots claim that people...       0.0   \n",
       "2      RT @Mooseoftorment Call me sexist, but when I ...       1.0   \n",
       "3      @g0ssipsquirrelx Wrong, ISIS follows the examp...       1.0   \n",
       "4      RT @TRobinsonNewEra: http://t.co/nkkCbpcHEo Sa...       0.0   \n",
       "...                                                  ...       ...   \n",
       "16580  Feeling so sorry for the girls, they should be...       0.0   \n",
       "16581  #MKR 'pretty good dishes we're happy with' - O...       0.0   \n",
       "16582  RT @colonelkickhead: Deconstructed lemon tart!...       0.0   \n",
       "16583  @versacezaynx @nyazpolitics @greenlinerzjm You...       0.0   \n",
       "16584  And before you protest that you're *not* mad, ...       0.0   \n",
       "\n",
       "                                            Cleaned Text  Length  \n",
       "0      read context no change meaning history islamic...      54  \n",
       "1      idiot claim people tried stop becoming terrori...      86  \n",
       "2           rt call sexist go auto place rather talk guy      44  \n",
       "3       wrong isi follows example mohammed quran exactly      48  \n",
       "4      rt saudi preacher raped tortured five year old...      70  \n",
       "...                                                  ...     ...  \n",
       "16580      feeling sorry girls safe kat andre going home      45  \n",
       "16581  pretty good dish we re happy with ok well neve...      60  \n",
       "16582  rt deconstructed lemon tart can please go one ...     100  \n",
       "16583                             stupid talk to blocked      22  \n",
       "16584  protest not mad there much reason tweeting wom...      57  \n",
       "\n",
       "[16585 rows x 4 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Priyesh Dave\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset['Tokens'] = [simple_preprocess(sentence) for sentence in dataset['Cleaned Text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>oh_label</th>\n",
       "      <th>Cleaned Text</th>\n",
       "      <th>Length</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@halalflaws @biebervalue @greenlinerzjm I read...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>read context no change meaning history islamic...</td>\n",
       "      <td>54</td>\n",
       "      <td>[read, context, no, change, meaning, history, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ShreyaBafna3 Now you idiots claim that people...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>idiot claim people tried stop becoming terrori...</td>\n",
       "      <td>86</td>\n",
       "      <td>[idiot, claim, people, tried, stop, becoming, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @Mooseoftorment Call me sexist, but when I ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rt call sexist go auto place rather talk guy</td>\n",
       "      <td>44</td>\n",
       "      <td>[rt, call, sexist, go, auto, place, rather, ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@g0ssipsquirrelx Wrong, ISIS follows the examp...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>wrong isi follows example mohammed quran exactly</td>\n",
       "      <td>48</td>\n",
       "      <td>[wrong, isi, follows, example, mohammed, quran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @TRobinsonNewEra: http://t.co/nkkCbpcHEo Sa...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rt saudi preacher raped tortured five year old...</td>\n",
       "      <td>70</td>\n",
       "      <td>[rt, saudi, preacher, raped, tortured, five, y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  oh_label  \\\n",
       "0  @halalflaws @biebervalue @greenlinerzjm I read...       0.0   \n",
       "1  @ShreyaBafna3 Now you idiots claim that people...       0.0   \n",
       "2  RT @Mooseoftorment Call me sexist, but when I ...       1.0   \n",
       "3  @g0ssipsquirrelx Wrong, ISIS follows the examp...       1.0   \n",
       "4  RT @TRobinsonNewEra: http://t.co/nkkCbpcHEo Sa...       0.0   \n",
       "\n",
       "                                        Cleaned Text  Length  \\\n",
       "0  read context no change meaning history islamic...      54   \n",
       "1  idiot claim people tried stop becoming terrori...      86   \n",
       "2       rt call sexist go auto place rather talk guy      44   \n",
       "3   wrong isi follows example mohammed quran exactly      48   \n",
       "4  rt saudi preacher raped tortured five year old...      70   \n",
       "\n",
       "                                              Tokens  \n",
       "0  [read, context, no, change, meaning, history, ...  \n",
       "1  [idiot, claim, people, tried, stop, becoming, ...  \n",
       "2  [rt, call, sexist, go, auto, place, rather, ta...  \n",
       "3  [wrong, isi, follows, example, mohammed, quran...  \n",
       "4  [rt, saudi, preacher, raped, tortured, five, y...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_size = 1000\n",
    "word2vec_model = Word2Vec(dataset['Tokens'], min_count=1, window=10, vector_size=vector_size, workers=8, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.59068897e-01, -1.62096210e-02,  6.12645857e-02,  1.27397582e-01,\n",
       "        1.51499072e-02,  2.78897434e-02,  8.85943919e-02,  1.12681739e-01,\n",
       "       -6.33594096e-02,  6.96348995e-02,  6.38258234e-02,  2.63297092e-02,\n",
       "       -2.58807912e-02,  2.28036456e-02,  8.54240209e-02, -4.30091433e-02,\n",
       "       -9.73128900e-02, -1.27138896e-02,  7.59315118e-02, -1.32021397e-01,\n",
       "        2.09686272e-02, -2.50060055e-02, -1.16026355e-02, -1.41014745e-02,\n",
       "        7.54363984e-02,  2.23613046e-02,  2.70476080e-02, -5.66235073e-02,\n",
       "       -1.67580739e-01,  6.04459271e-02,  9.31861624e-02, -3.35567184e-02,\n",
       "       -1.60755950e-03, -8.13387930e-02,  3.77570763e-02, -6.48485869e-02,\n",
       "        7.51266703e-02,  9.87086538e-03,  2.12977026e-02, -1.15865946e-01,\n",
       "        1.80366561e-02, -1.30223799e-02, -3.66284288e-02,  1.65488213e-01,\n",
       "       -2.63127666e-02, -4.65158233e-03, -8.93644020e-02,  1.24801338e-01,\n",
       "       -4.65367772e-02,  4.12965901e-02, -5.81989065e-03, -2.18067020e-02,\n",
       "        7.71677913e-03, -6.66617528e-02,  8.81936848e-02,  2.90256087e-02,\n",
       "        9.57682431e-02,  4.89155799e-02, -2.85222288e-02, -2.72743795e-02,\n",
       "       -1.22180134e-01,  4.36927080e-02, -9.57279801e-02, -1.62008759e-02,\n",
       "       -2.70336890e-03,  2.02408675e-02,  5.23204990e-02,  1.45672053e-01,\n",
       "        2.55388655e-02, -2.63363030e-02,  2.16168370e-02, -5.83348088e-02,\n",
       "        5.40355332e-02, -5.21345846e-02,  5.48945628e-02, -2.56158002e-02,\n",
       "       -4.25800793e-02,  1.82105476e-04,  8.20958987e-03,  2.38118023e-02,\n",
       "       -3.84889692e-02,  5.51675744e-02, -1.31356731e-01,  1.01142377e-01,\n",
       "       -1.49791121e-01,  5.39457016e-02, -4.11453731e-02,  1.05886837e-03,\n",
       "        2.91191787e-02,  7.49221966e-02, -9.90768801e-03,  2.57622246e-02,\n",
       "       -4.47641965e-03,  9.33683515e-02,  1.34403691e-01,  7.14704767e-02,\n",
       "        8.03349093e-02, -8.32361877e-02,  5.60369194e-02,  3.29699926e-02,\n",
       "       -3.02966069e-02,  5.79614230e-02,  6.12944737e-02,  5.97072542e-02,\n",
       "       -3.14584523e-02,  3.43365222e-02, -6.66459603e-03,  2.67699771e-02,\n",
       "       -8.90504476e-03, -7.68547952e-02, -5.79750426e-02, -4.93470654e-02,\n",
       "        1.71420407e-02,  6.61005452e-02,  8.74913950e-03,  5.99549944e-03,\n",
       "        4.74888049e-02, -5.07716686e-02,  7.82588422e-02, -1.12331629e-01,\n",
       "       -3.10624540e-02,  1.19661344e-02,  1.05369017e-01, -9.05676931e-03,\n",
       "       -5.14830602e-03,  1.97107662e-02, -8.61950815e-02,  5.72092645e-02,\n",
       "        1.69000346e-02,  8.03992301e-02,  3.94976288e-02, -2.00177208e-02,\n",
       "        3.08804382e-02, -3.32853235e-02,  2.23166472e-03,  3.96909751e-03,\n",
       "       -5.57758799e-03, -2.45794351e-03, -7.74584413e-02, -7.93438330e-02,\n",
       "        5.69517165e-02, -3.35483886e-02, -7.18411505e-02, -2.45349854e-02,\n",
       "        5.83716445e-02,  2.59377854e-03,  9.23095550e-03,  6.93727806e-02,\n",
       "        5.37202284e-02, -2.49589998e-02,  5.06807566e-02, -4.50244509e-02,\n",
       "       -2.03986410e-02,  1.08440362e-01, -1.87578514e-01,  3.63177806e-02,\n",
       "        6.42523021e-02,  1.62542369e-02, -1.44456339e-03,  1.01728579e-02,\n",
       "        1.14356361e-01,  5.41969091e-02, -4.65909466e-02, -1.03447571e-01,\n",
       "       -7.72871971e-02,  5.81804141e-02,  1.11741550e-01,  3.92916724e-02,\n",
       "        5.46889082e-02,  1.32522419e-01,  9.34888944e-02,  1.11098722e-01,\n",
       "       -7.69173494e-04, -2.70747244e-02, -1.40665444e-02, -7.76622724e-03,\n",
       "       -9.05118957e-02, -2.03191908e-03,  2.47369520e-03,  7.03448206e-02,\n",
       "        9.98856202e-02,  9.21526738e-03,  6.03551418e-02,  8.44942927e-02,\n",
       "        1.94632523e-02,  6.06849641e-02,  3.79650928e-02,  5.38135506e-02,\n",
       "        3.20563987e-02,  1.17035322e-02,  1.19855389e-01, -1.20103873e-01,\n",
       "        3.49183343e-02, -5.95293939e-02,  1.03891954e-01,  5.13153896e-02,\n",
       "        3.18346582e-02, -3.41366380e-02,  4.50246558e-02,  1.08923763e-02,\n",
       "       -3.26959528e-02,  2.61087082e-02,  1.79781821e-02,  3.22438888e-02,\n",
       "       -1.60440914e-02, -1.65104996e-02, -9.17123333e-02,  1.65936779e-02,\n",
       "       -6.03758916e-03, -2.22710259e-02,  1.71307437e-02,  1.57961398e-02,\n",
       "       -5.38863316e-02, -2.84347106e-02,  2.94928290e-02, -1.59987524e-01,\n",
       "       -2.62607094e-02, -7.71459518e-03, -1.38282180e-01, -5.41561060e-02,\n",
       "        8.21864009e-02,  7.76900947e-02,  7.19195381e-02,  5.58084995e-02,\n",
       "       -1.67550147e-02, -3.16003747e-02,  8.44658315e-02, -1.24944129e-03,\n",
       "        5.47405146e-02, -2.55998317e-02, -8.05979036e-03, -9.20749158e-02,\n",
       "        1.40836343e-01, -7.61931809e-03, -1.00809417e-03, -7.52869109e-03,\n",
       "        5.39222062e-02, -9.68653336e-02,  6.83929622e-02, -8.31002928e-03,\n",
       "       -5.86428791e-02, -6.93749264e-03, -7.35222921e-02,  6.57816008e-02,\n",
       "        3.14238854e-02,  3.73635404e-02,  3.54248360e-02,  2.94744018e-02,\n",
       "        2.49404404e-02,  2.42411941e-02,  3.19573730e-02, -3.78135294e-02,\n",
       "       -5.14177680e-02, -3.91150266e-02, -3.89363356e-02,  1.20553281e-03,\n",
       "        7.25707039e-02,  2.58248523e-02, -7.21221939e-02, -2.87507400e-02,\n",
       "       -1.01416230e-01,  1.88429728e-02, -5.20878397e-02, -2.55366564e-02,\n",
       "       -4.79786517e-03,  4.32938784e-02, -2.61276402e-02,  1.66925997e-01,\n",
       "       -1.42270356e-01,  9.30687562e-02, -6.09604269e-03,  2.04745233e-02,\n",
       "        1.45748174e-02,  9.88355801e-02, -1.11423425e-01,  4.58054170e-02,\n",
       "        1.13097364e-02, -9.60807949e-02, -1.10413045e-01,  1.00157715e-01,\n",
       "        6.26915768e-02,  8.16804841e-02, -3.26375104e-02, -2.82879937e-02,\n",
       "        8.31261724e-02, -1.04536088e-02, -1.24936097e-03, -5.79467304e-02,\n",
       "       -2.34312960e-03,  1.11408189e-01, -7.40655288e-02,  7.48537481e-02,\n",
       "        4.61592898e-02,  1.33959025e-01,  5.42231798e-02, -3.84221040e-02,\n",
       "        6.95453361e-02, -7.94658363e-02,  7.41244853e-03, -1.99255496e-02,\n",
       "       -3.60870063e-02,  4.37633321e-03,  2.13972311e-02, -2.07538567e-02,\n",
       "        1.10515235e-02, -6.34062216e-02,  7.69817596e-03,  5.70478402e-02,\n",
       "        3.78081538e-02, -6.19552806e-02, -2.12625172e-02, -7.81219304e-02,\n",
       "       -3.15945968e-02,  2.52073854e-02,  1.86540578e-02,  1.56310331e-02,\n",
       "       -1.21115148e-02, -3.07994392e-02, -1.64494645e-02, -3.26930285e-02,\n",
       "       -9.58430860e-03,  1.00644164e-01,  4.33838367e-02,  4.53105476e-03,\n",
       "       -5.06735668e-02, -1.02029234e-01, -3.31066661e-02, -4.02650125e-02,\n",
       "       -1.09028518e-02, -3.88298812e-03,  4.06500250e-02,  2.53988840e-02,\n",
       "       -7.89033473e-02, -1.72995236e-02, -1.13666197e-03, -1.05591133e-01,\n",
       "        2.42199772e-03, -2.85238028e-02, -2.66433228e-02, -8.52440372e-02,\n",
       "        1.02672093e-01, -4.57138382e-03, -7.86426514e-02, -5.54034859e-02,\n",
       "       -5.92172332e-02,  8.17733631e-02, -2.12123141e-01,  1.46694006e-02,\n",
       "       -2.71277484e-02,  6.39135297e-03, -7.78582096e-02, -4.64533875e-03,\n",
       "       -6.15629144e-02,  1.23379938e-01, -9.85478237e-03,  1.08463168e-01,\n",
       "       -1.39643252e-02, -6.84077442e-02,  7.95912668e-02, -3.59350070e-02,\n",
       "       -7.16392770e-02,  1.33286953e-01, -8.84950384e-02, -3.32786590e-02,\n",
       "        1.94295775e-02, -5.49675748e-02,  7.46616125e-02, -3.81734334e-02,\n",
       "       -6.17538244e-02, -2.12329943e-02, -1.00141257e-01, -7.63959959e-02,\n",
       "       -5.70703223e-02,  1.35255652e-02, -6.16489537e-02,  4.77678366e-02,\n",
       "        3.89806107e-02,  8.00808705e-03,  4.01108935e-02,  4.86219935e-02,\n",
       "        3.82292308e-02,  1.09770983e-01,  2.04140060e-02,  5.65415062e-02,\n",
       "       -5.33560961e-02, -5.12782065e-03,  5.89861348e-02,  1.78336874e-02,\n",
       "        7.05865100e-02,  1.19660059e-02, -3.47720869e-02, -1.11649051e-01,\n",
       "       -6.56143762e-03, -7.61825070e-02,  1.45534230e-02,  5.14800707e-03,\n",
       "        5.15252836e-02,  7.86373913e-02, -1.11472502e-03, -2.29751784e-02,\n",
       "        5.80259115e-02,  2.65195612e-02, -2.18948666e-02, -9.22239199e-02,\n",
       "        7.12242052e-02, -6.51244968e-02, -9.50193964e-03,  1.07166819e-01,\n",
       "        6.61283825e-03,  6.38060942e-02, -2.47788988e-02, -4.84013073e-02,\n",
       "       -6.11115992e-02, -6.75205514e-02, -1.48079209e-02, -1.96427740e-02,\n",
       "       -1.33605031e-02, -6.66059926e-03,  8.74986053e-02, -1.08226426e-01,\n",
       "       -1.44634033e-02, -1.32244810e-01, -8.02106038e-02,  2.98777185e-02,\n",
       "       -7.16004074e-02, -9.35104638e-02, -2.07127258e-02,  8.46987367e-02,\n",
       "       -8.24623033e-02,  3.29906419e-02, -6.47903606e-02,  2.63808556e-02,\n",
       "        1.36459023e-02, -2.99114101e-02,  6.51938319e-02,  2.51656044e-02,\n",
       "        3.86722595e-03,  6.39052987e-02, -2.49538291e-02,  5.62519059e-02,\n",
       "        9.43807811e-02,  1.77353863e-02,  1.52923670e-02,  1.75618764e-03,\n",
       "        1.93673342e-01,  1.85849646e-03,  3.77338678e-02, -4.93565127e-02,\n",
       "        6.65404275e-02, -1.46238161e-02,  7.34767839e-02, -5.29310964e-02,\n",
       "       -4.85466234e-02, -1.37584269e-01, -4.72953916e-02, -5.07953204e-02,\n",
       "       -1.17319347e-02, -4.29759920e-02,  1.22308142e-01, -4.17136662e-02,\n",
       "       -2.54678838e-02,  8.72193575e-02, -4.39077541e-02,  4.64816764e-02,\n",
       "       -4.60804775e-02,  3.86450365e-02, -4.93780300e-02, -4.83316071e-02,\n",
       "       -3.98470927e-03,  7.64381746e-03, -1.18339382e-01, -1.48330163e-03,\n",
       "        4.11361344e-02, -1.03403278e-01,  5.53764813e-02,  2.17698917e-01,\n",
       "        8.24366361e-02, -1.23446703e-01, -1.21117227e-01,  4.76968400e-02,\n",
       "       -7.48144910e-02, -1.06654577e-01,  9.04851314e-03,  1.44835725e-01,\n",
       "       -3.35392319e-02,  8.54583904e-02, -1.33880591e-02,  8.16864520e-02,\n",
       "        1.94304045e-02, -6.83942512e-02,  3.28877494e-02, -5.10191470e-02,\n",
       "        2.23020129e-02, -2.72309799e-02, -6.79730903e-03, -2.61456408e-02,\n",
       "        1.83703080e-02, -7.26023838e-02, -8.66828188e-02, -4.28643376e-02,\n",
       "       -2.53206249e-02,  1.24580741e-01,  2.92045511e-02,  2.26183590e-02,\n",
       "       -1.69048291e-02, -1.47316843e-01,  5.94359189e-02,  1.47703603e-01,\n",
       "        1.30668193e-01, -8.32230523e-02, -2.11684331e-02,  3.13840471e-02,\n",
       "        3.61572616e-02, -1.27371494e-02, -6.30751625e-02, -1.53709397e-01,\n",
       "       -9.24588144e-02, -6.95918202e-02, -6.31007850e-02,  1.28153965e-01,\n",
       "       -2.68690381e-02, -4.19899113e-02,  9.55008417e-02, -4.60127220e-02,\n",
       "        5.80235906e-02,  1.36162654e-01, -4.63304892e-02,  7.47677535e-02,\n",
       "       -8.80223587e-02, -3.81427854e-02,  1.95193961e-02,  1.02084808e-01,\n",
       "       -3.66590060e-02, -2.29131319e-02,  4.02452685e-02,  4.02695872e-02,\n",
       "       -1.16940334e-01, -1.06810480e-01,  9.21610463e-03, -8.51886272e-02,\n",
       "        3.50053497e-02, -3.80184688e-02, -1.06796086e-01, -3.46304402e-02,\n",
       "       -7.11631179e-02, -5.34077510e-02, -2.83650011e-02, -5.31533025e-02,\n",
       "        4.90051694e-02,  1.49948606e-02, -3.75395529e-02,  1.23165024e-03,\n",
       "       -2.70325225e-02, -9.66048017e-02,  2.51389071e-02, -6.45446554e-02,\n",
       "        3.08267903e-02,  7.59185702e-02,  6.36000708e-02,  6.74257949e-02,\n",
       "        1.48397371e-01,  1.53435189e-02,  2.09071804e-02, -6.68881810e-04,\n",
       "       -6.45131692e-02,  5.82558140e-02, -4.54576500e-02, -9.52313691e-02,\n",
       "        8.14276710e-02,  3.89177129e-02, -1.07184321e-01,  5.71484640e-02,\n",
       "       -1.09907771e-02, -2.77493373e-02, -2.48745549e-02,  4.27364111e-02,\n",
       "       -6.21328019e-02,  3.28784622e-03,  2.19417270e-02,  9.16483030e-02,\n",
       "       -3.36261392e-02, -5.91383390e-02, -4.53092717e-02, -1.52195208e-02,\n",
       "       -3.25654447e-02,  9.59527865e-03, -4.95107658e-03,  4.34143580e-02,\n",
       "        4.12232280e-02,  7.10173994e-02, -2.63549741e-02, -2.81231590e-02,\n",
       "       -5.91836236e-02,  8.83196518e-02,  1.40427751e-02, -4.51864116e-02,\n",
       "       -2.77961828e-02,  4.56933640e-02,  5.54603525e-03,  4.92438227e-02,\n",
       "       -6.96895197e-02, -3.70059013e-02, -1.26901522e-01,  2.15689093e-02,\n",
       "        1.66829657e-02, -4.57842238e-02, -7.64899924e-02,  1.45867243e-01,\n",
       "        1.51044922e-02,  3.09729632e-02, -2.72832587e-02, -3.19362730e-02,\n",
       "       -1.19481133e-02,  4.64794151e-02, -1.19242340e-01,  2.80476082e-02,\n",
       "        1.84102003e-02, -3.37800453e-03,  5.91501109e-02,  7.39476010e-02,\n",
       "       -2.28486098e-02, -2.36586854e-02, -8.75963941e-02, -3.97721790e-02,\n",
       "       -1.68553612e-03,  4.74539027e-02, -8.76164734e-02,  4.31264676e-02,\n",
       "       -2.14341562e-02, -4.55471240e-02,  4.32907566e-02,  5.99100292e-02,\n",
       "       -2.18163729e-02, -8.17677826e-02,  7.39621967e-02,  1.09551154e-01,\n",
       "        4.28423397e-02,  2.96484549e-02, -9.35847834e-02, -1.10796265e-01,\n",
       "        3.12055312e-02, -3.82284634e-02,  6.60740882e-02, -1.82409529e-02,\n",
       "        6.70281351e-02,  7.46348426e-02, -1.01408191e-01, -8.17167908e-02,\n",
       "        6.68245926e-02,  6.10987283e-02,  1.79875940e-02,  2.35201269e-02,\n",
       "        9.76594687e-02,  9.15248618e-02,  2.35204063e-02, -1.37632219e-02,\n",
       "        1.61358733e-02, -4.48141880e-02,  7.62422744e-04, -9.83712971e-02,\n",
       "       -3.39796953e-02, -1.08128086e-01,  8.28128122e-03, -1.48880733e-02,\n",
       "        7.09459279e-03,  1.12604788e-02,  8.66645351e-02,  1.55981034e-02,\n",
       "        4.67292555e-02, -2.15520114e-02,  6.25734553e-02,  5.04074572e-03,\n",
       "       -3.39522026e-02,  1.22148357e-01,  3.90435122e-02, -2.59528831e-02,\n",
       "       -2.78682611e-03, -1.72369163e-02, -9.47332978e-02,  2.59268028e-03,\n",
       "       -8.45210105e-02, -6.52066246e-02,  3.53611596e-02,  1.00698238e-02,\n",
       "       -5.40363453e-02, -2.00506784e-02, -1.05441898e-01,  1.20314077e-01,\n",
       "       -4.30347435e-02, -4.08746190e-02,  1.86222047e-02,  2.45051621e-03,\n",
       "        1.67054925e-02, -3.53359096e-02,  3.11321653e-02, -1.46439066e-02,\n",
       "        5.29030291e-03,  1.12216668e-02,  4.56977077e-02,  5.58035523e-02,\n",
       "       -3.52067612e-02,  1.30963000e-02,  1.14271184e-02,  4.41226885e-02,\n",
       "       -3.72657292e-02,  3.61307263e-02,  1.32688507e-01, -4.04975638e-02,\n",
       "       -1.37960494e-01, -8.94253794e-03,  9.61761735e-03, -9.72804353e-02,\n",
       "       -8.93478990e-02, -2.02596299e-02,  1.72911379e-02,  1.15865339e-02,\n",
       "        9.29598045e-03, -2.17564814e-02, -4.54498567e-02,  1.71598420e-02,\n",
       "        4.21873406e-02,  1.41482968e-02, -4.40738797e-02,  5.28032780e-02,\n",
       "        8.02314728e-02,  1.42335230e-02,  7.07300901e-02, -5.62471561e-02,\n",
       "        1.30664796e-01,  3.19912285e-02, -2.88456902e-02,  5.28761186e-02,\n",
       "       -3.08825020e-02, -5.77955619e-02,  4.60381620e-03,  2.33061742e-02,\n",
       "       -1.58357956e-02, -1.15412503e-01,  1.05009072e-01, -9.91197005e-02,\n",
       "        4.18398157e-02, -5.68145178e-02, -1.23184383e-01,  7.05961585e-02,\n",
       "       -1.20665602e-01, -2.88763233e-02, -3.04398872e-02,  2.88866460e-02,\n",
       "        9.95765328e-02,  7.28822276e-02, -2.88336631e-02, -1.45804346e-01,\n",
       "        6.90619946e-02, -1.18438341e-02, -5.99596687e-02,  8.49658325e-02,\n",
       "        1.95006207e-02,  8.94491076e-02, -1.09904423e-01,  2.55450271e-02,\n",
       "       -3.20672803e-02, -1.96279455e-02, -1.15540087e-01,  2.22984012e-02,\n",
       "        6.37030825e-02, -7.20155686e-02, -5.17416671e-02, -1.50300879e-02,\n",
       "        5.89654930e-02, -7.85265788e-02, -3.31948698e-02, -1.65525954e-02,\n",
       "        1.06948368e-01, -1.10214613e-01, -2.18717959e-02, -6.84454143e-02,\n",
       "       -8.14025328e-02, -6.09496087e-02,  3.59483436e-02, -6.80172443e-02,\n",
       "        9.94116813e-03, -4.94748838e-02, -1.47380577e-02, -9.15156081e-02,\n",
       "        9.10028890e-02, -9.72840711e-02, -8.90881568e-03, -3.39335836e-02,\n",
       "        3.22832614e-02, -1.01692356e-01, -2.08291300e-02,  4.85738367e-02,\n",
       "       -3.94079760e-02,  6.47127582e-03,  2.26568915e-02,  8.45101401e-02,\n",
       "        3.34313735e-02, -1.28727928e-01,  5.60969375e-02, -3.71278115e-02,\n",
       "        2.69770017e-03, -6.94700927e-02, -2.23823674e-02, -1.30100679e-02,\n",
       "        7.30303004e-02, -2.93908603e-02, -5.54502383e-02,  1.32620865e-02,\n",
       "        3.09023801e-02,  5.17780408e-02, -9.53716924e-04, -6.89696744e-02,\n",
       "        6.82121292e-02,  1.90667599e-03, -3.28127295e-02,  1.03632212e-02,\n",
       "       -7.72969350e-02, -4.93791588e-02, -3.46674547e-02,  1.58413481e-02,\n",
       "        3.23834792e-02, -6.50438294e-03, -1.83353275e-02, -2.08895374e-02,\n",
       "       -3.32806669e-02, -3.80815892e-03, -5.99113740e-02, -8.45460892e-02,\n",
       "       -4.00218479e-02,  5.99827897e-03, -6.99520856e-03, -1.05800973e-02,\n",
       "       -5.32861203e-02,  6.93165138e-02, -1.01886755e-02,  3.32845487e-02,\n",
       "       -3.98035608e-02,  1.45154133e-01,  2.36465186e-02, -2.73926016e-02,\n",
       "       -5.05464263e-02,  2.06282552e-04,  7.62920231e-02, -1.73515137e-02,\n",
       "        5.16509973e-02, -5.65601960e-02, -3.31791453e-02,  3.43798287e-02,\n",
       "        1.03361607e-01,  4.33004238e-02,  1.20376065e-01,  4.03225943e-02,\n",
       "       -4.62315567e-02,  3.17195021e-02, -9.78951231e-02,  2.19254345e-02,\n",
       "       -2.71431822e-02,  2.41759494e-02, -7.84220621e-02, -4.26542461e-02,\n",
       "        4.59623225e-02, -3.78908142e-02,  2.19865181e-02,  4.86985929e-02,\n",
       "        2.46697348e-02, -9.78508778e-03,  3.17432694e-02, -3.26847769e-02,\n",
       "       -1.14965297e-01,  5.84681071e-02,  1.92247182e-02,  1.15004620e-02,\n",
       "        7.02907071e-02, -1.18475690e-01, -7.83587471e-02, -1.16548024e-01,\n",
       "       -1.16217218e-01, -4.68037874e-02, -5.39824106e-02, -1.30408674e-01,\n",
       "        6.06594607e-03, -1.33077726e-01,  1.03063375e-01,  3.14074568e-02,\n",
       "        1.33016855e-02, -7.49468803e-02, -3.28221284e-02,  1.26786996e-02,\n",
       "        1.10836169e-02, -9.32436623e-03, -8.55266154e-02,  8.33666995e-02,\n",
       "        4.24663760e-02,  6.68117851e-02,  9.34438333e-02,  9.38692912e-02,\n",
       "       -2.76875291e-02,  1.37609905e-02,  4.50861342e-02, -9.36273206e-03,\n",
       "       -8.61008242e-02,  3.70442122e-02, -6.20182343e-02, -5.46171330e-02,\n",
       "       -5.86312488e-02, -1.02240674e-01,  2.73465784e-03, -1.78755652e-02,\n",
       "        7.96506405e-02, -2.20309035e-03,  1.66399106e-02, -8.76949206e-02,\n",
       "       -8.46533924e-02, -4.79338914e-02,  4.03567776e-02, -1.06915161e-02,\n",
       "        7.27108046e-02, -8.92763436e-02,  3.32606249e-02, -2.47637164e-02,\n",
       "       -7.95880109e-02,  1.08795896e-01, -8.84071887e-02,  3.39217931e-02,\n",
       "       -2.33897027e-02,  3.58479545e-02, -1.19123086e-02, -4.40749563e-02,\n",
       "        3.64891142e-02, -8.65557417e-02,  8.29389840e-02, -9.34973136e-02,\n",
       "       -5.83176464e-02,  2.04343796e-02, -9.57885981e-02,  1.17116712e-03,\n",
       "       -9.11663547e-02, -4.46088575e-02, -1.06436405e-02, -2.51973365e-02,\n",
       "       -1.81743801e-02, -6.37218878e-02,  7.77667463e-02, -6.69390261e-02,\n",
       "       -7.43390098e-02,  7.83051252e-02,  4.77107279e-02,  1.26166150e-01,\n",
       "       -1.34340614e-01, -1.58540551e-02, -1.99707057e-02, -7.78990937e-03,\n",
       "       -6.66993728e-04, -1.94167513e-02,  9.17727128e-02,  1.20202312e-02,\n",
       "       -2.21884549e-02,  6.78873360e-02, -3.47251818e-02, -7.24152708e-03,\n",
       "        8.21150653e-03,  2.92996503e-02,  6.60322746e-03, -1.86510361e-03,\n",
       "       -6.79836124e-02, -9.49163586e-02,  5.24585359e-02, -1.50392935e-01,\n",
       "       -3.18325311e-02,  9.49027687e-02,  5.12831137e-02,  4.37315479e-02,\n",
       "        3.57594080e-02, -8.34530890e-02,  1.58887237e-01,  1.13322632e-02,\n",
       "       -1.03415148e-02,  6.65840209e-02, -2.77560782e-02, -8.30172151e-02,\n",
       "        2.43810527e-02, -5.01183085e-02, -2.72260159e-02,  1.71950017e-03,\n",
       "        4.30584289e-02,  2.25500464e-02, -6.71838149e-02, -3.57034104e-03,\n",
       "        6.75028637e-02,  5.48631139e-02,  4.28784117e-02, -2.52272654e-02,\n",
       "        1.40793383e-01,  3.37715186e-02,  5.50802611e-02, -5.02990484e-02,\n",
       "       -6.83082193e-02, -8.14377367e-02, -5.17740026e-02, -3.16832475e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.wv.get_vector('idiot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avgVectors(tokens):\n",
    "  avg_vector = np.mean([word2vec_model.wv.get_vector(token) for token in tokens], axis=0)\n",
    "  return avg_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Priyesh Dave\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning:\n",
      "\n",
      "Mean of empty slice.\n",
      "\n",
      "C:\\Users\\Priyesh Dave\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset['Word2Vec'] = dataset['Tokens'].apply(avgVectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>oh_label</th>\n",
       "      <th>Cleaned Text</th>\n",
       "      <th>Length</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Word2Vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@halalflaws @biebervalue @greenlinerzjm I read...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>read context no change meaning history islamic...</td>\n",
       "      <td>54</td>\n",
       "      <td>[read, context, no, change, meaning, history, ...</td>\n",
       "      <td>[0.1391722, -0.015404301, 0.057572592, 0.11904...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ShreyaBafna3 Now you idiots claim that people...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>idiot claim people tried stop becoming terrori...</td>\n",
       "      <td>86</td>\n",
       "      <td>[idiot, claim, people, tried, stop, becoming, ...</td>\n",
       "      <td>[0.12530968, -0.006700354, 0.058066975, 0.1041...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @Mooseoftorment Call me sexist, but when I ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rt call sexist go auto place rather talk guy</td>\n",
       "      <td>44</td>\n",
       "      <td>[rt, call, sexist, go, auto, place, rather, ta...</td>\n",
       "      <td>[0.13381705, -0.013543546, 0.08076621, 0.11225...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@g0ssipsquirrelx Wrong, ISIS follows the examp...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>wrong isi follows example mohammed quran exactly</td>\n",
       "      <td>48</td>\n",
       "      <td>[wrong, isi, follows, example, mohammed, quran...</td>\n",
       "      <td>[0.14474444, -0.010601993, 0.02713455, 0.13810...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @TRobinsonNewEra: http://t.co/nkkCbpcHEo Sa...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rt saudi preacher raped tortured five year old...</td>\n",
       "      <td>70</td>\n",
       "      <td>[rt, saudi, preacher, raped, tortured, five, y...</td>\n",
       "      <td>[0.12063544, -0.021805331, 0.05576928, 0.09215...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16580</th>\n",
       "      <td>Feeling so sorry for the girls, they should be...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>feeling sorry girls safe kat andre going home</td>\n",
       "      <td>45</td>\n",
       "      <td>[feeling, sorry, girls, safe, kat, andre, goin...</td>\n",
       "      <td>[0.15048704, -0.012110224, 0.13803366, 0.08641...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16581</th>\n",
       "      <td>#MKR 'pretty good dishes we're happy with' - O...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pretty good dish we re happy with ok well neve...</td>\n",
       "      <td>60</td>\n",
       "      <td>[pretty, good, dish, we, re, happy, with, ok, ...</td>\n",
       "      <td>[0.13081671, -0.023820447, 0.1275136, 0.123698...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16582</th>\n",
       "      <td>RT @colonelkickhead: Deconstructed lemon tart!...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rt deconstructed lemon tart can please go one ...</td>\n",
       "      <td>100</td>\n",
       "      <td>[rt, deconstructed, lemon, tart, can, please, ...</td>\n",
       "      <td>[0.13121797, -0.01306887, 0.12625006, 0.108089...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16583</th>\n",
       "      <td>@versacezaynx @nyazpolitics @greenlinerzjm You...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stupid talk to blocked</td>\n",
       "      <td>22</td>\n",
       "      <td>[stupid, talk, to, blocked]</td>\n",
       "      <td>[0.13149679, -0.012590678, 0.07335784, 0.12112...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16584</th>\n",
       "      <td>And before you protest that you're *not* mad, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>protest not mad there much reason tweeting wom...</td>\n",
       "      <td>57</td>\n",
       "      <td>[protest, not, mad, there, much, reason, tweet...</td>\n",
       "      <td>[0.12966438, -0.012538702, 0.07961005, 0.11013...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16585 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  oh_label  \\\n",
       "0      @halalflaws @biebervalue @greenlinerzjm I read...       0.0   \n",
       "1      @ShreyaBafna3 Now you idiots claim that people...       0.0   \n",
       "2      RT @Mooseoftorment Call me sexist, but when I ...       1.0   \n",
       "3      @g0ssipsquirrelx Wrong, ISIS follows the examp...       1.0   \n",
       "4      RT @TRobinsonNewEra: http://t.co/nkkCbpcHEo Sa...       0.0   \n",
       "...                                                  ...       ...   \n",
       "16580  Feeling so sorry for the girls, they should be...       0.0   \n",
       "16581  #MKR 'pretty good dishes we're happy with' - O...       0.0   \n",
       "16582  RT @colonelkickhead: Deconstructed lemon tart!...       0.0   \n",
       "16583  @versacezaynx @nyazpolitics @greenlinerzjm You...       0.0   \n",
       "16584  And before you protest that you're *not* mad, ...       0.0   \n",
       "\n",
       "                                            Cleaned Text  Length  \\\n",
       "0      read context no change meaning history islamic...      54   \n",
       "1      idiot claim people tried stop becoming terrori...      86   \n",
       "2           rt call sexist go auto place rather talk guy      44   \n",
       "3       wrong isi follows example mohammed quran exactly      48   \n",
       "4      rt saudi preacher raped tortured five year old...      70   \n",
       "...                                                  ...     ...   \n",
       "16580      feeling sorry girls safe kat andre going home      45   \n",
       "16581  pretty good dish we re happy with ok well neve...      60   \n",
       "16582  rt deconstructed lemon tart can please go one ...     100   \n",
       "16583                             stupid talk to blocked      22   \n",
       "16584  protest not mad there much reason tweeting wom...      57   \n",
       "\n",
       "                                                  Tokens  \\\n",
       "0      [read, context, no, change, meaning, history, ...   \n",
       "1      [idiot, claim, people, tried, stop, becoming, ...   \n",
       "2      [rt, call, sexist, go, auto, place, rather, ta...   \n",
       "3      [wrong, isi, follows, example, mohammed, quran...   \n",
       "4      [rt, saudi, preacher, raped, tortured, five, y...   \n",
       "...                                                  ...   \n",
       "16580  [feeling, sorry, girls, safe, kat, andre, goin...   \n",
       "16581  [pretty, good, dish, we, re, happy, with, ok, ...   \n",
       "16582  [rt, deconstructed, lemon, tart, can, please, ...   \n",
       "16583                        [stupid, talk, to, blocked]   \n",
       "16584  [protest, not, mad, there, much, reason, tweet...   \n",
       "\n",
       "                                                Word2Vec  \n",
       "0      [0.1391722, -0.015404301, 0.057572592, 0.11904...  \n",
       "1      [0.12530968, -0.006700354, 0.058066975, 0.1041...  \n",
       "2      [0.13381705, -0.013543546, 0.08076621, 0.11225...  \n",
       "3      [0.14474444, -0.010601993, 0.02713455, 0.13810...  \n",
       "4      [0.12063544, -0.021805331, 0.05576928, 0.09215...  \n",
       "...                                                  ...  \n",
       "16580  [0.15048704, -0.012110224, 0.13803366, 0.08641...  \n",
       "16581  [0.13081671, -0.023820447, 0.1275136, 0.123698...  \n",
       "16582  [0.13121797, -0.01306887, 0.12625006, 0.108089...  \n",
       "16583  [0.13149679, -0.012590678, 0.07335784, 0.12112...  \n",
       "16584  [0.12966438, -0.012538702, 0.07961005, 0.11013...  \n",
       "\n",
       "[16585 rows x 6 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Priyesh Dave\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning:\n",
      "\n",
      "Mean of empty slice.\n",
      "\n",
      "C:\\Users\\Priyesh Dave\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Store the vectors for train data in following file\n",
    "OUTPUT_FOLDER = '../Datasets/'\n",
    "word2vec_filename = OUTPUT_FOLDER + 'train_review_word2vec.csv'\n",
    "with open(word2vec_filename, 'w+') as word2vec_file:\n",
    "    for index, row in dataset.iterrows():\n",
    "        model_vector = (np.mean([word2vec_model.wv.get_vector(token) for token in row['Tokens']], axis=0)).tolist()\n",
    "        if index == 0:\n",
    "            header = \",\".join(str(ele) for ele in range(vector_size))\n",
    "            word2vec_file.write(header)\n",
    "            word2vec_file.write(\"\\n\")\n",
    "        # Check if the line exists else it is vector of zeros\n",
    "        if type(model_vector) is list:  \n",
    "            line1 = \",\".join( [str(vector_element) for vector_element in model_vector] )\n",
    "        else:\n",
    "            line1 = \",\".join([str(0) for i in range(vector_size)])\n",
    "        word2vec_file.write(line1)\n",
    "        word2vec_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.139172</td>\n",
       "      <td>-0.015404</td>\n",
       "      <td>0.057573</td>\n",
       "      <td>0.119046</td>\n",
       "      <td>0.013685</td>\n",
       "      <td>0.022992</td>\n",
       "      <td>0.077423</td>\n",
       "      <td>0.115961</td>\n",
       "      <td>-0.044865</td>\n",
       "      <td>0.056218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026172</td>\n",
       "      <td>-0.029434</td>\n",
       "      <td>0.129981</td>\n",
       "      <td>0.015133</td>\n",
       "      <td>0.053493</td>\n",
       "      <td>-0.043010</td>\n",
       "      <td>-0.077664</td>\n",
       "      <td>-0.087695</td>\n",
       "      <td>-0.067725</td>\n",
       "      <td>-0.025900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.125310</td>\n",
       "      <td>-0.006700</td>\n",
       "      <td>0.058067</td>\n",
       "      <td>0.104196</td>\n",
       "      <td>0.002171</td>\n",
       "      <td>0.017443</td>\n",
       "      <td>0.067311</td>\n",
       "      <td>0.122081</td>\n",
       "      <td>-0.041037</td>\n",
       "      <td>0.050169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030991</td>\n",
       "      <td>-0.027494</td>\n",
       "      <td>0.110958</td>\n",
       "      <td>0.022329</td>\n",
       "      <td>0.038806</td>\n",
       "      <td>-0.035423</td>\n",
       "      <td>-0.078966</td>\n",
       "      <td>-0.080697</td>\n",
       "      <td>-0.058431</td>\n",
       "      <td>-0.013146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.133817</td>\n",
       "      <td>-0.013544</td>\n",
       "      <td>0.080766</td>\n",
       "      <td>0.112260</td>\n",
       "      <td>-0.019646</td>\n",
       "      <td>-0.027326</td>\n",
       "      <td>0.086766</td>\n",
       "      <td>0.047910</td>\n",
       "      <td>-0.052568</td>\n",
       "      <td>0.039453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018955</td>\n",
       "      <td>-0.013806</td>\n",
       "      <td>0.111037</td>\n",
       "      <td>0.022271</td>\n",
       "      <td>0.090845</td>\n",
       "      <td>-0.016199</td>\n",
       "      <td>-0.052414</td>\n",
       "      <td>-0.061058</td>\n",
       "      <td>-0.065700</td>\n",
       "      <td>-0.024589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.144744</td>\n",
       "      <td>-0.010602</td>\n",
       "      <td>0.027135</td>\n",
       "      <td>0.138109</td>\n",
       "      <td>0.018115</td>\n",
       "      <td>0.033027</td>\n",
       "      <td>0.091207</td>\n",
       "      <td>0.181945</td>\n",
       "      <td>-0.051138</td>\n",
       "      <td>0.101468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029048</td>\n",
       "      <td>-0.025057</td>\n",
       "      <td>0.166849</td>\n",
       "      <td>0.018266</td>\n",
       "      <td>0.037110</td>\n",
       "      <td>-0.072879</td>\n",
       "      <td>-0.107979</td>\n",
       "      <td>-0.118019</td>\n",
       "      <td>-0.091262</td>\n",
       "      <td>-0.039369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.120635</td>\n",
       "      <td>-0.021805</td>\n",
       "      <td>0.055769</td>\n",
       "      <td>0.092159</td>\n",
       "      <td>-0.014182</td>\n",
       "      <td>0.018769</td>\n",
       "      <td>0.082231</td>\n",
       "      <td>0.102992</td>\n",
       "      <td>-0.043298</td>\n",
       "      <td>0.036214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041842</td>\n",
       "      <td>-0.023385</td>\n",
       "      <td>0.093287</td>\n",
       "      <td>0.021078</td>\n",
       "      <td>0.038500</td>\n",
       "      <td>-0.037745</td>\n",
       "      <td>-0.074081</td>\n",
       "      <td>-0.082790</td>\n",
       "      <td>-0.056627</td>\n",
       "      <td>-0.011060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16580</th>\n",
       "      <td>0.150487</td>\n",
       "      <td>-0.012110</td>\n",
       "      <td>0.138034</td>\n",
       "      <td>0.086417</td>\n",
       "      <td>-0.035722</td>\n",
       "      <td>-0.021624</td>\n",
       "      <td>0.080107</td>\n",
       "      <td>0.023067</td>\n",
       "      <td>-0.065379</td>\n",
       "      <td>-0.009039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043940</td>\n",
       "      <td>-0.007019</td>\n",
       "      <td>0.064244</td>\n",
       "      <td>0.048055</td>\n",
       "      <td>0.080539</td>\n",
       "      <td>0.008690</td>\n",
       "      <td>-0.043842</td>\n",
       "      <td>-0.029989</td>\n",
       "      <td>-0.040435</td>\n",
       "      <td>0.016206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16581</th>\n",
       "      <td>0.130817</td>\n",
       "      <td>-0.023820</td>\n",
       "      <td>0.127514</td>\n",
       "      <td>0.123699</td>\n",
       "      <td>0.001802</td>\n",
       "      <td>-0.009748</td>\n",
       "      <td>0.067108</td>\n",
       "      <td>0.015257</td>\n",
       "      <td>-0.038393</td>\n",
       "      <td>-0.011983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001896</td>\n",
       "      <td>-0.016280</td>\n",
       "      <td>0.067583</td>\n",
       "      <td>0.004285</td>\n",
       "      <td>0.082278</td>\n",
       "      <td>-0.008132</td>\n",
       "      <td>-0.047996</td>\n",
       "      <td>-0.053658</td>\n",
       "      <td>-0.034887</td>\n",
       "      <td>0.005656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16582</th>\n",
       "      <td>0.131218</td>\n",
       "      <td>-0.013069</td>\n",
       "      <td>0.126250</td>\n",
       "      <td>0.108090</td>\n",
       "      <td>-0.016428</td>\n",
       "      <td>-0.020928</td>\n",
       "      <td>0.071040</td>\n",
       "      <td>0.034713</td>\n",
       "      <td>-0.035535</td>\n",
       "      <td>-0.002747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022896</td>\n",
       "      <td>-0.032039</td>\n",
       "      <td>0.078839</td>\n",
       "      <td>0.031743</td>\n",
       "      <td>0.087470</td>\n",
       "      <td>0.011023</td>\n",
       "      <td>-0.045950</td>\n",
       "      <td>-0.041572</td>\n",
       "      <td>-0.043497</td>\n",
       "      <td>-0.002814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16583</th>\n",
       "      <td>0.131497</td>\n",
       "      <td>-0.012591</td>\n",
       "      <td>0.073358</td>\n",
       "      <td>0.121129</td>\n",
       "      <td>0.005624</td>\n",
       "      <td>-0.003065</td>\n",
       "      <td>0.079125</td>\n",
       "      <td>0.065997</td>\n",
       "      <td>-0.047527</td>\n",
       "      <td>0.046685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012508</td>\n",
       "      <td>-0.023177</td>\n",
       "      <td>0.125806</td>\n",
       "      <td>0.011815</td>\n",
       "      <td>0.086856</td>\n",
       "      <td>-0.027691</td>\n",
       "      <td>-0.058323</td>\n",
       "      <td>-0.072766</td>\n",
       "      <td>-0.063418</td>\n",
       "      <td>-0.030536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16584</th>\n",
       "      <td>0.129664</td>\n",
       "      <td>-0.012539</td>\n",
       "      <td>0.079610</td>\n",
       "      <td>0.110136</td>\n",
       "      <td>-0.003073</td>\n",
       "      <td>-0.015345</td>\n",
       "      <td>0.079881</td>\n",
       "      <td>0.060282</td>\n",
       "      <td>-0.045505</td>\n",
       "      <td>0.039934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017551</td>\n",
       "      <td>-0.020227</td>\n",
       "      <td>0.116980</td>\n",
       "      <td>0.014501</td>\n",
       "      <td>0.083159</td>\n",
       "      <td>-0.022958</td>\n",
       "      <td>-0.058766</td>\n",
       "      <td>-0.067539</td>\n",
       "      <td>-0.065302</td>\n",
       "      <td>-0.026357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16585 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.139172 -0.015404  0.057573  0.119046  0.013685  0.022992  0.077423   \n",
       "1      0.125310 -0.006700  0.058067  0.104196  0.002171  0.017443  0.067311   \n",
       "2      0.133817 -0.013544  0.080766  0.112260 -0.019646 -0.027326  0.086766   \n",
       "3      0.144744 -0.010602  0.027135  0.138109  0.018115  0.033027  0.091207   \n",
       "4      0.120635 -0.021805  0.055769  0.092159 -0.014182  0.018769  0.082231   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "16580  0.150487 -0.012110  0.138034  0.086417 -0.035722 -0.021624  0.080107   \n",
       "16581  0.130817 -0.023820  0.127514  0.123699  0.001802 -0.009748  0.067108   \n",
       "16582  0.131218 -0.013069  0.126250  0.108090 -0.016428 -0.020928  0.071040   \n",
       "16583  0.131497 -0.012591  0.073358  0.121129  0.005624 -0.003065  0.079125   \n",
       "16584  0.129664 -0.012539  0.079610  0.110136 -0.003073 -0.015345  0.079881   \n",
       "\n",
       "              7         8         9  ...       990       991       992  \\\n",
       "0      0.115961 -0.044865  0.056218  ...  0.026172 -0.029434  0.129981   \n",
       "1      0.122081 -0.041037  0.050169  ...  0.030991 -0.027494  0.110958   \n",
       "2      0.047910 -0.052568  0.039453  ...  0.018955 -0.013806  0.111037   \n",
       "3      0.181945 -0.051138  0.101468  ...  0.029048 -0.025057  0.166849   \n",
       "4      0.102992 -0.043298  0.036214  ...  0.041842 -0.023385  0.093287   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "16580  0.023067 -0.065379 -0.009039  ...  0.043940 -0.007019  0.064244   \n",
       "16581  0.015257 -0.038393 -0.011983  ...  0.001896 -0.016280  0.067583   \n",
       "16582  0.034713 -0.035535 -0.002747  ...  0.022896 -0.032039  0.078839   \n",
       "16583  0.065997 -0.047527  0.046685  ...  0.012508 -0.023177  0.125806   \n",
       "16584  0.060282 -0.045505  0.039934  ...  0.017551 -0.020227  0.116980   \n",
       "\n",
       "            993       994       995       996       997       998       999  \n",
       "0      0.015133  0.053493 -0.043010 -0.077664 -0.087695 -0.067725 -0.025900  \n",
       "1      0.022329  0.038806 -0.035423 -0.078966 -0.080697 -0.058431 -0.013146  \n",
       "2      0.022271  0.090845 -0.016199 -0.052414 -0.061058 -0.065700 -0.024589  \n",
       "3      0.018266  0.037110 -0.072879 -0.107979 -0.118019 -0.091262 -0.039369  \n",
       "4      0.021078  0.038500 -0.037745 -0.074081 -0.082790 -0.056627 -0.011060  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "16580  0.048055  0.080539  0.008690 -0.043842 -0.029989 -0.040435  0.016206  \n",
       "16581  0.004285  0.082278 -0.008132 -0.047996 -0.053658 -0.034887  0.005656  \n",
       "16582  0.031743  0.087470  0.011023 -0.045950 -0.041572 -0.043497 -0.002814  \n",
       "16583  0.011815  0.086856 -0.027691 -0.058323 -0.072766 -0.063418 -0.030536  \n",
       "16584  0.014501  0.083159 -0.022958 -0.058766 -0.067539 -0.065302 -0.026357  \n",
       "\n",
       "[16585 rows x 1000 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_word2vec = pd.read_csv('../Datasets/train_review_word2vec.csv')\n",
    "dataset_word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16585, 1000), (16585,))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_word2vec.shape, dataset['oh_label'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v, X_test_w2v, y_train_w2v, y_test_w2v = train_test_split(dataset_word2vec, dataset['oh_label'], test_size=.33, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    7505\n",
       "1.0    3606\n",
       "Name: oh_label, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_w2v.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    3737\n",
       "1.0    1737\n",
       "Name: oh_label, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_w2v.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Priyesh Dave\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:15:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Time taken to fit the model with word2vec vectors: 108.34686231613159\n",
      "Training\n",
      "0.998289982899829\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      7505\n",
      "         1.0       1.00      1.00      1.00      3606\n",
      "\n",
      "    accuracy                           1.00     11111\n",
      "   macro avg       1.00      1.00      1.00     11111\n",
      "weighted avg       1.00      1.00      1.00     11111\n",
      "\n",
      "[[7501    4]\n",
      " [  15 3591]]\n",
      "==================================\n",
      "Test\n",
      "Accuracy Score:  0.7877237851662404\n",
      "AUC:  0.728986104043817\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.89      0.85      3737\n",
      "         1.0       0.71      0.57      0.63      1737\n",
      "\n",
      "    accuracy                           0.79      5474\n",
      "   macro avg       0.76      0.73      0.74      5474\n",
      "weighted avg       0.78      0.79      0.78      5474\n",
      "\n",
      "[[3325  412]\n",
      " [ 750  987]]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "#Import the DecisionTreeeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#Initialize the model\n",
    "MODEL_NAME = 'XGBClassifier'\n",
    "clf_decision_word2vec = XGBClassifier()\n",
    "\n",
    "start_time = time.time()\n",
    "# Fit the model\n",
    "clf_decision_word2vec.fit(X_train_w2v, y_train_w2v)\n",
    "print(\"Time taken to fit the model with word2vec vectors: \" + str(time.time() - start_time))\n",
    "\n",
    "\n",
    "train_pred_w2v = clf_decision_word2vec.predict(X_train_w2v)\n",
    "test_pred_w2v = clf_decision_word2vec.predict(X_test_w2v)\n",
    "\n",
    "\n",
    "print('Training')\n",
    "print(accuracy_score(y_train_w2v, train_pred_w2v))\n",
    "print(classification_report(y_train_w2v, train_pred_w2v))\n",
    "print(confusion_matrix(y_train_w2v, train_pred_w2v))\n",
    "\n",
    "print('==================================')\n",
    "\n",
    "print('Test')\n",
    "score = accuracy_score(y_test_w2v, test_pred_w2v)\n",
    "auc_score = roc_auc_score(y_test_w2v, test_pred_w2v)\n",
    "print('Accuracy Score: ', score)\n",
    "print('AUC: ', auc_score)\n",
    "print(classification_report(y_test_w2v, test_pred_w2v))\n",
    "print(confusion_matrix(y_test_w2v, test_pred_w2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Models/XGBClassifier_78.77_72.9.pkl']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(mnb, '../Models/{}_{}_{}.pkl'.format(MODEL_NAME, round(score*100, 2), round(auc_score*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Embedding, SpatialDropout1D, Dropout, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_w2v =  np.array(y_train_w2v).reshape(-1,1)\n",
    "y_test_w2v =  np.array(y_test_w2v).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11111, 1000), (5474, 1000), (11111, 1), (5474, 1))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_w2v.shape, X_test_w2v.shape, y_train_w2v.shape, y_test_w2v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v_lstm = np.array(X_train_w2v).reshape(-1, 1, vector_size)\n",
    "X_test_w2v_lstm  = np.array(X_test_w2v).reshape(-1, 1, vector_size)\n",
    "y_train_w2v_lstm = y_train_w2v.reshape(-1, 1, 1)\n",
    "y_test_w2v_lstm = y_test_w2v.reshape(-1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11111, 1, 1000), (5474, 1, 1000), (11111, 1, 1), (5474, 1, 1))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_w2v_lstm.shape, X_test_w2v_lstm.shape, y_train_w2v_lstm.shape, y_test_w2v_lstm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'W2V_LSTM'\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Bidirectional(LSTM(256, input_shape=(1, vector_size), kernel_initializer = 'he_uniform', activation = 'relu', return_sequences=True)))\n",
    "\n",
    "model.add(Bidirectional(LSTM(128, kernel_initializer = 'he_uniform', activation='relu')))\n",
    "\n",
    "model.add(Dense(1, kernel_initializer = 'glorot_uniform', activation='sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "44/44 [==============================] - 11s 91ms/step - loss: 0.6079 - accuracy: 0.6908 - val_loss: 0.5522 - val_accuracy: 0.7505\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.5358 - accuracy: 0.7522 - val_loss: 0.5311 - val_accuracy: 0.7539\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 3s 75ms/step - loss: 0.5235 - accuracy: 0.7570 - val_loss: 0.5138 - val_accuracy: 0.7618\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 3s 77ms/step - loss: 0.5148 - accuracy: 0.7611 - val_loss: 0.5085 - val_accuracy: 0.7642\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 3s 80ms/step - loss: 0.5094 - accuracy: 0.7630 - val_loss: 0.5119 - val_accuracy: 0.7640\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 3s 76ms/step - loss: 0.5073 - accuracy: 0.7673 - val_loss: 0.5029 - val_accuracy: 0.7665\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 3s 78ms/step - loss: 0.5020 - accuracy: 0.7656 - val_loss: 0.5012 - val_accuracy: 0.7682\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 3s 75ms/step - loss: 0.4992 - accuracy: 0.7690 - val_loss: 0.4954 - val_accuracy: 0.7693\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 3s 76ms/step - loss: 0.4950 - accuracy: 0.7708 - val_loss: 0.4907 - val_accuracy: 0.7711\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 3s 74ms/step - loss: 0.4917 - accuracy: 0.7731 - val_loss: 0.5032 - val_accuracy: 0.7594\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.4890 - accuracy: 0.7759 - val_loss: 0.4899 - val_accuracy: 0.7698\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 3s 75ms/step - loss: 0.4920 - accuracy: 0.7753 - val_loss: 0.5125 - val_accuracy: 0.7561\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 3s 71ms/step - loss: 0.4884 - accuracy: 0.7763 - val_loss: 0.4918 - val_accuracy: 0.7784\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 3s 76ms/step - loss: 0.4916 - accuracy: 0.7749 - val_loss: 0.4822 - val_accuracy: 0.7786\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 3s 79ms/step - loss: 0.4855 - accuracy: 0.7777 - val_loss: 0.4862 - val_accuracy: 0.7722\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 3s 75ms/step - loss: 0.4825 - accuracy: 0.7784 - val_loss: 0.4813 - val_accuracy: 0.7806\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 3s 78ms/step - loss: 0.4795 - accuracy: 0.7796 - val_loss: 0.4808 - val_accuracy: 0.7799\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 4s 85ms/step - loss: 0.4806 - accuracy: 0.7782 - val_loss: 0.4791 - val_accuracy: 0.7804\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 3s 79ms/step - loss: 0.4861 - accuracy: 0.7790 - val_loss: 0.4856 - val_accuracy: 0.7707\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 4s 80ms/step - loss: 0.4821 - accuracy: 0.7781 - val_loss: 0.4763 - val_accuracy: 0.7773\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 3s 80ms/step - loss: 0.4773 - accuracy: 0.7816 - val_loss: 0.4755 - val_accuracy: 0.7815\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 3s 77ms/step - loss: 0.4787 - accuracy: 0.7830 - val_loss: 0.4768 - val_accuracy: 0.7740\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 4s 81ms/step - loss: 0.4770 - accuracy: 0.7844 - val_loss: 0.4795 - val_accuracy: 0.7768\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 3s 79ms/step - loss: 0.4744 - accuracy: 0.7808 - val_loss: 0.4775 - val_accuracy: 0.7826\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 3s 77ms/step - loss: 0.4758 - accuracy: 0.7797 - val_loss: 0.4750 - val_accuracy: 0.7802\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 3s 76ms/step - loss: 0.4781 - accuracy: 0.7824 - val_loss: 0.4853 - val_accuracy: 0.7716\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 3s 76ms/step - loss: 0.4738 - accuracy: 0.7840 - val_loss: 0.4744 - val_accuracy: 0.7753\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 3s 75ms/step - loss: 0.4750 - accuracy: 0.7843 - val_loss: 0.4744 - val_accuracy: 0.7837\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 3s 77ms/step - loss: 0.4755 - accuracy: 0.7814 - val_loss: 0.4860 - val_accuracy: 0.7744\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 3s 78ms/step - loss: 0.4737 - accuracy: 0.7845 - val_loss: 0.4715 - val_accuracy: 0.7822\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 3s 79ms/step - loss: 0.4684 - accuracy: 0.7871 - val_loss: 0.4730 - val_accuracy: 0.7810\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 3s 75ms/step - loss: 0.4764 - accuracy: 0.7834 - val_loss: 0.4750 - val_accuracy: 0.7760\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 3s 77ms/step - loss: 0.4695 - accuracy: 0.7849 - val_loss: 0.4751 - val_accuracy: 0.7806\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 3s 75ms/step - loss: 0.4705 - accuracy: 0.7844 - val_loss: 0.4730 - val_accuracy: 0.7846\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 3s 76ms/step - loss: 0.4702 - accuracy: 0.7858 - val_loss: 0.4737 - val_accuracy: 0.7802\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 3s 74ms/step - loss: 0.4717 - accuracy: 0.7862 - val_loss: 0.4754 - val_accuracy: 0.7801\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 3s 74ms/step - loss: 0.4702 - accuracy: 0.7846 - val_loss: 0.4813 - val_accuracy: 0.7777\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 3s 73ms/step - loss: 0.4678 - accuracy: 0.7861 - val_loss: 0.4699 - val_accuracy: 0.7843\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 3s 72ms/step - loss: 0.4655 - accuracy: 0.7893 - val_loss: 0.4730 - val_accuracy: 0.7832\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 3s 79ms/step - loss: 0.4677 - accuracy: 0.7878 - val_loss: 0.4703 - val_accuracy: 0.7859\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 3s 75ms/step - loss: 0.4663 - accuracy: 0.7890 - val_loss: 0.4721 - val_accuracy: 0.7815\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 3s 74ms/step - loss: 0.4650 - accuracy: 0.7882 - val_loss: 0.4771 - val_accuracy: 0.7815\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 3s 79ms/step - loss: 0.4651 - accuracy: 0.7884 - val_loss: 0.4698 - val_accuracy: 0.7846\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 3s 75ms/step - loss: 0.4650 - accuracy: 0.7875 - val_loss: 0.4746 - val_accuracy: 0.7828\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 3s 78ms/step - loss: 0.4624 - accuracy: 0.7905 - val_loss: 0.4684 - val_accuracy: 0.7866\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 3s 75ms/step - loss: 0.4635 - accuracy: 0.7879 - val_loss: 0.4701 - val_accuracy: 0.7850\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 3s 74ms/step - loss: 0.4641 - accuracy: 0.7890 - val_loss: 0.4815 - val_accuracy: 0.7791\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 3s 75ms/step - loss: 0.4613 - accuracy: 0.7911 - val_loss: 0.4728 - val_accuracy: 0.7892\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 3s 75ms/step - loss: 0.4617 - accuracy: 0.7868 - val_loss: 0.4693 - val_accuracy: 0.7883\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 4s 82ms/step - loss: 0.4606 - accuracy: 0.7899 - val_loss: 0.4794 - val_accuracy: 0.7857\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 3s 76ms/step - loss: 0.4658 - accuracy: 0.7889 - val_loss: 0.4681 - val_accuracy: 0.7830\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 3s 77ms/step - loss: 0.4635 - accuracy: 0.7881 - val_loss: 0.4754 - val_accuracy: 0.7810\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 4s 85ms/step - loss: 0.4577 - accuracy: 0.7925 - val_loss: 0.4727 - val_accuracy: 0.7870\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 3s 75ms/step - loss: 0.4588 - accuracy: 0.7929 - val_loss: 0.4697 - val_accuracy: 0.7866\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 3s 76ms/step - loss: 0.4566 - accuracy: 0.7939 - val_loss: 0.4686 - val_accuracy: 0.7872\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 3s 80ms/step - loss: 0.4572 - accuracy: 0.7907 - val_loss: 0.4708 - val_accuracy: 0.7859\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 3s 79ms/step - loss: 0.4572 - accuracy: 0.7916 - val_loss: 0.4828 - val_accuracy: 0.7782\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 3s 77ms/step - loss: 0.4586 - accuracy: 0.7915 - val_loss: 0.4723 - val_accuracy: 0.7848\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 3s 79ms/step - loss: 0.4569 - accuracy: 0.7927 - val_loss: 0.4767 - val_accuracy: 0.7841\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 3s 79ms/step - loss: 0.4557 - accuracy: 0.7943 - val_loss: 0.4682 - val_accuracy: 0.7843\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 3s 78ms/step - loss: 0.4567 - accuracy: 0.7934 - val_loss: 0.4688 - val_accuracy: 0.7883\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 3s 75ms/step - loss: 0.4548 - accuracy: 0.7928 - val_loss: 0.4713 - val_accuracy: 0.7857\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 4s 86ms/step - loss: 0.4613 - accuracy: 0.7934 - val_loss: 0.4729 - val_accuracy: 0.7822\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 4s 81ms/step - loss: 0.4577 - accuracy: 0.7907 - val_loss: 0.4740 - val_accuracy: 0.7885\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 3s 78ms/step - loss: 0.4551 - accuracy: 0.7930 - val_loss: 0.4687 - val_accuracy: 0.7863\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 3s 76ms/step - loss: 0.4535 - accuracy: 0.7929 - val_loss: 0.4707 - val_accuracy: 0.7855\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 3s 76ms/step - loss: 0.4536 - accuracy: 0.7931 - val_loss: 0.4662 - val_accuracy: 0.7853\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 3s 74ms/step - loss: 0.4547 - accuracy: 0.7943 - val_loss: 0.4773 - val_accuracy: 0.7881\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 0.4550 - accuracy: 0.7947 - val_loss: 0.4759 - val_accuracy: 0.7833\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 3s 67ms/step - loss: 0.4520 - accuracy: 0.7939 - val_loss: 0.4701 - val_accuracy: 0.7850\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 0.4539 - accuracy: 0.7937 - val_loss: 0.4706 - val_accuracy: 0.7855\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 3s 64ms/step - loss: 0.4560 - accuracy: 0.7920 - val_loss: 0.4654 - val_accuracy: 0.7886\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 3s 62ms/step - loss: 0.4479 - accuracy: 0.7952 - val_loss: 0.4785 - val_accuracy: 0.7815\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 0.4498 - accuracy: 0.7988 - val_loss: 0.4672 - val_accuracy: 0.7908\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 0.4495 - accuracy: 0.7968 - val_loss: 0.4687 - val_accuracy: 0.7870\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 3s 58ms/step - loss: 0.4502 - accuracy: 0.7967 - val_loss: 0.4679 - val_accuracy: 0.7923\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 3s 64ms/step - loss: 0.4529 - accuracy: 0.7961 - val_loss: 0.4665 - val_accuracy: 0.7874\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 3s 64ms/step - loss: 0.4501 - accuracy: 0.7952 - val_loss: 0.4783 - val_accuracy: 0.7830\n",
      "Epoch 79/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 0.4521 - accuracy: 0.7950 - val_loss: 0.4699 - val_accuracy: 0.7906\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 0.4478 - accuracy: 0.7982 - val_loss: 0.4668 - val_accuracy: 0.7897\n",
      "Epoch 81/100\n",
      "44/44 [==============================] - 3s 59ms/step - loss: 0.4471 - accuracy: 0.7966 - val_loss: 0.4709 - val_accuracy: 0.7897\n",
      "Epoch 82/100\n",
      "44/44 [==============================] - 3s 59ms/step - loss: 0.4513 - accuracy: 0.7968 - val_loss: 0.4706 - val_accuracy: 0.7890\n",
      "Epoch 83/100\n",
      "44/44 [==============================] - 2s 57ms/step - loss: 0.4501 - accuracy: 0.7961 - val_loss: 0.4637 - val_accuracy: 0.7921\n",
      "Epoch 84/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 0.4464 - accuracy: 0.7996 - val_loss: 0.4690 - val_accuracy: 0.7874\n",
      "Epoch 85/100\n",
      "44/44 [==============================] - 3s 58ms/step - loss: 0.4481 - accuracy: 0.7979 - val_loss: 0.4699 - val_accuracy: 0.7885\n",
      "Epoch 86/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 0.4462 - accuracy: 0.7989 - val_loss: 0.4644 - val_accuracy: 0.7899\n",
      "Epoch 87/100\n",
      "44/44 [==============================] - 3s 63ms/step - loss: 0.4485 - accuracy: 0.7952 - val_loss: 0.4695 - val_accuracy: 0.7866\n",
      "Epoch 88/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 0.4472 - accuracy: 0.7945 - val_loss: 0.4681 - val_accuracy: 0.7885\n",
      "Epoch 89/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 0.4461 - accuracy: 0.7986 - val_loss: 0.4664 - val_accuracy: 0.7899\n",
      "Epoch 90/100\n",
      "44/44 [==============================] - 2s 57ms/step - loss: 0.4427 - accuracy: 0.8008 - val_loss: 0.4660 - val_accuracy: 0.7912\n",
      "Epoch 91/100\n",
      "44/44 [==============================] - 2s 54ms/step - loss: 0.4427 - accuracy: 0.8006 - val_loss: 0.4719 - val_accuracy: 0.7886\n",
      "Epoch 92/100\n",
      "44/44 [==============================] - 2s 55ms/step - loss: 0.4460 - accuracy: 0.7956 - val_loss: 0.4666 - val_accuracy: 0.7914\n",
      "Epoch 93/100\n",
      "44/44 [==============================] - 2s 53ms/step - loss: 0.4445 - accuracy: 0.7978 - val_loss: 0.4674 - val_accuracy: 0.7914\n",
      "Epoch 94/100\n",
      "44/44 [==============================] - 2s 55ms/step - loss: 0.4440 - accuracy: 0.7976 - val_loss: 0.4644 - val_accuracy: 0.7928\n",
      "Epoch 95/100\n",
      "44/44 [==============================] - 2s 56ms/step - loss: 0.4429 - accuracy: 0.7980 - val_loss: 0.4697 - val_accuracy: 0.7859\n",
      "Epoch 96/100\n",
      "44/44 [==============================] - 2s 56ms/step - loss: 0.4425 - accuracy: 0.8001 - val_loss: 0.4708 - val_accuracy: 0.7872\n",
      "Epoch 97/100\n",
      "44/44 [==============================] - 2s 57ms/step - loss: 0.4412 - accuracy: 0.8009 - val_loss: 0.4672 - val_accuracy: 0.7925\n",
      "Epoch 98/100\n",
      "44/44 [==============================] - 3s 58ms/step - loss: 0.4398 - accuracy: 0.8005 - val_loss: 0.4678 - val_accuracy: 0.7938\n",
      "Epoch 99/100\n",
      "44/44 [==============================] - 2s 54ms/step - loss: 0.4415 - accuracy: 0.8006 - val_loss: 0.4667 - val_accuracy: 0.7864\n",
      "Epoch 100/100\n",
      "44/44 [==============================] - 2s 55ms/step - loss: 0.4419 - accuracy: 0.8007 - val_loss: 0.4667 - val_accuracy: 0.7917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x221d1baf070>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_w2v_lstm, y_train_w2v_lstm, validation_data=(X_test_w2v_lstm, y_test_w2v_lstm), epochs=100, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 1, 512)           2574336   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 256)              656384    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,230,977\n",
      "Trainable params: 3,230,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "0.8028980289802898\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.93      0.86      7505\n",
      "         1.0       0.79      0.54      0.64      3606\n",
      "\n",
      "    accuracy                           0.80     11111\n",
      "   macro avg       0.80      0.73      0.75     11111\n",
      "weighted avg       0.80      0.80      0.79     11111\n",
      "\n",
      "[[6985  520]\n",
      " [1670 1936]]\n",
      "==================================\n",
      "Test\n",
      "Accuracy Score:  0.7917427840701498\n",
      "AUC:  0.7202214269879587\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.92      0.86      3737\n",
      "         1.0       0.74      0.52      0.62      1737\n",
      "\n",
      "    accuracy                           0.79      5474\n",
      "   macro avg       0.77      0.72      0.74      5474\n",
      "weighted avg       0.79      0.79      0.78      5474\n",
      "\n",
      "[[3423  314]\n",
      " [ 826  911]]\n"
     ]
    }
   ],
   "source": [
    "train_pred_w2v = model.predict(X_train_w2v_lstm)\n",
    "train_pred_w2v = (train_pred_w2v > 0.5)\n",
    "train_pred_w2v\n",
    "\n",
    "test_pred_w2v = model.predict(X_test_w2v_lstm)\n",
    "test_pred_w2v = (test_pred_w2v > 0.5)\n",
    "test_pred_w2v\n",
    "\n",
    "print('Training')\n",
    "print(accuracy_score(y_train_w2v, train_pred_w2v))\n",
    "print(classification_report(y_train_w2v, train_pred_w2v))\n",
    "print(confusion_matrix(y_train_w2v, train_pred_w2v))\n",
    "\n",
    "print('==================================')\n",
    "\n",
    "print('Test')\n",
    "score = accuracy_score(y_test_w2v, test_pred_w2v)\n",
    "auc_score = roc_auc_score(y_test_w2v, test_pred_w2v)\n",
    "print('Accuracy Score: ', score)\n",
    "print('AUC: ', auc_score)\n",
    "print(classification_report(y_test_w2v, test_pred_w2v))\n",
    "print(confusion_matrix(y_test_w2v, test_pred_w2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://f2ad12b0-e618-4620-bd81-68de4c9e0d52/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x00000221CEFFBAC0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x00000221CE4F0D00> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x00000221D1B0F310> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x00000221D1B16040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../Models/W2V_LSTM_79.17_72.02.pkl']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, '../Models/{}_{}_{}.pkl'.format(MODEL_NAME, round(score*100, 2), round(auc_score*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>oh_label</th>\n",
       "      <th>Cleaned Text</th>\n",
       "      <th>Length</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Word2Vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@halalflaws @biebervalue @greenlinerzjm I read...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>read context no change meaning history islamic...</td>\n",
       "      <td>54</td>\n",
       "      <td>[read, context, no, change, meaning, history, ...</td>\n",
       "      <td>[0.1391722, -0.015404301, 0.057572592, 0.11904...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ShreyaBafna3 Now you idiots claim that people...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>idiot claim people tried stop becoming terrori...</td>\n",
       "      <td>86</td>\n",
       "      <td>[idiot, claim, people, tried, stop, becoming, ...</td>\n",
       "      <td>[0.12530968, -0.006700354, 0.058066975, 0.1041...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @Mooseoftorment Call me sexist, but when I ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rt call sexist go auto place rather talk guy</td>\n",
       "      <td>44</td>\n",
       "      <td>[rt, call, sexist, go, auto, place, rather, ta...</td>\n",
       "      <td>[0.13381705, -0.013543546, 0.08076621, 0.11225...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@g0ssipsquirrelx Wrong, ISIS follows the examp...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>wrong isi follows example mohammed quran exactly</td>\n",
       "      <td>48</td>\n",
       "      <td>[wrong, isi, follows, example, mohammed, quran...</td>\n",
       "      <td>[0.14474444, -0.010601993, 0.02713455, 0.13810...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @TRobinsonNewEra: http://t.co/nkkCbpcHEo Sa...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rt saudi preacher raped tortured five year old...</td>\n",
       "      <td>70</td>\n",
       "      <td>[rt, saudi, preacher, raped, tortured, five, y...</td>\n",
       "      <td>[0.12063544, -0.021805331, 0.05576928, 0.09215...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  oh_label  \\\n",
       "0  @halalflaws @biebervalue @greenlinerzjm I read...       0.0   \n",
       "1  @ShreyaBafna3 Now you idiots claim that people...       0.0   \n",
       "2  RT @Mooseoftorment Call me sexist, but when I ...       1.0   \n",
       "3  @g0ssipsquirrelx Wrong, ISIS follows the examp...       1.0   \n",
       "4  RT @TRobinsonNewEra: http://t.co/nkkCbpcHEo Sa...       0.0   \n",
       "\n",
       "                                        Cleaned Text  Length  \\\n",
       "0  read context no change meaning history islamic...      54   \n",
       "1  idiot claim people tried stop becoming terrori...      86   \n",
       "2       rt call sexist go auto place rather talk guy      44   \n",
       "3   wrong isi follows example mohammed quran exactly      48   \n",
       "4  rt saudi preacher raped tortured five year old...      70   \n",
       "\n",
       "                                              Tokens  \\\n",
       "0  [read, context, no, change, meaning, history, ...   \n",
       "1  [idiot, claim, people, tried, stop, becoming, ...   \n",
       "2  [rt, call, sexist, go, auto, place, rather, ta...   \n",
       "3  [wrong, isi, follows, example, mohammed, quran...   \n",
       "4  [rt, saudi, preacher, raped, tortured, five, y...   \n",
       "\n",
       "                                            Word2Vec  \n",
       "0  [0.1391722, -0.015404301, 0.057572592, 0.11904...  \n",
       "1  [0.12530968, -0.006700354, 0.058066975, 0.1041...  \n",
       "2  [0.13381705, -0.013543546, 0.08076621, 0.11225...  \n",
       "3  [0.14474444, -0.010601993, 0.02713455, 0.13810...  \n",
       "4  [0.12063544, -0.021805331, 0.05576928, 0.09215...  "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting what is the highest count of words in any sentence\n",
    "max_count = max([len(arr) for arr in dataset['Tokens']])\n",
    "max_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_size = 16000\n",
    "sent_length = 25\n",
    "embedding_vector_features = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot representation of words\n",
    "onehot_repr=[one_hot(sentence,voc_size) for sentence in dataset['Cleaned Text']] \n",
    "#onehot_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     0     0 ...  4007  7654  1264]\n",
      " [    0     0     0 ...  4630 14956 15369]\n",
      " [    0     0     0 ...  4910  3373  6823]\n",
      " ...\n",
      " [    0     0     0 ... 11542    29  7372]\n",
      " [    0     0     0 ...  3373 15169  5548]\n",
      " [    0     0     0 ... 13274  7437  4457]]\n"
     ]
    }
   ],
   "source": [
    "# Embedding the sentences\n",
    "embedded_docs = pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
    "print(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16585, 25)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_docs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "#     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "#     possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "#     predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "#     precision = true_positives / (predicted_positives + K.epsilon())\n",
    "#     recall = true_positives / (possible_positives + K.epsilon())\n",
    "#     f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "#     return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Bidirectional(LSTM(200, kernel_initializer  = 'he_uniform', return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(100, kernel_initializer  = 'he_uniform')))\n",
    "\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_callbacks = [\n",
    "    EarlyStopping(patience=2),\n",
    "    ModelCheckpoint(filepath='../LSTM/Callbacks 3/model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    TensorBoard(log_dir='../LSTM/logs'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_LSTM = np.array(embedded_docs)\n",
    "y_LSTM = np.array(dataset['oh_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16585, 25), (16585,))"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_LSTM.shape, y_LSTM.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lstm, X_test_lstm, y_train_lstm, y_test_lstm = train_test_split(X_LSTM, y_LSTM, test_size=.33, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "44/44 [==============================] - 44s 838ms/step - loss: 0.5391 - accuracy: 0.7396 - val_loss: 0.4341 - val_accuracy: 0.8100\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 40s 901ms/step - loss: 0.3350 - accuracy: 0.8636 - val_loss: 0.4200 - val_accuracy: 0.8140\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 42s 960ms/step - loss: 0.2451 - accuracy: 0.9040 - val_loss: 0.4929 - val_accuracy: 0.8138\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 39s 902ms/step - loss: 0.1791 - accuracy: 0.9334 - val_loss: 0.5334 - val_accuracy: 0.7972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x222f0944d60>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_lstm, y_train_lstm, validation_data=(X_test_lstm, y_test_lstm), epochs=100, batch_size=256, callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking best model for the callbacks\n",
    "model = tensorflow.keras.models.load_model('../LSTM/Callbacks 3/model.02-0.42.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       ...,\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred_lstm = model.predict(X_train_lstm)\n",
    "train_pred_lstm = (train_pred_lstm > 0.5)\n",
    "train_pred_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       ...,\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_lstm = model.predict(X_test_lstm)\n",
    "test_pred_lstm = (test_pred_lstm > 0.5)\n",
    "test_pred_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.916119161191612"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train_lstm, train_pred_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8140299598100109"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_lstm, test_pred_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>oh_label</th>\n",
       "      <th>Cleaned Text</th>\n",
       "      <th>Length</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Word2Vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@halalflaws @biebervalue @greenlinerzjm I read...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>read context no change meaning history islamic...</td>\n",
       "      <td>54</td>\n",
       "      <td>[read, context, no, change, meaning, history, ...</td>\n",
       "      <td>[0.1391722, -0.015404301, 0.057572592, 0.11904...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ShreyaBafna3 Now you idiots claim that people...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>idiot claim people tried stop becoming terrori...</td>\n",
       "      <td>86</td>\n",
       "      <td>[idiot, claim, people, tried, stop, becoming, ...</td>\n",
       "      <td>[0.12530968, -0.006700354, 0.058066975, 0.1041...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @Mooseoftorment Call me sexist, but when I ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rt call sexist go auto place rather talk guy</td>\n",
       "      <td>44</td>\n",
       "      <td>[rt, call, sexist, go, auto, place, rather, ta...</td>\n",
       "      <td>[0.13381705, -0.013543546, 0.08076621, 0.11225...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@g0ssipsquirrelx Wrong, ISIS follows the examp...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>wrong isi follows example mohammed quran exactly</td>\n",
       "      <td>48</td>\n",
       "      <td>[wrong, isi, follows, example, mohammed, quran...</td>\n",
       "      <td>[0.14474444, -0.010601993, 0.02713455, 0.13810...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @TRobinsonNewEra: http://t.co/nkkCbpcHEo Sa...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rt saudi preacher raped tortured five year old...</td>\n",
       "      <td>70</td>\n",
       "      <td>[rt, saudi, preacher, raped, tortured, five, y...</td>\n",
       "      <td>[0.12063544, -0.021805331, 0.05576928, 0.09215...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  oh_label  \\\n",
       "0  @halalflaws @biebervalue @greenlinerzjm I read...       0.0   \n",
       "1  @ShreyaBafna3 Now you idiots claim that people...       0.0   \n",
       "2  RT @Mooseoftorment Call me sexist, but when I ...       1.0   \n",
       "3  @g0ssipsquirrelx Wrong, ISIS follows the examp...       1.0   \n",
       "4  RT @TRobinsonNewEra: http://t.co/nkkCbpcHEo Sa...       0.0   \n",
       "\n",
       "                                        Cleaned Text  Length  \\\n",
       "0  read context no change meaning history islamic...      54   \n",
       "1  idiot claim people tried stop becoming terrori...      86   \n",
       "2       rt call sexist go auto place rather talk guy      44   \n",
       "3   wrong isi follows example mohammed quran exactly      48   \n",
       "4  rt saudi preacher raped tortured five year old...      70   \n",
       "\n",
       "                                              Tokens  \\\n",
       "0  [read, context, no, change, meaning, history, ...   \n",
       "1  [idiot, claim, people, tried, stop, becoming, ...   \n",
       "2  [rt, call, sexist, go, auto, place, rather, ta...   \n",
       "3  [wrong, isi, follows, example, mohammed, quran...   \n",
       "4  [rt, saudi, preacher, raped, tortured, five, y...   \n",
       "\n",
       "                                            Word2Vec  \n",
       "0  [0.1391722, -0.015404301, 0.057572592, 0.11904...  \n",
       "1  [0.12530968, -0.006700354, 0.058066975, 0.1041...  \n",
       "2  [0.13381705, -0.013543546, 0.08076621, 0.11225...  \n",
       "3  [0.14474444, -0.010601993, 0.02713455, 0.13810...  \n",
       "4  [0.12063544, -0.021805331, 0.05576928, 0.09215...  "
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet:  .@comattwow @JustLaurenB Not doubting. Think feminist hypocrisy on Ladies Nights is a great example of their hypocrisy. Putting it out there\n",
      "True Value:  Toxic\n",
      "Predicted Value:  Toxic\n"
     ]
    }
   ],
   "source": [
    "randomNumber = np.random.randint(0, X_LSTM.shape[0]+1)\n",
    "\n",
    "data = X_LSTM[randomNumber].reshape(1,-1)\n",
    "\n",
    "true_value = y_LSTM[randomNumber]\n",
    "\n",
    "pred_value = model.predict(data)\n",
    "pred_value = (pred_value > 0.5)\n",
    "\n",
    "tweet = dataset['Text'][randomNumber]\n",
    "\n",
    "mapper = {0 : 'Not Toxic', 1 : 'Toxic'}\n",
    "\n",
    "print('Tweet: ', tweet)\n",
    "print('True Value: ', mapper[int(true_value)])\n",
    "print('Predicted Value: ', mapper[int(pred_value[0][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_embedding(sentence):\n",
    "\n",
    "  # One hot representation of words\n",
    "  onehot_repr = [one_hot(sentence,voc_size)] \n",
    "\n",
    "  # Embedding the sentences\n",
    "  embedded_docs = pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
    "  return embedded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(sentence):\n",
    "  sentence = cleanData(sentence)\n",
    "  data_lstm = word_embedding(sentence)\n",
    "\n",
    "  prediction = model.predict(data_lstm)\n",
    "  prediction = (prediction >= 0.5)\n",
    "  mapper = {False: 'Not Toxic', True:'Toxic'}\n",
    "  return mapper[prediction[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Toxic'"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predictions('.@comattwow @JustLaurenB Not doubting. Think feminist hypocrisy on Ladies Nights is a great example of their hypocrisy. Putting it out there')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e147b052be5536a019399d7281fa07f9aa68d0dfdf21ead313763d9c98e78705"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
