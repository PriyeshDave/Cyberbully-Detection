{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from textblob import TextBlob\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../Datasets/Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Annotation</th>\n",
       "      <th>oh_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.74948705591165E+017</td>\n",
       "      <td>5.74948705591165E+017</td>\n",
       "      <td>@halalflaws @biebervalue @greenlinerzjm I read...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.71917888690393E+017</td>\n",
       "      <td>5.71917888690393E+017</td>\n",
       "      <td>@ShreyaBafna3 Now you idiots claim that people...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.90255841338601E+017</td>\n",
       "      <td>3.90255841338601E+017</td>\n",
       "      <td>RT @Mooseoftorment Call me sexist, but when I ...</td>\n",
       "      <td>sexism</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.68208850655916E+017</td>\n",
       "      <td>5.68208850655916E+017</td>\n",
       "      <td>@g0ssipsquirrelx Wrong, ISIS follows the examp...</td>\n",
       "      <td>racism</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.75596338802373E+017</td>\n",
       "      <td>5.75596338802373E+017</td>\n",
       "      <td>#mkr No No No No No No</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16846</th>\n",
       "      <td>5.75606766236475E+017</td>\n",
       "      <td>5.75606766236475E+017</td>\n",
       "      <td>Feeling so sorry for the girls, they should be...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16847</th>\n",
       "      <td>5.72333822886326E+017</td>\n",
       "      <td>5.72333822886326E+017</td>\n",
       "      <td>#MKR 'pretty good dishes we're happy with' - O...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16848</th>\n",
       "      <td>5.72326950057845E+017</td>\n",
       "      <td>5.72326950057845E+017</td>\n",
       "      <td>RT @colonelkickhead: Deconstructed lemon tart!...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16849</th>\n",
       "      <td>5.74799612642357E+017</td>\n",
       "      <td>5.74799612642357E+017</td>\n",
       "      <td>@versacezaynx @nyazpolitics @greenlinerzjm You...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16850</th>\n",
       "      <td>5.68826121153684E+017</td>\n",
       "      <td>5.68826121153684E+017</td>\n",
       "      <td>And before you protest that you're *not* mad, ...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16851 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       index                     id  \\\n",
       "0      5.74948705591165E+017  5.74948705591165E+017   \n",
       "1      5.71917888690393E+017  5.71917888690393E+017   \n",
       "2      3.90255841338601E+017  3.90255841338601E+017   \n",
       "3      5.68208850655916E+017  5.68208850655916E+017   \n",
       "4      5.75596338802373E+017  5.75596338802373E+017   \n",
       "...                      ...                    ...   \n",
       "16846  5.75606766236475E+017  5.75606766236475E+017   \n",
       "16847  5.72333822886326E+017  5.72333822886326E+017   \n",
       "16848  5.72326950057845E+017  5.72326950057845E+017   \n",
       "16849  5.74799612642357E+017  5.74799612642357E+017   \n",
       "16850  5.68826121153684E+017  5.68826121153684E+017   \n",
       "\n",
       "                                                    Text Annotation  oh_label  \n",
       "0      @halalflaws @biebervalue @greenlinerzjm I read...       none       0.0  \n",
       "1      @ShreyaBafna3 Now you idiots claim that people...       none       0.0  \n",
       "2      RT @Mooseoftorment Call me sexist, but when I ...     sexism       1.0  \n",
       "3      @g0ssipsquirrelx Wrong, ISIS follows the examp...     racism       1.0  \n",
       "4                                 #mkr No No No No No No       none       0.0  \n",
       "...                                                  ...        ...       ...  \n",
       "16846  Feeling so sorry for the girls, they should be...       none       0.0  \n",
       "16847  #MKR 'pretty good dishes we're happy with' - O...       none       0.0  \n",
       "16848  RT @colonelkickhead: Deconstructed lemon tart!...       none       0.0  \n",
       "16849  @versacezaynx @nyazpolitics @greenlinerzjm You...       none       0.0  \n",
       "16850  And before you protest that you're *not* mad, ...       none       0.0  \n",
       "\n",
       "[16851 rows x 5 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    11501\n",
       "1.0     5347\n",
       "Name: oh_label, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['oh_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Annotation</th>\n",
       "      <th>oh_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@halalflaws @biebervalue @greenlinerzjm I read...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ShreyaBafna3 Now you idiots claim that people...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @Mooseoftorment Call me sexist, but when I ...</td>\n",
       "      <td>sexism</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@g0ssipsquirrelx Wrong, ISIS follows the examp...</td>\n",
       "      <td>racism</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#mkr No No No No No No</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16846</th>\n",
       "      <td>Feeling so sorry for the girls, they should be...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16847</th>\n",
       "      <td>#MKR 'pretty good dishes we're happy with' - O...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16848</th>\n",
       "      <td>RT @colonelkickhead: Deconstructed lemon tart!...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16849</th>\n",
       "      <td>@versacezaynx @nyazpolitics @greenlinerzjm You...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16850</th>\n",
       "      <td>And before you protest that you're *not* mad, ...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16851 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text Annotation  oh_label\n",
       "0      @halalflaws @biebervalue @greenlinerzjm I read...       none       0.0\n",
       "1      @ShreyaBafna3 Now you idiots claim that people...       none       0.0\n",
       "2      RT @Mooseoftorment Call me sexist, but when I ...     sexism       1.0\n",
       "3      @g0ssipsquirrelx Wrong, ISIS follows the examp...     racism       1.0\n",
       "4                                 #mkr No No No No No No       none       0.0\n",
       "...                                                  ...        ...       ...\n",
       "16846  Feeling so sorry for the girls, they should be...       none       0.0\n",
       "16847  #MKR 'pretty good dishes we're happy with' - O...       none       0.0\n",
       "16848  RT @colonelkickhead: Deconstructed lemon tart!...       none       0.0\n",
       "16849  @versacezaynx @nyazpolitics @greenlinerzjm You...       none       0.0\n",
       "16850  And before you protest that you're *not* mad, ...       none       0.0\n",
       "\n",
       "[16851 rows x 3 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset[['Text','Annotation', 'oh_label']]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "none      11501\n",
       "sexism     3377\n",
       "racism     1970\n",
       "Name: Annotation, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Annotation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Priyesh Dave\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:4901: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.drop('Annotation', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text        1\n",
       "oh_label    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Priyesh Dave\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>oh_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@halalflaws @biebervalue @greenlinerzjm I read...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ShreyaBafna3 Now you idiots claim that people...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @Mooseoftorment Call me sexist, but when I ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@g0ssipsquirrelx Wrong, ISIS follows the examp...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#mkr No No No No No No</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  oh_label\n",
       "0  @halalflaws @biebervalue @greenlinerzjm I read...       0.0\n",
       "1  @ShreyaBafna3 Now you idiots claim that people...       0.0\n",
       "2  RT @Mooseoftorment Call me sexist, but when I ...       1.0\n",
       "3  @g0ssipsquirrelx Wrong, ISIS follows the examp...       1.0\n",
       "4                             #mkr No No No No No No       0.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@halalflaws @biebervalue @greenlinerzjm I read them in context.No change in meaning. The history of Islamic slavery. https://t.co/xWJzpSodGj'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.loc[0]['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeTags(sentence):\n",
    "  return ' '.join([word for word in sentence.split(' ') if not word.__contains__('@')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanData(sentence):\n",
    "  sentence = str(sentence)\n",
    "  sentence = sentence.lower()\n",
    "\n",
    "  # Removing @tags from sentences\n",
    "  sentence = removeTags(sentence)\n",
    "\n",
    "  # Removing twitter handles urls\n",
    "  sentence = ' '.join([word if not word.__contains__('https:') else '' for word in sentence.split(' ')])\n",
    "\n",
    "  # Removing twitter handles urls\n",
    "  sentence = ' '.join([word if not word.__contains__('http:') else '' for word in sentence.split(' ')])\n",
    "\n",
    "  # Removing #MKR from tweets\n",
    "  sentence = ' '.join([word if not word.__contains__('#mkr') else '' for word in sentence.split(' ')])\n",
    "\n",
    "  # Removing stopwords and lemmatizing \n",
    "  sentence = ' '.join([lm.lemmatize(word) for word in sentence.split(' ') if not word in sw])\n",
    "  \n",
    "  #Removing special characters\n",
    "  sentence = re.sub(\"[^a-z ]\", \" \", sentence)\n",
    "\n",
    "  # Removing single characters\n",
    "  sentence = ' '.join([word if not len(word) == 1 else '' for word in sentence.split(' ')])\n",
    "\n",
    "  # Removing extra spaces\n",
    "  sentence = re.sub(\" +\", \" \", sentence)\n",
    "\n",
    "  return sentence.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Models/Lemmatizer.pkl']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(lm, '../Models/Lemmatizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Priyesh Dave\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset['Cleaned Text'] = dataset['Text'].apply(cleanData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>oh_label</th>\n",
       "      <th>Cleaned Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@halalflaws @biebervalue @greenlinerzjm I read...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>read context no change meaning history islamic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ShreyaBafna3 Now you idiots claim that people...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>idiot claim people tried stop becoming terrori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @Mooseoftorment Call me sexist, but when I ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rt call sexist go auto place rather talk guy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@g0ssipsquirrelx Wrong, ISIS follows the examp...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>wrong isi follows example mohammed quran exactly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#mkr No No No No No No</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16846</th>\n",
       "      <td>Feeling so sorry for the girls, they should be...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>feeling sorry girls safe kat andre going home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16847</th>\n",
       "      <td>#MKR 'pretty good dishes we're happy with' - O...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pretty good dish we re happy with ok well neve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16848</th>\n",
       "      <td>RT @colonelkickhead: Deconstructed lemon tart!...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rt deconstructed lemon tart can please go one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16849</th>\n",
       "      <td>@versacezaynx @nyazpolitics @greenlinerzjm You...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stupid talk to blocked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16850</th>\n",
       "      <td>And before you protest that you're *not* mad, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>protest not mad there much reason tweeting wom...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16848 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  oh_label  \\\n",
       "0      @halalflaws @biebervalue @greenlinerzjm I read...       0.0   \n",
       "1      @ShreyaBafna3 Now you idiots claim that people...       0.0   \n",
       "2      RT @Mooseoftorment Call me sexist, but when I ...       1.0   \n",
       "3      @g0ssipsquirrelx Wrong, ISIS follows the examp...       1.0   \n",
       "4                                 #mkr No No No No No No       0.0   \n",
       "...                                                  ...       ...   \n",
       "16846  Feeling so sorry for the girls, they should be...       0.0   \n",
       "16847  #MKR 'pretty good dishes we're happy with' - O...       0.0   \n",
       "16848  RT @colonelkickhead: Deconstructed lemon tart!...       0.0   \n",
       "16849  @versacezaynx @nyazpolitics @greenlinerzjm You...       0.0   \n",
       "16850  And before you protest that you're *not* mad, ...       0.0   \n",
       "\n",
       "                                            Cleaned Text  \n",
       "0      read context no change meaning history islamic...  \n",
       "1      idiot claim people tried stop becoming terrori...  \n",
       "2           rt call sexist go auto place rather talk guy  \n",
       "3       wrong isi follows example mohammed quran exactly  \n",
       "4                                                         \n",
       "...                                                  ...  \n",
       "16846      feeling sorry girls safe kat andre going home  \n",
       "16847  pretty good dish we re happy with ok well neve...  \n",
       "16848  rt deconstructed lemon tart can please go one ...  \n",
       "16849                             stupid talk to blocked  \n",
       "16850  protest not mad there much reason tweeting wom...  \n",
       "\n",
       "[16848 rows x 3 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text            0\n",
       "oh_label        0\n",
       "Cleaned Text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get length of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Priyesh Dave\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset['Length'] = [len(sentence) for sentence in dataset['Cleaned Text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>oh_label</th>\n",
       "      <th>Cleaned Text</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@halalflaws @biebervalue @greenlinerzjm I read...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>read context no change meaning history islamic...</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ShreyaBafna3 Now you idiots claim that people...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>idiot claim people tried stop becoming terrori...</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @Mooseoftorment Call me sexist, but when I ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rt call sexist go auto place rather talk guy</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@g0ssipsquirrelx Wrong, ISIS follows the examp...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>wrong isi follows example mohammed quran exactly</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#mkr No No No No No No</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16846</th>\n",
       "      <td>Feeling so sorry for the girls, they should be...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>feeling sorry girls safe kat andre going home</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16847</th>\n",
       "      <td>#MKR 'pretty good dishes we're happy with' - O...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pretty good dish we re happy with ok well neve...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16848</th>\n",
       "      <td>RT @colonelkickhead: Deconstructed lemon tart!...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rt deconstructed lemon tart can please go one ...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16849</th>\n",
       "      <td>@versacezaynx @nyazpolitics @greenlinerzjm You...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stupid talk to blocked</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16850</th>\n",
       "      <td>And before you protest that you're *not* mad, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>protest not mad there much reason tweeting wom...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16848 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  oh_label  \\\n",
       "0      @halalflaws @biebervalue @greenlinerzjm I read...       0.0   \n",
       "1      @ShreyaBafna3 Now you idiots claim that people...       0.0   \n",
       "2      RT @Mooseoftorment Call me sexist, but when I ...       1.0   \n",
       "3      @g0ssipsquirrelx Wrong, ISIS follows the examp...       1.0   \n",
       "4                                 #mkr No No No No No No       0.0   \n",
       "...                                                  ...       ...   \n",
       "16846  Feeling so sorry for the girls, they should be...       0.0   \n",
       "16847  #MKR 'pretty good dishes we're happy with' - O...       0.0   \n",
       "16848  RT @colonelkickhead: Deconstructed lemon tart!...       0.0   \n",
       "16849  @versacezaynx @nyazpolitics @greenlinerzjm You...       0.0   \n",
       "16850  And before you protest that you're *not* mad, ...       0.0   \n",
       "\n",
       "                                            Cleaned Text  Length  \n",
       "0      read context no change meaning history islamic...      54  \n",
       "1      idiot claim people tried stop becoming terrori...      86  \n",
       "2           rt call sexist go auto place rather talk guy      44  \n",
       "3       wrong isi follows example mohammed quran exactly      48  \n",
       "4                                                              0  \n",
       "...                                                  ...     ...  \n",
       "16846      feeling sorry girls safe kat andre going home      45  \n",
       "16847  pretty good dish we re happy with ok well neve...      60  \n",
       "16848  rt deconstructed lemon tart can please go one ...     100  \n",
       "16849                             stupid talk to blocked      22  \n",
       "16850  protest not mad there much reason tweeting wom...      57  \n",
       "\n",
       "[16848 rows x 4 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>oh_label</th>\n",
       "      <th>Cleaned Text</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#mkr No No No No No No</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>@JillWetzler I ❤️ u</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>@dankmtl @PeaceNotHate_ http://t.co/HxgNJvWoqG</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>@Assiye61 http://t.co/dduX3ZbMtE</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>@98Halima @BilalIGhumman @johnnygjokaj @cdnKha...</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16576</th>\n",
       "      <td>@olaoliv http://t.co/6PmFc7kdYh</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16719</th>\n",
       "      <td>@iAmCaticorn @CherguiaMbark http://t.co/igBq14...</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16771</th>\n",
       "      <td>@ROJNAME_english http://t.co/Ej5MsCentH</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16778</th>\n",
       "      <td>@98Halima @BilalIGhumman @johnnygjokaj @cdnKha...</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16813</th>\n",
       "      <td>@randi_ebooks @desertfox899 what</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>263 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  oh_label  \\\n",
       "4                                 #mkr No No No No No No       0.0   \n",
       "149                                  @JillWetzler I ❤️ u       0.0   \n",
       "179       @dankmtl @PeaceNotHate_ http://t.co/HxgNJvWoqG       0.0   \n",
       "211                     @Assiye61 http://t.co/dduX3ZbMtE       0.0   \n",
       "240    @98Halima @BilalIGhumman @johnnygjokaj @cdnKha...       0.0   \n",
       "...                                                  ...       ...   \n",
       "16576                    @olaoliv http://t.co/6PmFc7kdYh       0.0   \n",
       "16719  @iAmCaticorn @CherguiaMbark http://t.co/igBq14...       0.0   \n",
       "16771            @ROJNAME_english http://t.co/Ej5MsCentH       0.0   \n",
       "16778  @98Halima @BilalIGhumman @johnnygjokaj @cdnKha...       0.0   \n",
       "16813                   @randi_ebooks @desertfox899 what       0.0   \n",
       "\n",
       "      Cleaned Text  Length  \n",
       "4                        0  \n",
       "149                      0  \n",
       "179                      0  \n",
       "211                      0  \n",
       "240                      0  \n",
       "...            ...     ...  \n",
       "16576                    0  \n",
       "16719                    0  \n",
       "16771                    0  \n",
       "16778                    0  \n",
       "16813                    0  \n",
       "\n",
       "[263 rows x 4 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After cleaning the text some cleaned text has no words so will have to remove those records\n",
    "dataset[dataset['Length'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_words_index = dataset[dataset['Length'] == 0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Priyesh Dave\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:4901: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.drop(zero_words_index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>oh_label</th>\n",
       "      <th>Cleaned Text</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@halalflaws @biebervalue @greenlinerzjm I read...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>read context no change meaning history islamic...</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ShreyaBafna3 Now you idiots claim that people...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>idiot claim people tried stop becoming terrori...</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @Mooseoftorment Call me sexist, but when I ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rt call sexist go auto place rather talk guy</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@g0ssipsquirrelx Wrong, ISIS follows the examp...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>wrong isi follows example mohammed quran exactly</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RT @TRobinsonNewEra: http://t.co/nkkCbpcHEo Sa...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rt saudi preacher raped tortured five year old...</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16846</th>\n",
       "      <td>Feeling so sorry for the girls, they should be...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>feeling sorry girls safe kat andre going home</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16847</th>\n",
       "      <td>#MKR 'pretty good dishes we're happy with' - O...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pretty good dish we re happy with ok well neve...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16848</th>\n",
       "      <td>RT @colonelkickhead: Deconstructed lemon tart!...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rt deconstructed lemon tart can please go one ...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16849</th>\n",
       "      <td>@versacezaynx @nyazpolitics @greenlinerzjm You...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stupid talk to blocked</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16850</th>\n",
       "      <td>And before you protest that you're *not* mad, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>protest not mad there much reason tweeting wom...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16585 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  oh_label  \\\n",
       "0      @halalflaws @biebervalue @greenlinerzjm I read...       0.0   \n",
       "1      @ShreyaBafna3 Now you idiots claim that people...       0.0   \n",
       "2      RT @Mooseoftorment Call me sexist, but when I ...       1.0   \n",
       "3      @g0ssipsquirrelx Wrong, ISIS follows the examp...       1.0   \n",
       "5      RT @TRobinsonNewEra: http://t.co/nkkCbpcHEo Sa...       0.0   \n",
       "...                                                  ...       ...   \n",
       "16846  Feeling so sorry for the girls, they should be...       0.0   \n",
       "16847  #MKR 'pretty good dishes we're happy with' - O...       0.0   \n",
       "16848  RT @colonelkickhead: Deconstructed lemon tart!...       0.0   \n",
       "16849  @versacezaynx @nyazpolitics @greenlinerzjm You...       0.0   \n",
       "16850  And before you protest that you're *not* mad, ...       0.0   \n",
       "\n",
       "                                            Cleaned Text  Length  \n",
       "0      read context no change meaning history islamic...      54  \n",
       "1      idiot claim people tried stop becoming terrori...      86  \n",
       "2           rt call sexist go auto place rather talk guy      44  \n",
       "3       wrong isi follows example mohammed quran exactly      48  \n",
       "5      rt saudi preacher raped tortured five year old...      70  \n",
       "...                                                  ...     ...  \n",
       "16846      feeling sorry girls safe kat andre going home      45  \n",
       "16847  pretty good dish we re happy with ok well neve...      60  \n",
       "16848  rt deconstructed lemon tart can please go one ...     100  \n",
       "16849                             stupid talk to blocked      22  \n",
       "16850  protest not mad there much reason tweeting wom...      57  \n",
       "\n",
       "[16585 rows x 4 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Priyesh Dave\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:4901: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>oh_label</th>\n",
       "      <th>Cleaned Text</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@halalflaws @biebervalue @greenlinerzjm I read...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>read context no change meaning history islamic...</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ShreyaBafna3 Now you idiots claim that people...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>idiot claim people tried stop becoming terrori...</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @Mooseoftorment Call me sexist, but when I ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rt call sexist go auto place rather talk guy</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@g0ssipsquirrelx Wrong, ISIS follows the examp...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>wrong isi follows example mohammed quran exactly</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @TRobinsonNewEra: http://t.co/nkkCbpcHEo Sa...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rt saudi preacher raped tortured five year old...</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16580</th>\n",
       "      <td>Feeling so sorry for the girls, they should be...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>feeling sorry girls safe kat andre going home</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16581</th>\n",
       "      <td>#MKR 'pretty good dishes we're happy with' - O...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pretty good dish we re happy with ok well neve...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16582</th>\n",
       "      <td>RT @colonelkickhead: Deconstructed lemon tart!...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rt deconstructed lemon tart can please go one ...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16583</th>\n",
       "      <td>@versacezaynx @nyazpolitics @greenlinerzjm You...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stupid talk to blocked</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16584</th>\n",
       "      <td>And before you protest that you're *not* mad, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>protest not mad there much reason tweeting wom...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16585 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  oh_label  \\\n",
       "0      @halalflaws @biebervalue @greenlinerzjm I read...       0.0   \n",
       "1      @ShreyaBafna3 Now you idiots claim that people...       0.0   \n",
       "2      RT @Mooseoftorment Call me sexist, but when I ...       1.0   \n",
       "3      @g0ssipsquirrelx Wrong, ISIS follows the examp...       1.0   \n",
       "4      RT @TRobinsonNewEra: http://t.co/nkkCbpcHEo Sa...       0.0   \n",
       "...                                                  ...       ...   \n",
       "16580  Feeling so sorry for the girls, they should be...       0.0   \n",
       "16581  #MKR 'pretty good dishes we're happy with' - O...       0.0   \n",
       "16582  RT @colonelkickhead: Deconstructed lemon tart!...       0.0   \n",
       "16583  @versacezaynx @nyazpolitics @greenlinerzjm You...       0.0   \n",
       "16584  And before you protest that you're *not* mad, ...       0.0   \n",
       "\n",
       "                                            Cleaned Text  Length  \n",
       "0      read context no change meaning history islamic...      54  \n",
       "1      idiot claim people tried stop becoming terrori...      86  \n",
       "2           rt call sexist go auto place rather talk guy      44  \n",
       "3       wrong isi follows example mohammed quran exactly      48  \n",
       "4      rt saudi preacher raped tortured five year old...      70  \n",
       "...                                                  ...     ...  \n",
       "16580      feeling sorry girls safe kat andre going home      45  \n",
       "16581  pretty good dish we re happy with ok well neve...      60  \n",
       "16582  rt deconstructed lemon tart can please go one ...     100  \n",
       "16583                             stupid talk to blocked      22  \n",
       "16584  protest not mad there much reason tweeting wom...      57  \n",
       "\n",
       "[16585 rows x 4 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.reset_index(inplace=True)\n",
    "dataset.drop('index', axis=1, inplace=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordDict = dict()\n",
    "wordsList = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getwordsCount(sentence):\n",
    "  wordsList = sentence.split(' ')\n",
    "  for word in wordsList:\n",
    "    wordDict[word] = wordDict.get(word, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        None\n",
       "1        None\n",
       "2        None\n",
       "3        None\n",
       "4        None\n",
       "         ... \n",
       "16580    None\n",
       "16581    None\n",
       "16582    None\n",
       "16583    None\n",
       "16584    None\n",
       "Name: Cleaned Text, Length: 16585, dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Cleaned Text'].apply(getwordsCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedDict = dict(sorted(wordDict.items(), key = lambda x: x[1], reverse=True))\n",
    "#sortedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rt</th>\n",
       "      <td>3683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kat</th>\n",
       "      <td>1103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sexist</th>\n",
       "      <td>1097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woman</th>\n",
       "      <td>992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>islam</th>\n",
       "      <td>924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people</th>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>muslim</th>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get</th>\n",
       "      <td>694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amp</th>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>think</th>\n",
       "      <td>575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>andre</th>\n",
       "      <td>548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would</th>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>girl</th>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>know</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go</th>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>want</th>\n",
       "      <td>454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make</th>\n",
       "      <td>452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>can</th>\n",
       "      <td>448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>really</th>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>men</th>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>say</th>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>see</th>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>going</th>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>look</th>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>need</th>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ve</th>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thing</th>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>even</th>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isi</th>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>call</th>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oh</th>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>never</th>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>way</th>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hate</th>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>still</th>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>well</th>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>women</th>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>back</th>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuck</th>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>re</th>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Count\n",
       "Word         \n",
       "rt       3683\n",
       "kat      1103\n",
       "sexist   1097\n",
       "like     1024\n",
       "woman     992\n",
       "islam     924\n",
       "people    708\n",
       "muslim    701\n",
       "get       694\n",
       "amp       691\n",
       "one       664\n",
       "think     575\n",
       "andre     548\n",
       "it        523\n",
       "would     512\n",
       "girl      504\n",
       "know      500\n",
       "that      496\n",
       "go        468\n",
       "want      454\n",
       "make      452\n",
       "time      452\n",
       "can       448\n",
       "really    400\n",
       "good      399\n",
       "men       384\n",
       "say       373\n",
       "see       365\n",
       "going     358\n",
       "look      358\n",
       "need      352\n",
       "ve        328\n",
       "right     327\n",
       "thing     327\n",
       "even      312\n",
       "isi       308\n",
       "call      303\n",
       "oh        302\n",
       "you       300\n",
       "never     292\n",
       "female    288\n",
       "way       281\n",
       "hate      281\n",
       "still     275\n",
       "well      259\n",
       "no        258\n",
       "women     246\n",
       "back      245\n",
       "fuck      243\n",
       "re        243"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsCount = pd.DataFrame(sortedDict.values(), index=sortedDict.keys(), columns=['Count'])\n",
    "wordsCount.index.name = 'Word'\n",
    "wordsCount.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "Count=%{x}<br>Word=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "h",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": [
          243,
          243,
          245,
          246,
          258,
          259,
          275,
          281,
          281,
          288,
          292,
          300,
          302,
          303,
          308,
          312,
          327,
          327,
          328,
          352,
          358,
          358,
          365,
          373,
          384,
          399,
          400,
          448,
          452,
          452,
          454,
          468,
          496,
          500,
          504,
          512,
          523,
          548,
          575,
          664,
          691,
          694,
          701,
          708,
          924,
          992,
          1024,
          1097,
          1103,
          3683
         ],
         "xaxis": "x",
         "y": [
          "re",
          "fuck",
          "back",
          "women",
          "no",
          "well",
          "still",
          "hate",
          "way",
          "female",
          "never",
          "you",
          "oh",
          "call",
          "isi",
          "even",
          "thing",
          "right",
          "ve",
          "need",
          "look",
          "going",
          "see",
          "say",
          "men",
          "good",
          "really",
          "can",
          "time",
          "make",
          "want",
          "go",
          "that",
          "know",
          "girl",
          "would",
          "it",
          "andre",
          "think",
          "one",
          "amp",
          "get",
          "muslim",
          "people",
          "islam",
          "woman",
          "like",
          "sexist",
          "kat",
          "rt"
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "height": 1000,
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Most common words"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Count"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Word"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "px.bar(data_frame = wordsCount.head(50).sort_values(by='Count', ascending=True), x='Count', height=1000, title='Most common words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Length of Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1bf8bec8b20>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(dataset['Length'], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>oh_label</th>\n",
       "      <th>Cleaned Text</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@halalflaws @biebervalue @greenlinerzjm I read...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>read context no change meaning history islamic...</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ShreyaBafna3 Now you idiots claim that people...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>idiot claim people tried stop becoming terrori...</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @Mooseoftorment Call me sexist, but when I ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rt call sexist go auto place rather talk guy</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@g0ssipsquirrelx Wrong, ISIS follows the examp...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>wrong isi follows example mohammed quran exactly</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @TRobinsonNewEra: http://t.co/nkkCbpcHEo Sa...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rt saudi preacher raped tortured five year old...</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16580</th>\n",
       "      <td>Feeling so sorry for the girls, they should be...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>feeling sorry girls safe kat andre going home</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16581</th>\n",
       "      <td>#MKR 'pretty good dishes we're happy with' - O...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pretty good dish we re happy with ok well neve...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16582</th>\n",
       "      <td>RT @colonelkickhead: Deconstructed lemon tart!...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rt deconstructed lemon tart can please go one ...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16583</th>\n",
       "      <td>@versacezaynx @nyazpolitics @greenlinerzjm You...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stupid talk to blocked</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16584</th>\n",
       "      <td>And before you protest that you're *not* mad, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>protest not mad there much reason tweeting wom...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16585 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  oh_label  \\\n",
       "0      @halalflaws @biebervalue @greenlinerzjm I read...       0.0   \n",
       "1      @ShreyaBafna3 Now you idiots claim that people...       0.0   \n",
       "2      RT @Mooseoftorment Call me sexist, but when I ...       1.0   \n",
       "3      @g0ssipsquirrelx Wrong, ISIS follows the examp...       1.0   \n",
       "4      RT @TRobinsonNewEra: http://t.co/nkkCbpcHEo Sa...       0.0   \n",
       "...                                                  ...       ...   \n",
       "16580  Feeling so sorry for the girls, they should be...       0.0   \n",
       "16581  #MKR 'pretty good dishes we're happy with' - O...       0.0   \n",
       "16582  RT @colonelkickhead: Deconstructed lemon tart!...       0.0   \n",
       "16583  @versacezaynx @nyazpolitics @greenlinerzjm You...       0.0   \n",
       "16584  And before you protest that you're *not* mad, ...       0.0   \n",
       "\n",
       "                                            Cleaned Text  Length  \n",
       "0      read context no change meaning history islamic...      54  \n",
       "1      idiot claim people tried stop becoming terrori...      86  \n",
       "2           rt call sexist go auto place rather talk guy      44  \n",
       "3       wrong isi follows example mohammed quran exactly      48  \n",
       "4      rt saudi preacher raped tortured five year old...      70  \n",
       "...                                                  ...     ...  \n",
       "16580      feeling sorry girls safe kat andre going home      45  \n",
       "16581  pretty good dish we re happy with ok well neve...      60  \n",
       "16582  rt deconstructed lemon tart can please go one ...     100  \n",
       "16583                             stupid talk to blocked      22  \n",
       "16584  protest not mad there much reason tweeting wom...      57  \n",
       "\n",
       "[16585 rows x 4 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>onscreen</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>definitive</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ruling</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sherry</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cocktail</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frikin</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nina</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gratitude</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ancestor</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wankers</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reallyaone</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>harrypotter</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lookalike</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faruq</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wome</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fava</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aggressor</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>titles</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unborn</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hopped</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enthusiastic</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subconsciously</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>norah</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vincent</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restrict</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unbridled</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>failures</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>philharmonic</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toward</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whitefeminists</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anidifranco</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>donor</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sioa</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unsw</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>potty</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workout</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ceeeeeeeebs</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mcculloch</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indicting</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>darrenwilson</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delaying</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reb</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hoover</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>connections</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumors</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overdramatic</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apocalypse</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>myaunt</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>casters</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yesss</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>protestors</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mn</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shutitdown</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>icantbreathe</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angle</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labours</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pacify</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>having</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mykitchenmistake</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Count\n",
       "Word                   \n",
       "onscreen              1\n",
       "definitive            1\n",
       "ruling                1\n",
       "sherry                1\n",
       "cocktail              1\n",
       "frikin                1\n",
       "nina                  1\n",
       "gratitude             1\n",
       "ancestor              1\n",
       "wankers               1\n",
       "reallyaone            1\n",
       "harrypotter           1\n",
       "lookalike             1\n",
       "faruq                 1\n",
       "wome                  1\n",
       "fava                  1\n",
       "aggressor             1\n",
       "titles                1\n",
       "unborn                1\n",
       "hopped                1\n",
       "enthusiastic          1\n",
       "subconsciously        1\n",
       "norah                 1\n",
       "vincent               1\n",
       "restrict              1\n",
       "unbridled             1\n",
       "failures              1\n",
       "philharmonic          1\n",
       "toward                1\n",
       "whitefeminists        1\n",
       "anidifranco           1\n",
       "donor                 1\n",
       "sioa                  1\n",
       "unsw                  1\n",
       "potty                 1\n",
       "workout               1\n",
       "ceeeeeeeebs           1\n",
       "mcculloch             1\n",
       "indicting             1\n",
       "darrenwilson          1\n",
       "delaying              1\n",
       "reb                   1\n",
       "hoover                1\n",
       "connections           1\n",
       "rumors                1\n",
       "overdramatic          1\n",
       "feat                  1\n",
       "apocalypse            1\n",
       "myaunt                1\n",
       "casters               1\n",
       "yesss                 1\n",
       "protestors            1\n",
       "mn                    1\n",
       "shutitdown            1\n",
       "icantbreathe          1\n",
       "angle                 1\n",
       "labours               1\n",
       "pacify                1\n",
       "having                1\n",
       "mykitchenmistake      1"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsCount.tail(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing & Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative_df = dataset[dataset['oh_label'] == 0 ].sample(5300)\n",
    "# positive_df = dataset[dataset['oh_label'] == 1 ].sample(5300)\n",
    "\n",
    "# dataset = pd.concat([negative_df, positive_df], axis=0)\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16585, 15258)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tfidf.fit_transform(dataset['Cleaned Text']).toarray()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve, auc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, dataset['oh_label'], test_size=.33, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    7505\n",
       "1.0    3606\n",
       "Name: oh_label, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    3737\n",
       "1.0    1737\n",
       "Name: oh_label, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Accuracy Score:  0.8515885158851588\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.98      0.90      7505\n",
      "         1.0       0.94      0.58      0.72      3606\n",
      "\n",
      "    accuracy                           0.85     11111\n",
      "   macro avg       0.89      0.78      0.81     11111\n",
      "weighted avg       0.87      0.85      0.84     11111\n",
      "\n",
      "[[7382  123]\n",
      " [1526 2080]]\n",
      "==================================\n",
      "Test\n",
      "Accuracy Score:  0.7849835586408477\n",
      "AUC:  0.6841517298347957\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.96      0.86      3737\n",
      "         1.0       0.83      0.41      0.55      1737\n",
      "\n",
      "    accuracy                           0.78      5474\n",
      "   macro avg       0.80      0.68      0.70      5474\n",
      "weighted avg       0.79      0.78      0.76      5474\n",
      "\n",
      "[[3588  149]\n",
      " [1028  709]]\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'MultinomialNaiveBayes'\n",
    "mnb.fit(X_train, y_train)\n",
    "\n",
    "train_pred = mnb.predict(X_train)\n",
    "test_pred = mnb.predict(X_test)\n",
    "\n",
    "\n",
    "print('Training')\n",
    "print('Accuracy Score: ',accuracy_score(y_train, train_pred))\n",
    "print(classification_report(y_train, train_pred))\n",
    "print(confusion_matrix(y_train, train_pred))\n",
    "\n",
    "print('==================================')\n",
    "\n",
    "print('Test')\n",
    "score = accuracy_score(y_test, test_pred)\n",
    "auc_score = roc_auc_score(y_test, test_pred)\n",
    "print('Accuracy Score: ',score)\n",
    "print('AUC: ', auc_score)\n",
    "print(classification_report(y_test, test_pred))\n",
    "print(confusion_matrix(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Models/MultinomialNaiveBayes_78.5_68.42.pkl']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(mnb, '../Models/{}_{}_{}.pkl'.format(MODEL_NAME, round(score*100, 2), round(auc_score*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding (Word2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>oh_label</th>\n",
       "      <th>Cleaned Text</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@halalflaws @biebervalue @greenlinerzjm I read...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>read context no change meaning history islamic...</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ShreyaBafna3 Now you idiots claim that people...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>idiot claim people tried stop becoming terrori...</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @Mooseoftorment Call me sexist, but when I ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rt call sexist go auto place rather talk guy</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@g0ssipsquirrelx Wrong, ISIS follows the examp...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>wrong isi follows example mohammed quran exactly</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @TRobinsonNewEra: http://t.co/nkkCbpcHEo Sa...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rt saudi preacher raped tortured five year old...</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16580</th>\n",
       "      <td>Feeling so sorry for the girls, they should be...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>feeling sorry girls safe kat andre going home</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16581</th>\n",
       "      <td>#MKR 'pretty good dishes we're happy with' - O...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pretty good dish we re happy with ok well neve...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16582</th>\n",
       "      <td>RT @colonelkickhead: Deconstructed lemon tart!...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rt deconstructed lemon tart can please go one ...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16583</th>\n",
       "      <td>@versacezaynx @nyazpolitics @greenlinerzjm You...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stupid talk to blocked</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16584</th>\n",
       "      <td>And before you protest that you're *not* mad, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>protest not mad there much reason tweeting wom...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16585 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  oh_label  \\\n",
       "0      @halalflaws @biebervalue @greenlinerzjm I read...       0.0   \n",
       "1      @ShreyaBafna3 Now you idiots claim that people...       0.0   \n",
       "2      RT @Mooseoftorment Call me sexist, but when I ...       1.0   \n",
       "3      @g0ssipsquirrelx Wrong, ISIS follows the examp...       1.0   \n",
       "4      RT @TRobinsonNewEra: http://t.co/nkkCbpcHEo Sa...       0.0   \n",
       "...                                                  ...       ...   \n",
       "16580  Feeling so sorry for the girls, they should be...       0.0   \n",
       "16581  #MKR 'pretty good dishes we're happy with' - O...       0.0   \n",
       "16582  RT @colonelkickhead: Deconstructed lemon tart!...       0.0   \n",
       "16583  @versacezaynx @nyazpolitics @greenlinerzjm You...       0.0   \n",
       "16584  And before you protest that you're *not* mad, ...       0.0   \n",
       "\n",
       "                                            Cleaned Text  Length  \n",
       "0      read context no change meaning history islamic...      54  \n",
       "1      idiot claim people tried stop becoming terrori...      86  \n",
       "2           rt call sexist go auto place rather talk guy      44  \n",
       "3       wrong isi follows example mohammed quran exactly      48  \n",
       "4      rt saudi preacher raped tortured five year old...      70  \n",
       "...                                                  ...     ...  \n",
       "16580      feeling sorry girls safe kat andre going home      45  \n",
       "16581  pretty good dish we re happy with ok well neve...      60  \n",
       "16582  rt deconstructed lemon tart can please go one ...     100  \n",
       "16583                             stupid talk to blocked      22  \n",
       "16584  protest not mad there much reason tweeting wom...      57  \n",
       "\n",
       "[16585 rows x 4 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Priyesh Dave\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset['Tokens'] = [simple_preprocess(sentence) for sentence in dataset['Cleaned Text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>oh_label</th>\n",
       "      <th>Cleaned Text</th>\n",
       "      <th>Length</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@halalflaws @biebervalue @greenlinerzjm I read...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>read context no change meaning history islamic...</td>\n",
       "      <td>54</td>\n",
       "      <td>[read, context, no, change, meaning, history, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ShreyaBafna3 Now you idiots claim that people...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>idiot claim people tried stop becoming terrori...</td>\n",
       "      <td>86</td>\n",
       "      <td>[idiot, claim, people, tried, stop, becoming, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @Mooseoftorment Call me sexist, but when I ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rt call sexist go auto place rather talk guy</td>\n",
       "      <td>44</td>\n",
       "      <td>[rt, call, sexist, go, auto, place, rather, ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@g0ssipsquirrelx Wrong, ISIS follows the examp...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>wrong isi follows example mohammed quran exactly</td>\n",
       "      <td>48</td>\n",
       "      <td>[wrong, isi, follows, example, mohammed, quran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @TRobinsonNewEra: http://t.co/nkkCbpcHEo Sa...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rt saudi preacher raped tortured five year old...</td>\n",
       "      <td>70</td>\n",
       "      <td>[rt, saudi, preacher, raped, tortured, five, y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  oh_label  \\\n",
       "0  @halalflaws @biebervalue @greenlinerzjm I read...       0.0   \n",
       "1  @ShreyaBafna3 Now you idiots claim that people...       0.0   \n",
       "2  RT @Mooseoftorment Call me sexist, but when I ...       1.0   \n",
       "3  @g0ssipsquirrelx Wrong, ISIS follows the examp...       1.0   \n",
       "4  RT @TRobinsonNewEra: http://t.co/nkkCbpcHEo Sa...       0.0   \n",
       "\n",
       "                                        Cleaned Text  Length  \\\n",
       "0  read context no change meaning history islamic...      54   \n",
       "1  idiot claim people tried stop becoming terrori...      86   \n",
       "2       rt call sexist go auto place rather talk guy      44   \n",
       "3   wrong isi follows example mohammed quran exactly      48   \n",
       "4  rt saudi preacher raped tortured five year old...      70   \n",
       "\n",
       "                                              Tokens  \n",
       "0  [read, context, no, change, meaning, history, ...  \n",
       "1  [idiot, claim, people, tried, stop, becoming, ...  \n",
       "2  [rt, call, sexist, go, auto, place, rather, ta...  \n",
       "3  [wrong, isi, follows, example, mohammed, quran...  \n",
       "4  [rt, saudi, preacher, raped, tortured, five, y...  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_size = 1000\n",
    "word2vec_model = Word2Vec(dataset['Tokens'], min_count=1, window=10, vector_size=vector_size, workers=8, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.30963966e-01, -9.75819025e-03,  5.69641627e-02,  1.20901883e-01,\n",
       "        1.76030938e-02,  3.64487991e-02,  7.83597529e-02,  1.41248941e-01,\n",
       "       -4.77247275e-02,  5.65520450e-02,  6.77472651e-02,  1.79874636e-02,\n",
       "       -4.98278812e-02,  3.39959413e-02,  6.83978647e-02, -2.33743973e-02,\n",
       "       -7.79297426e-02, -2.35521868e-02,  8.00683051e-02, -1.35564849e-01,\n",
       "        4.36036848e-02, -4.86501008e-02, -3.10863797e-02, -2.93551479e-02,\n",
       "        4.64467891e-02,  3.03897355e-03,  6.22686669e-02, -2.27365345e-02,\n",
       "       -1.81819573e-01,  7.64057264e-02,  1.12932593e-01, -2.76209731e-02,\n",
       "        1.28352121e-02, -8.30943733e-02,  5.48604280e-02, -6.18271753e-02,\n",
       "        3.67418677e-02, -6.15375955e-03,  8.99724010e-03, -1.01030454e-01,\n",
       "        2.88877101e-03, -4.59263567e-03, -6.16813302e-02,  1.45220533e-01,\n",
       "       -5.04558198e-02, -2.22578249e-03, -5.97444512e-02,  1.27496704e-01,\n",
       "       -4.97086681e-02,  5.74112982e-02, -2.31278166e-02,  1.71526440e-03,\n",
       "        1.74140017e-02, -9.25583094e-02,  9.22289863e-02,  1.13495560e-02,\n",
       "        1.01392820e-01,  5.60660623e-02, -4.84260097e-02, -1.52646508e-02,\n",
       "       -1.34278476e-01,  5.14286906e-02, -1.13805734e-01, -3.79559286e-02,\n",
       "        1.13773830e-02,  4.84164804e-02,  5.02118915e-02,  1.56719923e-01,\n",
       "        2.78835036e-02, -1.89379696e-02,  2.95145251e-02, -5.34730628e-02,\n",
       "        5.74184582e-02, -6.29255548e-02,  8.13021734e-02, -2.65410580e-02,\n",
       "       -4.78653796e-02,  1.50765460e-02,  4.96579427e-03,  2.81310808e-02,\n",
       "       -5.03953621e-02,  6.25708699e-02, -1.64724484e-01,  7.89995939e-02,\n",
       "       -1.52209237e-01,  4.25447486e-02, -5.56862578e-02, -2.41775513e-02,\n",
       "        2.41369680e-02,  5.85269667e-02, -3.81344371e-03,  2.13791151e-02,\n",
       "       -2.13926807e-02,  1.04149982e-01,  1.38334647e-01,  7.28937164e-02,\n",
       "        9.43081751e-02, -8.59886408e-02,  5.86855151e-02,  2.43500881e-02,\n",
       "       -3.26781347e-02,  6.43847063e-02,  3.94956060e-02,  2.25243587e-02,\n",
       "       -2.40325686e-02,  3.26010436e-02, -3.16731557e-02,  3.90786082e-02,\n",
       "        1.21435570e-02, -6.00683466e-02, -4.56816927e-02, -9.41010714e-02,\n",
       "        2.55564004e-02,  7.25847259e-02,  4.11702134e-03,  3.39569263e-02,\n",
       "        4.20117006e-02, -3.48847322e-02,  9.03890133e-02, -9.30230841e-02,\n",
       "       -2.42125187e-02, -6.93328120e-03,  1.02666341e-01, -3.99875529e-02,\n",
       "        1.15956143e-02,  5.63856922e-02, -9.75639671e-02,  8.08540881e-02,\n",
       "        6.42070360e-03,  8.27903226e-02,  4.06426825e-02,  5.37098944e-03,\n",
       "        2.77376827e-02, -3.01196259e-02,  8.02159961e-03, -7.32706045e-04,\n",
       "       -7.64657976e-03,  1.53035820e-02, -8.77749473e-02, -7.22033083e-02,\n",
       "        6.13368377e-02, -3.79853696e-02, -8.56918022e-02, -3.58128063e-02,\n",
       "        5.07463627e-02,  1.84221670e-03,  3.23011130e-02,  7.23059997e-02,\n",
       "        2.67676320e-02, -1.45553658e-02,  4.40307334e-02, -5.47999777e-02,\n",
       "       -2.15576012e-02,  1.04706489e-01, -1.92283437e-01,  2.20833216e-02,\n",
       "        8.06809068e-02,  2.67069060e-02, -3.84152448e-03, -1.10006174e-02,\n",
       "        1.00247346e-01,  6.12525903e-02, -6.21756092e-02, -9.61765498e-02,\n",
       "       -6.53406680e-02,  6.89361468e-02,  7.26491138e-02,  2.53466759e-02,\n",
       "        8.36759359e-02,  1.09531760e-01,  1.04859464e-01,  1.15344025e-01,\n",
       "       -1.14859631e-02, -6.14661053e-02, -2.22761650e-02, -1.25942472e-02,\n",
       "       -9.92423594e-02,  5.26747014e-03, -1.73253473e-02,  6.09804839e-02,\n",
       "        7.55273998e-02,  1.28089432e-02,  5.46734668e-02,  1.01440631e-01,\n",
       "       -5.69922710e-03,  3.91736105e-02,  4.53059971e-02,  6.46715686e-02,\n",
       "        2.87465211e-02, -1.26850768e-03,  1.32388890e-01, -1.27707168e-01,\n",
       "        3.51127684e-02, -6.68948740e-02,  1.09746218e-01,  8.32714140e-02,\n",
       "        5.06944545e-02, -3.12890820e-02,  5.46211116e-02,  3.86158787e-02,\n",
       "       -2.66284798e-03,  2.40420029e-02,  4.60146926e-02,  5.23639061e-02,\n",
       "       -1.45257823e-02, -1.56098017e-02, -8.22721347e-02,  1.87494960e-02,\n",
       "       -2.23783404e-02, -3.27208750e-02,  4.58059413e-03,  1.99036654e-02,\n",
       "       -2.50371452e-02, -5.86645864e-02,  1.23196878e-04, -1.54555947e-01,\n",
       "       -1.87721439e-02,  9.31599643e-03, -1.50292516e-01, -5.47639132e-02,\n",
       "        8.58472660e-02,  6.09080084e-02,  5.58032803e-02,  2.90354714e-02,\n",
       "       -1.60456579e-02, -4.07988094e-02,  9.70650986e-02,  1.31679680e-02,\n",
       "        7.62110949e-02, -1.40988622e-02, -9.96580347e-03, -8.90012532e-02,\n",
       "        1.53701782e-01,  1.93207210e-03, -2.24501863e-02,  1.25975730e-02,\n",
       "        4.90383469e-02, -9.44542438e-02,  4.53176163e-02, -2.23837700e-02,\n",
       "       -5.39668277e-02, -2.95182131e-02, -6.43931553e-02,  4.64266874e-02,\n",
       "        2.21716780e-02,  3.68921235e-02,  3.49785648e-02,  1.32975886e-02,\n",
       "       -1.74290338e-03, -1.62343942e-02,  5.48058599e-02, -4.11386266e-02,\n",
       "       -2.28775181e-02, -3.52391154e-02, -6.09809160e-02, -1.41605665e-03,\n",
       "        8.97620618e-02,  1.12050362e-02, -8.44584182e-02, -2.98315864e-02,\n",
       "       -9.48080868e-02, -6.70151412e-03, -4.37256359e-02, -2.47909706e-02,\n",
       "       -1.37306005e-02,  4.24102582e-02, -5.62089980e-02,  1.68892786e-01,\n",
       "       -1.45473540e-01,  9.46785510e-02,  1.36683462e-02,  7.34522007e-03,\n",
       "        1.83257796e-02,  1.04518905e-01, -1.02707401e-01,  5.12433574e-02,\n",
       "        5.79654286e-03, -1.11477703e-01, -1.03345871e-01,  1.06907278e-01,\n",
       "        3.83894071e-02,  6.69806525e-02, -4.01295535e-02, -4.51606363e-02,\n",
       "        6.09278083e-02, -3.29689756e-02, -4.24638344e-03, -5.98155260e-02,\n",
       "        3.48463887e-03,  9.31420848e-02, -7.65719414e-02,  6.81510940e-02,\n",
       "        2.48527750e-02,  1.16422661e-01,  6.34471849e-02, -4.40538824e-02,\n",
       "        7.19960257e-02, -5.57679869e-02,  4.88773128e-03, -2.75160689e-02,\n",
       "       -6.43365011e-02,  1.51750287e-02,  5.52602522e-02, -2.41890922e-02,\n",
       "       -7.04539474e-03, -6.21598661e-02,  1.56651363e-02,  4.84060459e-02,\n",
       "        6.56774715e-02, -7.94016793e-02,  1.01357757e-03, -8.64116475e-02,\n",
       "       -6.41991720e-02,  1.02939848e-02,  3.11885588e-02,  3.34192562e-04,\n",
       "       -1.39787607e-02, -1.75738279e-02, -4.61174808e-02, -5.95155768e-02,\n",
       "       -4.91153169e-03,  9.10352245e-02,  3.86683047e-02,  2.99944868e-03,\n",
       "       -5.37428521e-02, -1.01092458e-01, -3.98534648e-02, -4.55441587e-02,\n",
       "       -7.62637099e-03,  6.83151360e-04,  3.93766463e-02,  1.54671799e-02,\n",
       "       -8.34479183e-02, -1.12192314e-02, -2.17027050e-02, -9.41015780e-02,\n",
       "        6.13654777e-03, -2.03402247e-02, -2.71417312e-02, -7.65216500e-02,\n",
       "        1.05160736e-01, -8.40542000e-03, -6.02287911e-02, -5.53862080e-02,\n",
       "       -5.60128428e-02,  6.47925436e-02, -2.02008203e-01,  1.06916158e-02,\n",
       "       -1.87340211e-02, -6.92100357e-03, -8.60372633e-02, -9.53995995e-03,\n",
       "       -9.15310085e-02,  1.12399802e-01,  3.90223088e-03,  1.06672764e-01,\n",
       "       -1.52271204e-02, -6.09204732e-02,  9.85608101e-02, -5.84848784e-02,\n",
       "       -4.63885590e-02,  9.75549296e-02, -8.77930149e-02, -3.91411558e-02,\n",
       "        8.24523903e-03, -6.72226474e-02,  8.03736150e-02, -3.29279304e-02,\n",
       "       -7.41337761e-02, -1.19076455e-02, -8.41688216e-02, -7.74623826e-02,\n",
       "       -3.21612991e-02, -1.17370570e-02, -4.83258329e-02,  4.64134403e-02,\n",
       "        5.72988875e-02,  6.70694048e-03,  3.84434499e-02,  3.61953937e-02,\n",
       "        4.82083298e-02,  8.97861868e-02, -2.26594741e-03,  4.15773131e-02,\n",
       "       -4.49282676e-02,  7.62260845e-03,  4.68378104e-02,  9.09935497e-03,\n",
       "        9.15222690e-02,  1.69338919e-02, -2.73167659e-02, -1.62891626e-01,\n",
       "        1.49035659e-02, -7.30681568e-02,  3.71222720e-02,  3.39616672e-04,\n",
       "        4.12574969e-02,  7.67358914e-02, -4.55797929e-03, -1.52869122e-02,\n",
       "        4.46661375e-02,  3.84917855e-02, -2.08823998e-02, -6.62093014e-02,\n",
       "        8.55579376e-02, -3.96423414e-02,  1.33120418e-02,  8.84890035e-02,\n",
       "        1.45347686e-02,  5.93209490e-02, -3.70885469e-02, -4.41405922e-02,\n",
       "       -5.61744161e-02, -5.81255183e-02, -1.08368043e-02, -2.93166433e-02,\n",
       "       -1.82925593e-02, -5.94589673e-03,  6.41417056e-02, -9.77001488e-02,\n",
       "       -3.55418660e-02, -1.31752297e-01, -5.72698861e-02,  2.40502562e-02,\n",
       "       -5.98786436e-02, -8.46976414e-02, -2.90076695e-02,  9.20756683e-02,\n",
       "       -9.16299596e-02,  3.60398553e-02, -4.07086611e-02,  3.00329272e-02,\n",
       "        1.01563502e-02, -2.80740298e-02,  5.18607795e-02,  2.88031995e-02,\n",
       "        1.46527477e-02,  8.19779709e-02, -1.72798932e-02,  5.37228920e-02,\n",
       "        9.84326005e-02,  7.87471829e-04,  4.20841277e-02, -7.84916151e-03,\n",
       "        1.91846192e-01,  3.64298671e-02,  2.45662685e-02, -3.56802419e-02,\n",
       "        8.44223499e-02, -6.40405575e-03,  5.47425114e-02, -5.14716841e-02,\n",
       "       -7.22557455e-02, -1.50497153e-01, -2.39346717e-02, -4.91422415e-02,\n",
       "        2.81255285e-04, -5.20603023e-02,  1.43250600e-01, -4.53720950e-02,\n",
       "       -4.39970046e-02,  7.91368335e-02, -3.50918844e-02,  3.92363891e-02,\n",
       "       -3.41969877e-02,  3.56920250e-02, -5.64492494e-02, -6.44009709e-02,\n",
       "        1.21691180e-02,  2.90606562e-02, -1.06369980e-01,  2.76403744e-02,\n",
       "        5.65041117e-02, -1.24865554e-01,  4.83157597e-02,  1.81270793e-01,\n",
       "        8.46903995e-02, -1.04304075e-01, -1.33834034e-01,  3.90360281e-02,\n",
       "       -8.50194842e-02, -1.20796286e-01,  1.65470615e-02,  1.52857706e-01,\n",
       "       -3.03936135e-02,  4.15153876e-02, -1.19048964e-04,  8.56280774e-02,\n",
       "        2.06898749e-02, -8.48358572e-02,  4.77043949e-02, -6.18456528e-02,\n",
       "        1.48713551e-02,  6.19308278e-03, -2.10227538e-03, -8.75737460e-04,\n",
       "        3.01199108e-02, -5.60123064e-02, -4.82677631e-02, -4.58250642e-02,\n",
       "       -4.54466753e-02,  1.60308167e-01,  2.10681874e-02,  1.48259215e-02,\n",
       "       -9.99357551e-03, -1.21850729e-01,  7.18994588e-02,  1.81362465e-01,\n",
       "        9.74834487e-02, -6.60682172e-02, -3.17557752e-02,  2.14752909e-02,\n",
       "        2.48659737e-02, -7.69653078e-03, -3.60790603e-02, -1.76045612e-01,\n",
       "       -9.01195481e-02, -4.45675552e-02, -3.22375037e-02,  1.51456147e-01,\n",
       "        4.52479348e-03, -6.44790903e-02,  9.83595848e-02, -5.42123690e-02,\n",
       "        6.67052940e-02,  1.49137259e-01, -7.07596242e-02,  6.82921186e-02,\n",
       "       -7.24432319e-02, -5.64433523e-02, -1.56508747e-03,  1.17575474e-01,\n",
       "       -7.67782554e-02, -4.49520871e-02,  3.22210789e-02,  7.77843967e-02,\n",
       "       -1.25821874e-01, -1.04031041e-01, -1.45468116e-02, -6.60203099e-02,\n",
       "        5.06431460e-02, -4.31090631e-02, -8.18066522e-02, -2.94089857e-02,\n",
       "       -7.66730085e-02, -5.40383942e-02, -4.15611491e-02, -6.96064606e-02,\n",
       "        6.00390360e-02,  2.74355449e-02, -5.43332063e-02,  3.41193303e-02,\n",
       "       -1.51391793e-02, -8.80858749e-02,  2.53206156e-02, -6.79469705e-02,\n",
       "        2.89835967e-02,  7.23341182e-02,  7.01572374e-02,  7.55578950e-02,\n",
       "        1.04197763e-01,  2.23693214e-02,  1.97043531e-02,  5.18918363e-03,\n",
       "       -5.93655370e-02,  6.57944754e-02, -2.98801716e-02, -9.17209983e-02,\n",
       "        7.62182102e-02,  2.35508196e-02, -1.17212333e-01,  7.76706487e-02,\n",
       "       -1.02272481e-02, -1.97926462e-02, -2.85305176e-02,  2.07050964e-02,\n",
       "       -7.35407919e-02,  1.09082256e-02,  3.50128263e-02,  9.12880599e-02,\n",
       "       -2.65580062e-02, -9.06934664e-02, -6.91250563e-02, -2.08481979e-02,\n",
       "       -2.78226957e-02, -9.85947344e-03, -1.17466338e-02,  2.56906673e-02,\n",
       "        3.64896692e-02,  7.00767338e-02, -1.85598489e-02, -2.67115869e-02,\n",
       "       -6.20323792e-02,  8.31223652e-02,  1.73281785e-02, -3.70109789e-02,\n",
       "       -1.88155379e-02,  4.03185450e-02,  1.82822198e-02,  4.98681441e-02,\n",
       "       -7.17327967e-02, -1.72304511e-02, -1.32268831e-01,  2.36289222e-02,\n",
       "        8.07676185e-03, -4.60562669e-02, -6.43455237e-02,  1.32849008e-01,\n",
       "        2.55181883e-02,  1.35926846e-02, -2.51562558e-02, -3.05726603e-02,\n",
       "        3.98109341e-03,  4.05988842e-02, -9.01931748e-02,  5.49052469e-02,\n",
       "        2.39772294e-02, -3.08341496e-02,  7.76097327e-02,  6.66899830e-02,\n",
       "        3.05366684e-02, -8.58379342e-03, -8.25822502e-02, -4.06613201e-02,\n",
       "       -2.46736445e-02,  5.63160479e-02, -9.93393064e-02,  3.13059054e-02,\n",
       "       -3.05264033e-02, -4.34955545e-02,  6.45132288e-02,  6.67628348e-02,\n",
       "       -3.72445211e-04, -7.80965164e-02,  6.13507107e-02,  8.71163383e-02,\n",
       "        3.96178439e-02,  4.00187895e-02, -8.14936310e-02, -1.00913323e-01,\n",
       "        2.18204185e-02, -5.92720993e-02,  5.78400865e-02, -1.68065913e-03,\n",
       "        7.27439150e-02,  8.52649510e-02, -8.44391584e-02, -5.94998673e-02,\n",
       "        6.19722381e-02,  6.44092560e-02,  7.41001312e-03,  2.70850919e-02,\n",
       "        7.35963061e-02,  9.37495306e-02,  4.21004482e-02, -1.70924701e-02,\n",
       "        1.86838321e-02, -1.14830621e-02, -1.42760761e-02, -9.89278406e-02,\n",
       "       -3.50094624e-02, -9.36992243e-02,  3.59332860e-02, -4.13556658e-02,\n",
       "        2.48187929e-02,  1.93791445e-02,  9.44333002e-02,  1.60113703e-02,\n",
       "        2.48749927e-02,  6.61861664e-03,  5.90095967e-02, -3.43083381e-03,\n",
       "       -4.14331146e-02,  9.34752449e-02,  5.80638610e-02, -4.35828306e-02,\n",
       "        2.67033111e-02, -1.43075343e-02, -7.20331222e-02, -2.45257001e-02,\n",
       "       -7.68072680e-02, -4.80044074e-02,  4.87994775e-02,  5.38691087e-03,\n",
       "       -3.06598321e-02, -4.94361743e-02, -1.08602896e-01,  1.25310183e-01,\n",
       "       -3.09507325e-02, -3.88646275e-02,  3.72714805e-03, -1.40835345e-02,\n",
       "        2.71569081e-02, -1.48177985e-02,  1.64161250e-02, -1.05133222e-03,\n",
       "        3.30036730e-02,  1.76340416e-02,  3.45256180e-02,  6.71612993e-02,\n",
       "       -7.07672536e-02,  1.47172669e-02,  1.30114947e-02,  2.97671370e-02,\n",
       "       -7.20984042e-02,  2.44899355e-02,  1.22249894e-01, -4.26506847e-02,\n",
       "       -1.49226949e-01, -5.73529210e-03, -8.85015540e-03, -1.22307777e-01,\n",
       "       -9.11402404e-02, -4.20057140e-02,  3.48182768e-02,  1.81332622e-02,\n",
       "       -1.79055389e-02, -4.74617444e-03, -1.77206658e-02,  1.79304965e-02,\n",
       "        5.42725623e-02,  1.38161276e-02, -5.26495054e-02,  3.62893865e-02,\n",
       "        5.72945885e-02,  1.61539651e-02,  6.85043782e-02, -4.36951593e-02,\n",
       "        1.07818544e-01,  1.32112065e-02, -1.67285316e-02,  5.76788038e-02,\n",
       "       -5.26776724e-02, -6.82718158e-02, -2.13049371e-02,  2.20118612e-02,\n",
       "       -1.01159909e-03, -1.08306572e-01,  9.35379118e-02, -1.05399139e-01,\n",
       "        3.27290706e-02, -5.30138314e-02, -1.22166924e-01,  5.70865460e-02,\n",
       "       -1.12843476e-01, -2.94249840e-02, -7.01814368e-02,  2.64930669e-02,\n",
       "        1.07895710e-01,  7.51248971e-02, -4.40700836e-02, -1.50079429e-01,\n",
       "        9.84966457e-02, -1.25171859e-02, -6.82844296e-02,  1.03199251e-01,\n",
       "        4.41587307e-02,  7.63012692e-02, -1.10429972e-01,  3.53527032e-02,\n",
       "       -3.23960744e-02, -2.31338646e-02, -1.31990463e-01,  2.28913967e-02,\n",
       "        5.44872954e-02, -8.13597143e-02, -6.63604364e-02,  8.80797335e-04,\n",
       "        5.04877456e-02, -8.41410160e-02, -4.48031016e-02, -1.15018934e-02,\n",
       "        1.11070991e-01, -1.13136284e-01, -2.28464361e-02, -8.93444791e-02,\n",
       "       -7.05791190e-02, -5.09108156e-02,  6.02888837e-02, -5.78772090e-02,\n",
       "        3.34128775e-02, -6.50900081e-02, -3.76192518e-02, -1.01198807e-01,\n",
       "        9.29347202e-02, -9.51711237e-02, -2.94604022e-02, -8.07541143e-03,\n",
       "        3.46368365e-02, -8.88578668e-02, -1.48578295e-02,  5.30404374e-02,\n",
       "       -4.94483784e-02,  1.59237888e-02, -9.88961011e-03,  1.10484071e-01,\n",
       "        4.59078187e-03, -1.38554245e-01,  5.54581620e-02, -4.19598967e-02,\n",
       "        3.33578978e-03, -4.40256894e-02, -1.57544557e-02, -1.17248446e-02,\n",
       "        7.17120320e-02, -3.61075848e-02, -4.36658189e-02,  1.91929095e-04,\n",
       "        3.55398958e-03,  8.56937617e-02,  8.55837425e-04, -1.00014523e-01,\n",
       "        7.09588826e-02,  4.86419676e-03, -5.15243113e-02,  3.28771025e-02,\n",
       "       -8.15406144e-02, -4.47949879e-02, -3.31077464e-02,  2.11891644e-02,\n",
       "        1.51836658e-02,  2.09958758e-02, -1.96455996e-02, -1.97232068e-02,\n",
       "       -2.86795180e-02,  4.82339691e-03, -6.31886199e-02, -8.71015936e-02,\n",
       "       -4.10054885e-02, -5.68066118e-03,  1.63835026e-02,  9.27386153e-03,\n",
       "       -3.53482515e-02,  6.64584562e-02, -1.45538282e-02,  4.33641300e-02,\n",
       "       -5.00778742e-02,  1.56884238e-01,  3.29526551e-02, -1.31461360e-02,\n",
       "       -4.94772866e-02, -3.40511207e-03,  7.14582577e-02, -1.76480114e-02,\n",
       "        4.68120687e-02, -6.65862188e-02, -7.56588131e-02,  2.96742171e-02,\n",
       "        1.18945763e-01,  6.95004761e-02,  1.27596706e-01,  2.32429877e-02,\n",
       "       -5.07135317e-02,  3.62613574e-02, -1.06155917e-01,  2.24350765e-03,\n",
       "       -8.06043148e-02,  2.01184247e-02, -8.03126767e-02, -4.31591049e-02,\n",
       "        5.59046306e-02, -5.03333881e-02,  3.80274281e-02,  3.55593562e-02,\n",
       "        1.16070285e-02, -2.03852970e-02,  4.90716733e-02, -3.92562225e-02,\n",
       "       -1.45550877e-01,  7.82158747e-02, -1.21871172e-03,  3.58988158e-02,\n",
       "        1.03176348e-01, -9.48686823e-02, -7.22957402e-02, -1.21097356e-01,\n",
       "       -1.28878847e-01, -8.44462588e-02, -3.70897017e-02, -1.12589441e-01,\n",
       "        3.88682331e-03, -1.37929901e-01,  1.25050411e-01,  1.36765232e-02,\n",
       "        7.78744044e-03, -8.87521729e-02, -3.56728360e-02, -3.73690529e-03,\n",
       "        4.78417985e-03, -7.80163612e-03, -7.32536912e-02,  8.13435018e-02,\n",
       "        4.38072421e-02,  9.38888267e-02,  1.06179722e-01,  9.41981226e-02,\n",
       "       -1.94578208e-02,  2.29838155e-02,  2.20404305e-02, -1.03659974e-02,\n",
       "       -6.49530441e-02,  6.29922450e-02, -2.65868139e-02, -5.36281392e-02,\n",
       "       -4.60679047e-02, -1.02078699e-01, -1.91768557e-02, -1.43955611e-02,\n",
       "        7.16816187e-02, -1.18313096e-02,  1.18897501e-02, -6.90919757e-02,\n",
       "       -9.49435905e-02, -4.53436561e-02,  2.88779736e-02, -4.59322613e-03,\n",
       "        7.57808834e-02, -8.69435221e-02,  4.56505828e-02, -3.37538915e-03,\n",
       "       -6.60889447e-02,  1.16356120e-01, -8.10792297e-02,  3.16267572e-02,\n",
       "       -1.60221420e-02,  2.11062860e-02, -4.71011130e-03, -3.43704596e-02,\n",
       "        4.83762845e-02, -1.16935074e-01,  5.28257266e-02, -7.14416057e-02,\n",
       "       -3.88628393e-02,  5.31269647e-02, -9.73544568e-02,  1.75239593e-02,\n",
       "       -1.08311802e-01, -2.67649405e-02, -9.40706488e-03, -1.78310473e-03,\n",
       "       -1.88499745e-02, -6.55923337e-02,  1.13553584e-01, -3.83439511e-02,\n",
       "       -5.87563701e-02,  7.99381435e-02,  6.50610477e-02,  1.23472914e-01,\n",
       "       -1.69298053e-01,  9.46558174e-03,  7.25638028e-03,  2.47799326e-02,\n",
       "        5.86795202e-03, -4.51046750e-02,  9.06900391e-02,  3.31306793e-02,\n",
       "        1.04526579e-02,  6.35541454e-02, -5.29856719e-02, -6.01450447e-03,\n",
       "        1.10995369e-02,  4.52702455e-02, -1.21775372e-02,  1.07390191e-02,\n",
       "       -6.25079274e-02, -1.05336562e-01,  4.87476029e-02, -1.13243863e-01,\n",
       "       -4.52236980e-02,  1.03995830e-01,  5.11547290e-02,  3.42031233e-02,\n",
       "        2.74363570e-02, -8.22477713e-02,  1.43833786e-01,  4.03084233e-03,\n",
       "        2.21665879e-03,  6.84899539e-02, -1.58621464e-02, -5.11428341e-02,\n",
       "        3.69096659e-02, -4.07792293e-02, -3.81156504e-02, -7.13660428e-03,\n",
       "        5.89771569e-02,  2.70079747e-02, -5.62710837e-02,  1.21822366e-02,\n",
       "        8.47966075e-02,  5.87027408e-02,  3.05002611e-02, -3.54218073e-02,\n",
       "        1.24699250e-01,  2.00171433e-02,  5.56273721e-02, -7.40904212e-02,\n",
       "       -9.00166780e-02, -6.03558570e-02, -4.62753624e-02, -3.87851037e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.wv.get_vector('idiot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avgVectors(tokens):\n",
    "  avg_vector = np.mean([word2vec_model.wv.get_vector(token) for token in tokens], axis=0)\n",
    "  return avg_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Priyesh Dave\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning:\n",
      "\n",
      "Mean of empty slice.\n",
      "\n",
      "C:\\Users\\Priyesh Dave\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset['Word2Vec'] = dataset['Tokens'].apply(avgVectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>oh_label</th>\n",
       "      <th>Cleaned Text</th>\n",
       "      <th>Length</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Word2Vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@halalflaws @biebervalue @greenlinerzjm I read...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>read context no change meaning history islamic...</td>\n",
       "      <td>54</td>\n",
       "      <td>[read, context, no, change, meaning, history, ...</td>\n",
       "      <td>[0.114670314, -0.0044393474, 0.06273181, 0.110...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ShreyaBafna3 Now you idiots claim that people...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>idiot claim people tried stop becoming terrori...</td>\n",
       "      <td>86</td>\n",
       "      <td>[idiot, claim, people, tried, stop, becoming, ...</td>\n",
       "      <td>[0.09785918, 0.0046663606, 0.057933852, 0.0922...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @Mooseoftorment Call me sexist, but when I ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rt call sexist go auto place rather talk guy</td>\n",
       "      <td>44</td>\n",
       "      <td>[rt, call, sexist, go, auto, place, rather, ta...</td>\n",
       "      <td>[0.12959903, -0.022027163, 0.08593789, 0.10656...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@g0ssipsquirrelx Wrong, ISIS follows the examp...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>wrong isi follows example mohammed quran exactly</td>\n",
       "      <td>48</td>\n",
       "      <td>[wrong, isi, follows, example, mohammed, quran...</td>\n",
       "      <td>[0.10890402, 0.009343521, 0.04986832, 0.125583...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @TRobinsonNewEra: http://t.co/nkkCbpcHEo Sa...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rt saudi preacher raped tortured five year old...</td>\n",
       "      <td>70</td>\n",
       "      <td>[rt, saudi, preacher, raped, tortured, five, y...</td>\n",
       "      <td>[0.1011598, -0.014321938, 0.049756516, 0.08684...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16580</th>\n",
       "      <td>Feeling so sorry for the girls, they should be...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>feeling sorry girls safe kat andre going home</td>\n",
       "      <td>45</td>\n",
       "      <td>[feeling, sorry, girls, safe, kat, andre, goin...</td>\n",
       "      <td>[0.14885987, -0.031006012, 0.11038468, 0.08918...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16581</th>\n",
       "      <td>#MKR 'pretty good dishes we're happy with' - O...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pretty good dish we re happy with ok well neve...</td>\n",
       "      <td>60</td>\n",
       "      <td>[pretty, good, dish, we, re, happy, with, ok, ...</td>\n",
       "      <td>[0.12320655, -0.032877184, 0.11019462, 0.11849...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16582</th>\n",
       "      <td>RT @colonelkickhead: Deconstructed lemon tart!...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rt deconstructed lemon tart can please go one ...</td>\n",
       "      <td>100</td>\n",
       "      <td>[rt, deconstructed, lemon, tart, can, please, ...</td>\n",
       "      <td>[0.12963274, -0.026281504, 0.108277515, 0.1066...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16583</th>\n",
       "      <td>@versacezaynx @nyazpolitics @greenlinerzjm You...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stupid talk to blocked</td>\n",
       "      <td>22</td>\n",
       "      <td>[stupid, talk, to, blocked]</td>\n",
       "      <td>[0.122984596, -0.0123676695, 0.08183649, 0.119...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16584</th>\n",
       "      <td>And before you protest that you're *not* mad, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>protest not mad there much reason tweeting wom...</td>\n",
       "      <td>57</td>\n",
       "      <td>[protest, not, mad, there, much, reason, tweet...</td>\n",
       "      <td>[0.121641636, -0.015797636, 0.08751015, 0.1072...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16585 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  oh_label  \\\n",
       "0      @halalflaws @biebervalue @greenlinerzjm I read...       0.0   \n",
       "1      @ShreyaBafna3 Now you idiots claim that people...       0.0   \n",
       "2      RT @Mooseoftorment Call me sexist, but when I ...       1.0   \n",
       "3      @g0ssipsquirrelx Wrong, ISIS follows the examp...       1.0   \n",
       "4      RT @TRobinsonNewEra: http://t.co/nkkCbpcHEo Sa...       0.0   \n",
       "...                                                  ...       ...   \n",
       "16580  Feeling so sorry for the girls, they should be...       0.0   \n",
       "16581  #MKR 'pretty good dishes we're happy with' - O...       0.0   \n",
       "16582  RT @colonelkickhead: Deconstructed lemon tart!...       0.0   \n",
       "16583  @versacezaynx @nyazpolitics @greenlinerzjm You...       0.0   \n",
       "16584  And before you protest that you're *not* mad, ...       0.0   \n",
       "\n",
       "                                            Cleaned Text  Length  \\\n",
       "0      read context no change meaning history islamic...      54   \n",
       "1      idiot claim people tried stop becoming terrori...      86   \n",
       "2           rt call sexist go auto place rather talk guy      44   \n",
       "3       wrong isi follows example mohammed quran exactly      48   \n",
       "4      rt saudi preacher raped tortured five year old...      70   \n",
       "...                                                  ...     ...   \n",
       "16580      feeling sorry girls safe kat andre going home      45   \n",
       "16581  pretty good dish we re happy with ok well neve...      60   \n",
       "16582  rt deconstructed lemon tart can please go one ...     100   \n",
       "16583                             stupid talk to blocked      22   \n",
       "16584  protest not mad there much reason tweeting wom...      57   \n",
       "\n",
       "                                                  Tokens  \\\n",
       "0      [read, context, no, change, meaning, history, ...   \n",
       "1      [idiot, claim, people, tried, stop, becoming, ...   \n",
       "2      [rt, call, sexist, go, auto, place, rather, ta...   \n",
       "3      [wrong, isi, follows, example, mohammed, quran...   \n",
       "4      [rt, saudi, preacher, raped, tortured, five, y...   \n",
       "...                                                  ...   \n",
       "16580  [feeling, sorry, girls, safe, kat, andre, goin...   \n",
       "16581  [pretty, good, dish, we, re, happy, with, ok, ...   \n",
       "16582  [rt, deconstructed, lemon, tart, can, please, ...   \n",
       "16583                        [stupid, talk, to, blocked]   \n",
       "16584  [protest, not, mad, there, much, reason, tweet...   \n",
       "\n",
       "                                                Word2Vec  \n",
       "0      [0.114670314, -0.0044393474, 0.06273181, 0.110...  \n",
       "1      [0.09785918, 0.0046663606, 0.057933852, 0.0922...  \n",
       "2      [0.12959903, -0.022027163, 0.08593789, 0.10656...  \n",
       "3      [0.10890402, 0.009343521, 0.04986832, 0.125583...  \n",
       "4      [0.1011598, -0.014321938, 0.049756516, 0.08684...  \n",
       "...                                                  ...  \n",
       "16580  [0.14885987, -0.031006012, 0.11038468, 0.08918...  \n",
       "16581  [0.12320655, -0.032877184, 0.11019462, 0.11849...  \n",
       "16582  [0.12963274, -0.026281504, 0.108277515, 0.1066...  \n",
       "16583  [0.122984596, -0.0123676695, 0.08183649, 0.119...  \n",
       "16584  [0.121641636, -0.015797636, 0.08751015, 0.1072...  \n",
       "\n",
       "[16585 rows x 6 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Priyesh Dave\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning:\n",
      "\n",
      "Mean of empty slice.\n",
      "\n",
      "C:\\Users\\Priyesh Dave\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Store the vectors for train data in following file\n",
    "OUTPUT_FOLDER = '../Datasets/'\n",
    "word2vec_filename = OUTPUT_FOLDER + 'train_review_word2vec.csv'\n",
    "with open(word2vec_filename, 'w+') as word2vec_file:\n",
    "    for index, row in dataset.iterrows():\n",
    "        model_vector = (np.mean([word2vec_model.wv.get_vector(token) for token in row['Tokens']], axis=0)).tolist()\n",
    "        if index == 0:\n",
    "            header = \",\".join(str(ele) for ele in range(vector_size))\n",
    "            word2vec_file.write(header)\n",
    "            word2vec_file.write(\"\\n\")\n",
    "        # Check if the line exists else it is vector of zeros\n",
    "        if type(model_vector) is list:  \n",
    "            line1 = \",\".join( [str(vector_element) for vector_element in model_vector] )\n",
    "        else:\n",
    "            line1 = \",\".join([str(0) for i in range(vector_size)])\n",
    "        word2vec_file.write(line1)\n",
    "        word2vec_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.114670</td>\n",
       "      <td>-0.004439</td>\n",
       "      <td>0.062732</td>\n",
       "      <td>0.110477</td>\n",
       "      <td>0.014469</td>\n",
       "      <td>0.022026</td>\n",
       "      <td>0.064147</td>\n",
       "      <td>0.132225</td>\n",
       "      <td>-0.027668</td>\n",
       "      <td>0.042734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027753</td>\n",
       "      <td>-0.025633</td>\n",
       "      <td>0.107865</td>\n",
       "      <td>-0.000444</td>\n",
       "      <td>0.065698</td>\n",
       "      <td>-0.051440</td>\n",
       "      <td>-0.092473</td>\n",
       "      <td>-0.069011</td>\n",
       "      <td>-0.060967</td>\n",
       "      <td>-0.045501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.097859</td>\n",
       "      <td>0.004666</td>\n",
       "      <td>0.057934</td>\n",
       "      <td>0.092291</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>0.017760</td>\n",
       "      <td>0.051027</td>\n",
       "      <td>0.137488</td>\n",
       "      <td>-0.023821</td>\n",
       "      <td>0.039454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026701</td>\n",
       "      <td>-0.026027</td>\n",
       "      <td>0.091673</td>\n",
       "      <td>0.011694</td>\n",
       "      <td>0.049051</td>\n",
       "      <td>-0.049401</td>\n",
       "      <td>-0.089994</td>\n",
       "      <td>-0.061750</td>\n",
       "      <td>-0.055047</td>\n",
       "      <td>-0.036416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.129599</td>\n",
       "      <td>-0.022027</td>\n",
       "      <td>0.085938</td>\n",
       "      <td>0.106567</td>\n",
       "      <td>-0.004082</td>\n",
       "      <td>-0.017714</td>\n",
       "      <td>0.087459</td>\n",
       "      <td>0.065462</td>\n",
       "      <td>-0.042060</td>\n",
       "      <td>0.026245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057278</td>\n",
       "      <td>-0.003784</td>\n",
       "      <td>0.096469</td>\n",
       "      <td>-0.022406</td>\n",
       "      <td>0.088140</td>\n",
       "      <td>0.016886</td>\n",
       "      <td>-0.074329</td>\n",
       "      <td>-0.048574</td>\n",
       "      <td>-0.044167</td>\n",
       "      <td>-0.026520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.108904</td>\n",
       "      <td>0.009344</td>\n",
       "      <td>0.049868</td>\n",
       "      <td>0.125583</td>\n",
       "      <td>0.020558</td>\n",
       "      <td>0.030475</td>\n",
       "      <td>0.073122</td>\n",
       "      <td>0.194954</td>\n",
       "      <td>-0.024054</td>\n",
       "      <td>0.077876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010921</td>\n",
       "      <td>-0.029047</td>\n",
       "      <td>0.124306</td>\n",
       "      <td>0.009001</td>\n",
       "      <td>0.058454</td>\n",
       "      <td>-0.097294</td>\n",
       "      <td>-0.112901</td>\n",
       "      <td>-0.099543</td>\n",
       "      <td>-0.090177</td>\n",
       "      <td>-0.073051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.101160</td>\n",
       "      <td>-0.014322</td>\n",
       "      <td>0.049757</td>\n",
       "      <td>0.086845</td>\n",
       "      <td>-0.003421</td>\n",
       "      <td>0.010018</td>\n",
       "      <td>0.062691</td>\n",
       "      <td>0.115056</td>\n",
       "      <td>-0.031006</td>\n",
       "      <td>0.032239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043644</td>\n",
       "      <td>-0.015530</td>\n",
       "      <td>0.079904</td>\n",
       "      <td>0.008794</td>\n",
       "      <td>0.046122</td>\n",
       "      <td>-0.057409</td>\n",
       "      <td>-0.074327</td>\n",
       "      <td>-0.062246</td>\n",
       "      <td>-0.044858</td>\n",
       "      <td>-0.030740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16580</th>\n",
       "      <td>0.148860</td>\n",
       "      <td>-0.031006</td>\n",
       "      <td>0.110385</td>\n",
       "      <td>0.089181</td>\n",
       "      <td>-0.026648</td>\n",
       "      <td>0.003521</td>\n",
       "      <td>0.069959</td>\n",
       "      <td>0.053351</td>\n",
       "      <td>-0.071849</td>\n",
       "      <td>-0.008577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076853</td>\n",
       "      <td>0.002499</td>\n",
       "      <td>0.071210</td>\n",
       "      <td>0.011523</td>\n",
       "      <td>0.058034</td>\n",
       "      <td>0.044467</td>\n",
       "      <td>-0.084420</td>\n",
       "      <td>-0.005123</td>\n",
       "      <td>-0.002850</td>\n",
       "      <td>0.027391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16581</th>\n",
       "      <td>0.123207</td>\n",
       "      <td>-0.032877</td>\n",
       "      <td>0.110195</td>\n",
       "      <td>0.118499</td>\n",
       "      <td>0.009525</td>\n",
       "      <td>-0.000166</td>\n",
       "      <td>0.050708</td>\n",
       "      <td>0.039667</td>\n",
       "      <td>-0.034306</td>\n",
       "      <td>-0.017679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045553</td>\n",
       "      <td>-0.010388</td>\n",
       "      <td>0.066958</td>\n",
       "      <td>-0.022430</td>\n",
       "      <td>0.085450</td>\n",
       "      <td>0.024122</td>\n",
       "      <td>-0.083393</td>\n",
       "      <td>-0.030818</td>\n",
       "      <td>-0.013077</td>\n",
       "      <td>0.004500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16582</th>\n",
       "      <td>0.129633</td>\n",
       "      <td>-0.026282</td>\n",
       "      <td>0.108278</td>\n",
       "      <td>0.106690</td>\n",
       "      <td>-0.006892</td>\n",
       "      <td>-0.007346</td>\n",
       "      <td>0.061197</td>\n",
       "      <td>0.055159</td>\n",
       "      <td>-0.034797</td>\n",
       "      <td>-0.009625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063047</td>\n",
       "      <td>-0.015321</td>\n",
       "      <td>0.076144</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.075729</td>\n",
       "      <td>0.042798</td>\n",
       "      <td>-0.075973</td>\n",
       "      <td>-0.016634</td>\n",
       "      <td>-0.016397</td>\n",
       "      <td>0.007155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16583</th>\n",
       "      <td>0.122985</td>\n",
       "      <td>-0.012368</td>\n",
       "      <td>0.081836</td>\n",
       "      <td>0.119814</td>\n",
       "      <td>0.012833</td>\n",
       "      <td>0.001483</td>\n",
       "      <td>0.076888</td>\n",
       "      <td>0.086947</td>\n",
       "      <td>-0.036801</td>\n",
       "      <td>0.031793</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036689</td>\n",
       "      <td>-0.019913</td>\n",
       "      <td>0.107801</td>\n",
       "      <td>-0.020458</td>\n",
       "      <td>0.095796</td>\n",
       "      <td>-0.006040</td>\n",
       "      <td>-0.080639</td>\n",
       "      <td>-0.056895</td>\n",
       "      <td>-0.047633</td>\n",
       "      <td>-0.038048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16584</th>\n",
       "      <td>0.121642</td>\n",
       "      <td>-0.015798</td>\n",
       "      <td>0.087510</td>\n",
       "      <td>0.107286</td>\n",
       "      <td>0.007167</td>\n",
       "      <td>-0.008289</td>\n",
       "      <td>0.076929</td>\n",
       "      <td>0.077290</td>\n",
       "      <td>-0.034070</td>\n",
       "      <td>0.023242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045588</td>\n",
       "      <td>-0.015149</td>\n",
       "      <td>0.097235</td>\n",
       "      <td>-0.023375</td>\n",
       "      <td>0.088729</td>\n",
       "      <td>0.006551</td>\n",
       "      <td>-0.079834</td>\n",
       "      <td>-0.055244</td>\n",
       "      <td>-0.047906</td>\n",
       "      <td>-0.033361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16585 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.114670 -0.004439  0.062732  0.110477  0.014469  0.022026  0.064147   \n",
       "1      0.097859  0.004666  0.057934  0.092291  0.000993  0.017760  0.051027   \n",
       "2      0.129599 -0.022027  0.085938  0.106567 -0.004082 -0.017714  0.087459   \n",
       "3      0.108904  0.009344  0.049868  0.125583  0.020558  0.030475  0.073122   \n",
       "4      0.101160 -0.014322  0.049757  0.086845 -0.003421  0.010018  0.062691   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "16580  0.148860 -0.031006  0.110385  0.089181 -0.026648  0.003521  0.069959   \n",
       "16581  0.123207 -0.032877  0.110195  0.118499  0.009525 -0.000166  0.050708   \n",
       "16582  0.129633 -0.026282  0.108278  0.106690 -0.006892 -0.007346  0.061197   \n",
       "16583  0.122985 -0.012368  0.081836  0.119814  0.012833  0.001483  0.076888   \n",
       "16584  0.121642 -0.015798  0.087510  0.107286  0.007167 -0.008289  0.076929   \n",
       "\n",
       "              7         8         9  ...       990       991       992  \\\n",
       "0      0.132225 -0.027668  0.042734  ...  0.027753 -0.025633  0.107865   \n",
       "1      0.137488 -0.023821  0.039454  ...  0.026701 -0.026027  0.091673   \n",
       "2      0.065462 -0.042060  0.026245  ...  0.057278 -0.003784  0.096469   \n",
       "3      0.194954 -0.024054  0.077876  ...  0.010921 -0.029047  0.124306   \n",
       "4      0.115056 -0.031006  0.032239  ...  0.043644 -0.015530  0.079904   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "16580  0.053351 -0.071849 -0.008577  ...  0.076853  0.002499  0.071210   \n",
       "16581  0.039667 -0.034306 -0.017679  ...  0.045553 -0.010388  0.066958   \n",
       "16582  0.055159 -0.034797 -0.009625  ...  0.063047 -0.015321  0.076144   \n",
       "16583  0.086947 -0.036801  0.031793  ...  0.036689 -0.019913  0.107801   \n",
       "16584  0.077290 -0.034070  0.023242  ...  0.045588 -0.015149  0.097235   \n",
       "\n",
       "            993       994       995       996       997       998       999  \n",
       "0     -0.000444  0.065698 -0.051440 -0.092473 -0.069011 -0.060967 -0.045501  \n",
       "1      0.011694  0.049051 -0.049401 -0.089994 -0.061750 -0.055047 -0.036416  \n",
       "2     -0.022406  0.088140  0.016886 -0.074329 -0.048574 -0.044167 -0.026520  \n",
       "3      0.009001  0.058454 -0.097294 -0.112901 -0.099543 -0.090177 -0.073051  \n",
       "4      0.008794  0.046122 -0.057409 -0.074327 -0.062246 -0.044858 -0.030740  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "16580  0.011523  0.058034  0.044467 -0.084420 -0.005123 -0.002850  0.027391  \n",
       "16581 -0.022430  0.085450  0.024122 -0.083393 -0.030818 -0.013077  0.004500  \n",
       "16582  0.000144  0.075729  0.042798 -0.075973 -0.016634 -0.016397  0.007155  \n",
       "16583 -0.020458  0.095796 -0.006040 -0.080639 -0.056895 -0.047633 -0.038048  \n",
       "16584 -0.023375  0.088729  0.006551 -0.079834 -0.055244 -0.047906 -0.033361  \n",
       "\n",
       "[16585 rows x 1000 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_word2vec = pd.read_csv('../Datasets/train_review_word2vec.csv')\n",
    "dataset_word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16585, 1000), (16585,))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_word2vec.shape, dataset['oh_label'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v, X_test_w2v, y_train_w2v, y_test_w2v = train_test_split(dataset_word2vec, dataset['oh_label'], test_size=.33, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    7505\n",
       "1.0    3606\n",
       "Name: oh_label, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_w2v.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    3737\n",
       "1.0    1737\n",
       "Name: oh_label, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_w2v.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Priyesh Dave\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:05:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Time taken to fit the model with word2vec vectors: 101.69084620475769\n",
      "Training\n",
      "0.998379983799838\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      7505\n",
      "         1.0       1.00      1.00      1.00      3606\n",
      "\n",
      "    accuracy                           1.00     11111\n",
      "   macro avg       1.00      1.00      1.00     11111\n",
      "weighted avg       1.00      1.00      1.00     11111\n",
      "\n",
      "[[7501    4]\n",
      " [  14 3592]]\n",
      "==================================\n",
      "Test\n",
      "Accuracy Score:  0.7813299232736572\n",
      "AUC:  0.7226085933057665\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.88      0.85      3737\n",
      "         1.0       0.69      0.56      0.62      1737\n",
      "\n",
      "    accuracy                           0.78      5474\n",
      "   macro avg       0.75      0.72      0.73      5474\n",
      "weighted avg       0.77      0.78      0.77      5474\n",
      "\n",
      "[[3301  436]\n",
      " [ 761  976]]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "#Import the DecisionTreeeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#Initialize the model\n",
    "MODEL_NAME = 'XGBClassifier'\n",
    "clf_decision_word2vec = XGBClassifier()\n",
    "\n",
    "start_time = time.time()\n",
    "# Fit the model\n",
    "clf_decision_word2vec.fit(X_train_w2v, y_train_w2v)\n",
    "print(\"Time taken to fit the model with word2vec vectors: \" + str(time.time() - start_time))\n",
    "\n",
    "\n",
    "train_pred_w2v = clf_decision_word2vec.predict(X_train_w2v)\n",
    "test_pred_w2v = clf_decision_word2vec.predict(X_test_w2v)\n",
    "\n",
    "\n",
    "print('Training')\n",
    "print(accuracy_score(y_train_w2v, train_pred_w2v))\n",
    "print(classification_report(y_train_w2v, train_pred_w2v))\n",
    "print(confusion_matrix(y_train_w2v, train_pred_w2v))\n",
    "\n",
    "print('==================================')\n",
    "\n",
    "print('Test')\n",
    "score = accuracy_score(y_test_w2v, test_pred_w2v)\n",
    "auc_score = roc_auc_score(y_test_w2v, test_pred_w2v)\n",
    "print('Accuracy Score: ', score)\n",
    "print('AUC: ', auc_score)\n",
    "print(classification_report(y_test_w2v, test_pred_w2v))\n",
    "print(confusion_matrix(y_test_w2v, test_pred_w2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Models/XGBClassifier_78.13_72.26.pkl']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(mnb, '../Models/{}_{}_{}.pkl'.format(MODEL_NAME, round(score*100, 2), round(auc_score*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Embedding, SpatialDropout1D, Dropout, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_w2v =  np.array(y_train_w2v).reshape(-1,1)\n",
    "y_test_w2v =  np.array(y_test_w2v).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11111, 1000), (5474, 1000), (11111, 1), (5474, 1))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_w2v.shape, X_test_w2v.shape, y_train_w2v.shape, y_test_w2v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v_lstm = np.array(X_train_w2v).reshape(-1, 1, vector_size)\n",
    "X_test_w2v_lstm  = np.array(X_test_w2v).reshape(-1, 1, vector_size)\n",
    "y_train_w2v_lstm = y_train_w2v.reshape(-1, 1, 1)\n",
    "y_test_w2v_lstm = y_test_w2v.reshape(-1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11111, 1, 1000), (5474, 1, 1000), (11111, 1, 1), (5474, 1, 1))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_w2v_lstm.shape, X_test_w2v_lstm.shape, y_train_w2v_lstm.shape, y_test_w2v_lstm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'W2V_LSTM'\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Bidirectional(LSTM(256, input_shape=(1, vector_size), kernel_initializer = 'he_uniform', activation = 'relu', return_sequences=True)))\n",
    "\n",
    "model.add(Bidirectional(LSTM(128, kernel_initializer = 'he_uniform', activation='relu')))\n",
    "\n",
    "model.add(Dense(1, kernel_initializer = 'glorot_uniform', activation='sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "44/44 [==============================] - 7s 58ms/step - loss: 0.6030 - accuracy: 0.6929 - val_loss: 0.5380 - val_accuracy: 0.7523\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.5349 - accuracy: 0.7511 - val_loss: 0.5201 - val_accuracy: 0.7585\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.5203 - accuracy: 0.7564 - val_loss: 0.5137 - val_accuracy: 0.7649\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 3s 57ms/step - loss: 0.5122 - accuracy: 0.7629 - val_loss: 0.5210 - val_accuracy: 0.7574\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 2s 54ms/step - loss: 0.5105 - accuracy: 0.7640 - val_loss: 0.5048 - val_accuracy: 0.7643\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 2s 55ms/step - loss: 0.5066 - accuracy: 0.7664 - val_loss: 0.5129 - val_accuracy: 0.7596\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 2s 55ms/step - loss: 0.5053 - accuracy: 0.7667 - val_loss: 0.4965 - val_accuracy: 0.7704\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 2s 55ms/step - loss: 0.4982 - accuracy: 0.7698 - val_loss: 0.4947 - val_accuracy: 0.7689\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 2s 56ms/step - loss: 0.5018 - accuracy: 0.7690 - val_loss: 0.5129 - val_accuracy: 0.7689\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 3s 59ms/step - loss: 0.5020 - accuracy: 0.7700 - val_loss: 0.4959 - val_accuracy: 0.7702\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 3s 57ms/step - loss: 0.4918 - accuracy: 0.7739 - val_loss: 0.4863 - val_accuracy: 0.7724\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 3s 57ms/step - loss: 0.4894 - accuracy: 0.7749 - val_loss: 0.4994 - val_accuracy: 0.7676\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 0.4866 - accuracy: 0.7767 - val_loss: 0.4829 - val_accuracy: 0.7738\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 3s 59ms/step - loss: 0.4845 - accuracy: 0.7804 - val_loss: 0.4900 - val_accuracy: 0.7724\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 0.4825 - accuracy: 0.7783 - val_loss: 0.4788 - val_accuracy: 0.7760\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 0.4810 - accuracy: 0.7800 - val_loss: 0.4781 - val_accuracy: 0.7779\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 3s 62ms/step - loss: 0.4798 - accuracy: 0.7809 - val_loss: 0.4742 - val_accuracy: 0.7773\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 0.4877 - accuracy: 0.7762 - val_loss: 0.4816 - val_accuracy: 0.7740\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 3s 63ms/step - loss: 0.4808 - accuracy: 0.7801 - val_loss: 0.4808 - val_accuracy: 0.7775\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 0.4763 - accuracy: 0.7836 - val_loss: 0.4772 - val_accuracy: 0.7810\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 3s 59ms/step - loss: 0.4777 - accuracy: 0.7821 - val_loss: 0.4770 - val_accuracy: 0.7791\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 3s 59ms/step - loss: 0.4757 - accuracy: 0.7826 - val_loss: 0.4743 - val_accuracy: 0.7790\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 0.4741 - accuracy: 0.7849 - val_loss: 0.4723 - val_accuracy: 0.7808\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 0.4743 - accuracy: 0.7831 - val_loss: 0.4709 - val_accuracy: 0.7810\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 3s 59ms/step - loss: 0.4730 - accuracy: 0.7839 - val_loss: 0.4805 - val_accuracy: 0.7749\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 3s 59ms/step - loss: 0.4760 - accuracy: 0.7817 - val_loss: 0.4842 - val_accuracy: 0.7762\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 3s 59ms/step - loss: 0.4734 - accuracy: 0.7863 - val_loss: 0.4711 - val_accuracy: 0.7826\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 3s 59ms/step - loss: 0.4754 - accuracy: 0.7831 - val_loss: 0.4704 - val_accuracy: 0.7844\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 3s 59ms/step - loss: 0.4720 - accuracy: 0.7844 - val_loss: 0.4717 - val_accuracy: 0.7830\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 3s 58ms/step - loss: 0.4723 - accuracy: 0.7859 - val_loss: 0.4765 - val_accuracy: 0.7810\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 3s 58ms/step - loss: 0.4704 - accuracy: 0.7865 - val_loss: 0.4701 - val_accuracy: 0.7850\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 0.4710 - accuracy: 0.7857 - val_loss: 0.4726 - val_accuracy: 0.7846\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 0.4690 - accuracy: 0.7876 - val_loss: 0.4714 - val_accuracy: 0.7837\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 3s 59ms/step - loss: 0.4704 - accuracy: 0.7871 - val_loss: 0.4749 - val_accuracy: 0.7808\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 0.4711 - accuracy: 0.7853 - val_loss: 0.4704 - val_accuracy: 0.7852\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 0.4669 - accuracy: 0.7878 - val_loss: 0.4705 - val_accuracy: 0.7861\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 0.4674 - accuracy: 0.7884 - val_loss: 0.4702 - val_accuracy: 0.7855\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 0.4655 - accuracy: 0.7899 - val_loss: 0.4697 - val_accuracy: 0.7868\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 3s 68ms/step - loss: 0.4659 - accuracy: 0.7894 - val_loss: 0.4675 - val_accuracy: 0.7899\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 3s 76ms/step - loss: 0.4637 - accuracy: 0.7885 - val_loss: 0.4663 - val_accuracy: 0.7879\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 3s 71ms/step - loss: 0.4637 - accuracy: 0.7903 - val_loss: 0.4682 - val_accuracy: 0.7853\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 3s 63ms/step - loss: 0.4660 - accuracy: 0.7859 - val_loss: 0.4690 - val_accuracy: 0.7866\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 0.4680 - accuracy: 0.7889 - val_loss: 0.4730 - val_accuracy: 0.7843\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 3s 63ms/step - loss: 0.4632 - accuracy: 0.7909 - val_loss: 0.4686 - val_accuracy: 0.7874\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 3s 67ms/step - loss: 0.4608 - accuracy: 0.7917 - val_loss: 0.4668 - val_accuracy: 0.7872\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 3s 64ms/step - loss: 0.4650 - accuracy: 0.7888 - val_loss: 0.4693 - val_accuracy: 0.7853\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.4644 - accuracy: 0.7902 - val_loss: 0.4642 - val_accuracy: 0.7901\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 3s 58ms/step - loss: 0.4608 - accuracy: 0.7915 - val_loss: 0.4647 - val_accuracy: 0.7885\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 2s 56ms/step - loss: 0.4590 - accuracy: 0.7937 - val_loss: 0.4647 - val_accuracy: 0.7892\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 2s 56ms/step - loss: 0.4575 - accuracy: 0.7934 - val_loss: 0.4664 - val_accuracy: 0.7857\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 2s 54ms/step - loss: 0.4582 - accuracy: 0.7923 - val_loss: 0.4675 - val_accuracy: 0.7886\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 3s 63ms/step - loss: 0.4629 - accuracy: 0.7891 - val_loss: 0.4642 - val_accuracy: 0.7908\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 2s 55ms/step - loss: 0.4564 - accuracy: 0.7948 - val_loss: 0.4667 - val_accuracy: 0.7830\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 2s 56ms/step - loss: 0.4579 - accuracy: 0.7934 - val_loss: 0.4667 - val_accuracy: 0.7879\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 2s 56ms/step - loss: 0.4555 - accuracy: 0.7938 - val_loss: 0.4663 - val_accuracy: 0.7906\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 3s 62ms/step - loss: 0.4557 - accuracy: 0.7930 - val_loss: 0.4652 - val_accuracy: 0.7892\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 3s 65ms/step - loss: 0.4590 - accuracy: 0.7880 - val_loss: 0.4729 - val_accuracy: 0.7826\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 3s 64ms/step - loss: 0.4570 - accuracy: 0.7916 - val_loss: 0.4704 - val_accuracy: 0.7890\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 3s 64ms/step - loss: 0.4564 - accuracy: 0.7941 - val_loss: 0.4690 - val_accuracy: 0.7868\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 3s 57ms/step - loss: 0.4570 - accuracy: 0.7912 - val_loss: 0.4714 - val_accuracy: 0.7848\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 2s 53ms/step - loss: 0.4547 - accuracy: 0.7932 - val_loss: 0.4644 - val_accuracy: 0.7905\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 2s 53ms/step - loss: 0.4554 - accuracy: 0.7937 - val_loss: 0.4628 - val_accuracy: 0.7896\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 2s 53ms/step - loss: 0.4547 - accuracy: 0.7969 - val_loss: 0.4639 - val_accuracy: 0.7899\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 2s 53ms/step - loss: 0.4569 - accuracy: 0.7934 - val_loss: 0.4661 - val_accuracy: 0.7910\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 2s 52ms/step - loss: 0.4550 - accuracy: 0.7962 - val_loss: 0.4640 - val_accuracy: 0.7923\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 2s 52ms/step - loss: 0.4536 - accuracy: 0.7943 - val_loss: 0.4655 - val_accuracy: 0.7901\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 3s 67ms/step - loss: 0.4525 - accuracy: 0.7952 - val_loss: 0.4645 - val_accuracy: 0.7901\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 3s 64ms/step - loss: 0.4526 - accuracy: 0.7933 - val_loss: 0.4625 - val_accuracy: 0.7932\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 3s 63ms/step - loss: 0.4536 - accuracy: 0.7970 - val_loss: 0.4703 - val_accuracy: 0.7914\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 3s 57ms/step - loss: 0.4545 - accuracy: 0.7938 - val_loss: 0.4642 - val_accuracy: 0.7879\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 3s 64ms/step - loss: 0.4516 - accuracy: 0.7944 - val_loss: 0.4679 - val_accuracy: 0.7859\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 3s 57ms/step - loss: 0.4514 - accuracy: 0.7975 - val_loss: 0.4745 - val_accuracy: 0.7843\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 0.4521 - accuracy: 0.7961 - val_loss: 0.4629 - val_accuracy: 0.7925\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 3s 65ms/step - loss: 0.4492 - accuracy: 0.7989 - val_loss: 0.4654 - val_accuracy: 0.7936\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 3s 69ms/step - loss: 0.4515 - accuracy: 0.7972 - val_loss: 0.4654 - val_accuracy: 0.7910\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 3s 63ms/step - loss: 0.4489 - accuracy: 0.7972 - val_loss: 0.4634 - val_accuracy: 0.7908\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 3s 65ms/step - loss: 0.4498 - accuracy: 0.7988 - val_loss: 0.4660 - val_accuracy: 0.7947\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 3s 62ms/step - loss: 0.4483 - accuracy: 0.7990 - val_loss: 0.4648 - val_accuracy: 0.7883\n",
      "Epoch 79/100\n",
      "44/44 [==============================] - 3s 68ms/step - loss: 0.4472 - accuracy: 0.7989 - val_loss: 0.4693 - val_accuracy: 0.7879\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 3s 59ms/step - loss: 0.4496 - accuracy: 0.7993 - val_loss: 0.4661 - val_accuracy: 0.7879\n",
      "Epoch 81/100\n",
      "44/44 [==============================] - 2s 56ms/step - loss: 0.4500 - accuracy: 0.7978 - val_loss: 0.4683 - val_accuracy: 0.7863\n",
      "Epoch 82/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 0.4483 - accuracy: 0.7950 - val_loss: 0.4706 - val_accuracy: 0.7848\n",
      "Epoch 83/100\n",
      "44/44 [==============================] - 2s 54ms/step - loss: 0.4480 - accuracy: 0.7993 - val_loss: 0.4634 - val_accuracy: 0.7912\n",
      "Epoch 84/100\n",
      "44/44 [==============================] - 2s 56ms/step - loss: 0.4489 - accuracy: 0.7962 - val_loss: 0.4657 - val_accuracy: 0.7923\n",
      "Epoch 85/100\n",
      "44/44 [==============================] - 3s 58ms/step - loss: 0.4474 - accuracy: 0.8006 - val_loss: 0.4648 - val_accuracy: 0.7934\n",
      "Epoch 86/100\n",
      "44/44 [==============================] - 2s 55ms/step - loss: 0.4471 - accuracy: 0.7976 - val_loss: 0.4705 - val_accuracy: 0.7861\n",
      "Epoch 87/100\n",
      "44/44 [==============================] - 2s 52ms/step - loss: 0.4456 - accuracy: 0.7988 - val_loss: 0.4794 - val_accuracy: 0.7828\n",
      "Epoch 88/100\n",
      "44/44 [==============================] - 2s 52ms/step - loss: 0.4507 - accuracy: 0.7967 - val_loss: 0.4644 - val_accuracy: 0.7883\n",
      "Epoch 89/100\n",
      "44/44 [==============================] - 2s 52ms/step - loss: 0.4460 - accuracy: 0.7983 - val_loss: 0.4674 - val_accuracy: 0.7892\n",
      "Epoch 90/100\n",
      "44/44 [==============================] - 2s 52ms/step - loss: 0.4439 - accuracy: 0.8006 - val_loss: 0.4641 - val_accuracy: 0.7905\n",
      "Epoch 91/100\n",
      "44/44 [==============================] - 2s 54ms/step - loss: 0.4405 - accuracy: 0.8022 - val_loss: 0.4661 - val_accuracy: 0.7903\n",
      "Epoch 92/100\n",
      "44/44 [==============================] - 2s 52ms/step - loss: 0.4423 - accuracy: 0.8009 - val_loss: 0.4722 - val_accuracy: 0.7864\n",
      "Epoch 93/100\n",
      "44/44 [==============================] - 2s 52ms/step - loss: 0.4426 - accuracy: 0.7986 - val_loss: 0.4673 - val_accuracy: 0.7910\n",
      "Epoch 94/100\n",
      "44/44 [==============================] - 2s 53ms/step - loss: 0.4448 - accuracy: 0.7978 - val_loss: 0.4654 - val_accuracy: 0.7894\n",
      "Epoch 95/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.4409 - accuracy: 0.8024 - val_loss: 0.4682 - val_accuracy: 0.7885\n",
      "Epoch 96/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.4423 - accuracy: 0.8009 - val_loss: 0.4670 - val_accuracy: 0.7923\n",
      "Epoch 97/100\n",
      "44/44 [==============================] - 2s 53ms/step - loss: 0.4411 - accuracy: 0.8050 - val_loss: 0.4682 - val_accuracy: 0.7883\n",
      "Epoch 98/100\n",
      "44/44 [==============================] - 2s 53ms/step - loss: 0.4432 - accuracy: 0.8021 - val_loss: 0.4741 - val_accuracy: 0.7868\n",
      "Epoch 99/100\n",
      "44/44 [==============================] - 2s 52ms/step - loss: 0.4401 - accuracy: 0.8011 - val_loss: 0.4643 - val_accuracy: 0.7888\n",
      "Epoch 100/100\n",
      "44/44 [==============================] - 2s 52ms/step - loss: 0.4405 - accuracy: 0.8009 - val_loss: 0.4726 - val_accuracy: 0.7886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c14ccc3880>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_w2v_lstm, y_train_w2v_lstm, validation_data=(X_test_w2v_lstm, y_test_w2v_lstm), epochs=100, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 1, 512)           2574336   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 256)              656384    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,230,977\n",
      "Trainable params: 3,230,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "0.8063180631806318\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.89      0.86      7505\n",
      "         1.0       0.74      0.62      0.68      3606\n",
      "\n",
      "    accuracy                           0.81     11111\n",
      "   macro avg       0.79      0.76      0.77     11111\n",
      "weighted avg       0.80      0.81      0.80     11111\n",
      "\n",
      "[[6708  797]\n",
      " [1355 2251]]\n",
      "==================================\n",
      "Test\n",
      "Accuracy Score:  0.788637194008038\n",
      "AUC:  0.736895696291377\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.88      0.85      3737\n",
      "         1.0       0.69      0.60      0.64      1737\n",
      "\n",
      "    accuracy                           0.79      5474\n",
      "   macro avg       0.76      0.74      0.75      5474\n",
      "weighted avg       0.78      0.79      0.78      5474\n",
      "\n",
      "[[3283  454]\n",
      " [ 703 1034]]\n"
     ]
    }
   ],
   "source": [
    "train_pred_w2v = model.predict(X_train_w2v_lstm)\n",
    "train_pred_w2v = (train_pred_w2v > 0.5)\n",
    "train_pred_w2v\n",
    "\n",
    "test_pred_w2v = model.predict(X_test_w2v_lstm)\n",
    "test_pred_w2v = (test_pred_w2v > 0.5)\n",
    "test_pred_w2v\n",
    "\n",
    "print('Training')\n",
    "print(accuracy_score(y_train_w2v, train_pred_w2v))\n",
    "print(classification_report(y_train_w2v, train_pred_w2v))\n",
    "print(confusion_matrix(y_train_w2v, train_pred_w2v))\n",
    "\n",
    "print('==================================')\n",
    "\n",
    "print('Test')\n",
    "score = accuracy_score(y_test_w2v, test_pred_w2v)\n",
    "auc_score = roc_auc_score(y_test_w2v, test_pred_w2v)\n",
    "print('Accuracy Score: ', score)\n",
    "print('AUC: ', auc_score)\n",
    "print(classification_report(y_test_w2v, test_pred_w2v))\n",
    "print(confusion_matrix(y_test_w2v, test_pred_w2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://e9af2b1e-4907-49e9-980e-17bad839c1ed/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001BFE45F8E50> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001BFF92F9820> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001BFF9323280> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001BFF9323BB0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../Models/W2V_LSTM_78.86_73.69.pkl']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, '../Models/{}_{}_{}.pkl'.format(MODEL_NAME, round(score*100, 2), round(auc_score*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>oh_label</th>\n",
       "      <th>Cleaned Text</th>\n",
       "      <th>Length</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Word2Vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@halalflaws @biebervalue @greenlinerzjm I read...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>read context no change meaning history islamic...</td>\n",
       "      <td>54</td>\n",
       "      <td>[read, context, no, change, meaning, history, ...</td>\n",
       "      <td>[0.114670314, -0.0044393474, 0.06273181, 0.110...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ShreyaBafna3 Now you idiots claim that people...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>idiot claim people tried stop becoming terrori...</td>\n",
       "      <td>86</td>\n",
       "      <td>[idiot, claim, people, tried, stop, becoming, ...</td>\n",
       "      <td>[0.09785918, 0.0046663606, 0.057933852, 0.0922...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @Mooseoftorment Call me sexist, but when I ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rt call sexist go auto place rather talk guy</td>\n",
       "      <td>44</td>\n",
       "      <td>[rt, call, sexist, go, auto, place, rather, ta...</td>\n",
       "      <td>[0.12959903, -0.022027163, 0.08593789, 0.10656...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@g0ssipsquirrelx Wrong, ISIS follows the examp...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>wrong isi follows example mohammed quran exactly</td>\n",
       "      <td>48</td>\n",
       "      <td>[wrong, isi, follows, example, mohammed, quran...</td>\n",
       "      <td>[0.10890402, 0.009343521, 0.04986832, 0.125583...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @TRobinsonNewEra: http://t.co/nkkCbpcHEo Sa...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rt saudi preacher raped tortured five year old...</td>\n",
       "      <td>70</td>\n",
       "      <td>[rt, saudi, preacher, raped, tortured, five, y...</td>\n",
       "      <td>[0.1011598, -0.014321938, 0.049756516, 0.08684...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  oh_label  \\\n",
       "0  @halalflaws @biebervalue @greenlinerzjm I read...       0.0   \n",
       "1  @ShreyaBafna3 Now you idiots claim that people...       0.0   \n",
       "2  RT @Mooseoftorment Call me sexist, but when I ...       1.0   \n",
       "3  @g0ssipsquirrelx Wrong, ISIS follows the examp...       1.0   \n",
       "4  RT @TRobinsonNewEra: http://t.co/nkkCbpcHEo Sa...       0.0   \n",
       "\n",
       "                                        Cleaned Text  Length  \\\n",
       "0  read context no change meaning history islamic...      54   \n",
       "1  idiot claim people tried stop becoming terrori...      86   \n",
       "2       rt call sexist go auto place rather talk guy      44   \n",
       "3   wrong isi follows example mohammed quran exactly      48   \n",
       "4  rt saudi preacher raped tortured five year old...      70   \n",
       "\n",
       "                                              Tokens  \\\n",
       "0  [read, context, no, change, meaning, history, ...   \n",
       "1  [idiot, claim, people, tried, stop, becoming, ...   \n",
       "2  [rt, call, sexist, go, auto, place, rather, ta...   \n",
       "3  [wrong, isi, follows, example, mohammed, quran...   \n",
       "4  [rt, saudi, preacher, raped, tortured, five, y...   \n",
       "\n",
       "                                            Word2Vec  \n",
       "0  [0.114670314, -0.0044393474, 0.06273181, 0.110...  \n",
       "1  [0.09785918, 0.0046663606, 0.057933852, 0.0922...  \n",
       "2  [0.12959903, -0.022027163, 0.08593789, 0.10656...  \n",
       "3  [0.10890402, 0.009343521, 0.04986832, 0.125583...  \n",
       "4  [0.1011598, -0.014321938, 0.049756516, 0.08684...  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting what is the highest count of words in any sentence\n",
    "max_count = max([len(arr) for arr in dataset['Tokens']])\n",
    "max_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_size = 16000\n",
    "sent_length = 25\n",
    "embedding_vector_features = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot representation of words\n",
    "onehot_repr=[one_hot(sentence,voc_size) for sentence in dataset['Cleaned Text']] \n",
    "#onehot_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "for encodingList, tokensList in zip(onehot_repr, dataset['Tokens']):\n",
    "  for index, word in zip(encodingList, tokensList):\n",
    "    one_hot_dict[word] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Encoded Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>read</td>\n",
       "      <td>11009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>context</td>\n",
       "      <td>10460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no</td>\n",
       "      <td>11347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>change</td>\n",
       "      <td>7523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>meaning</td>\n",
       "      <td>5340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Word  Encoded Value\n",
       "0     read          11009\n",
       "1  context          10460\n",
       "2       no          11347\n",
       "3   change           7523\n",
       "4  meaning           5340"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_df = pd.DataFrame(one_hot_dict.items(), columns=['Word', 'Encoded Value'])\n",
    "one_hot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_df.to_csv('../Datasets/One Hot Encoded Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     0     0 ...  1914  2393  8811]\n",
      " [    0     0     0 ... 10452 10184 15077]\n",
      " [    0     0     0 ...  1076   376 11527]\n",
      " ...\n",
      " [    0     0     0 ... 10765 10622  2487]\n",
      " [    0     0     0 ...   376 11649  9838]\n",
      " [    0     0     0 ... 15029  7576  2247]]\n"
     ]
    }
   ],
   "source": [
    "# Embedding the sentences\n",
    "embedded_docs = pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
    "print(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16585, 25)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_docs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "#     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "#     possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "#     predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "#     precision = true_positives / (predicted_positives + K.epsilon())\n",
    "#     recall = true_positives / (possible_positives + K.epsilon())\n",
    "#     f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "#     return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Bidirectional(LSTM(200, kernel_initializer  = 'he_uniform', return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(100, kernel_initializer  = 'he_uniform')))\n",
    "\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_callbacks = [\n",
    "    EarlyStopping(patience=2),\n",
    "    ModelCheckpoint(filepath='../LSTM/Callbacks 3/model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    TensorBoard(log_dir='../LSTM/logs'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_LSTM = np.array(embedded_docs)\n",
    "y_LSTM = np.array(dataset['oh_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16585, 25), (16585,))"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_LSTM.shape, y_LSTM.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lstm, X_test_lstm, y_train_lstm, y_test_lstm = train_test_split(X_LSTM, y_LSTM, test_size=.33, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "44/44 [==============================] - 47s 893ms/step - loss: 0.5472 - accuracy: 0.7242 - val_loss: 0.4243 - val_accuracy: 0.8133\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 42s 962ms/step - loss: 0.3386 - accuracy: 0.8588 - val_loss: 0.4188 - val_accuracy: 0.8107\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 37s 840ms/step - loss: 0.2382 - accuracy: 0.9064 - val_loss: 0.4713 - val_accuracy: 0.8034\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 38s 863ms/step - loss: 0.1638 - accuracy: 0.9410 - val_loss: 0.6086 - val_accuracy: 0.7899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c14f6c0fa0>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_lstm, y_train_lstm, validation_data=(X_test_lstm, y_test_lstm), epochs=100, batch_size=256, callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking best model for the callbacks\n",
    "model = tensorflow.keras.models.load_model('../LSTM/Callbacks 3/model.02-0.42.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       ...,\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred_lstm = model.predict(X_train_lstm)\n",
    "train_pred_lstm = (train_pred_lstm > 0.5)\n",
    "train_pred_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       ...,\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_lstm = model.predict(X_test_lstm)\n",
    "test_pred_lstm = (test_pred_lstm > 0.5)\n",
    "test_pred_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9148591485914859"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train_lstm, train_pred_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8107416879795396"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_lstm, test_pred_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>oh_label</th>\n",
       "      <th>Cleaned Text</th>\n",
       "      <th>Length</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Word2Vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@halalflaws @biebervalue @greenlinerzjm I read...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>read context no change meaning history islamic...</td>\n",
       "      <td>54</td>\n",
       "      <td>[read, context, no, change, meaning, history, ...</td>\n",
       "      <td>[0.114670314, -0.0044393474, 0.06273181, 0.110...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ShreyaBafna3 Now you idiots claim that people...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>idiot claim people tried stop becoming terrori...</td>\n",
       "      <td>86</td>\n",
       "      <td>[idiot, claim, people, tried, stop, becoming, ...</td>\n",
       "      <td>[0.09785918, 0.0046663606, 0.057933852, 0.0922...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @Mooseoftorment Call me sexist, but when I ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rt call sexist go auto place rather talk guy</td>\n",
       "      <td>44</td>\n",
       "      <td>[rt, call, sexist, go, auto, place, rather, ta...</td>\n",
       "      <td>[0.12959903, -0.022027163, 0.08593789, 0.10656...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@g0ssipsquirrelx Wrong, ISIS follows the examp...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>wrong isi follows example mohammed quran exactly</td>\n",
       "      <td>48</td>\n",
       "      <td>[wrong, isi, follows, example, mohammed, quran...</td>\n",
       "      <td>[0.10890402, 0.009343521, 0.04986832, 0.125583...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @TRobinsonNewEra: http://t.co/nkkCbpcHEo Sa...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rt saudi preacher raped tortured five year old...</td>\n",
       "      <td>70</td>\n",
       "      <td>[rt, saudi, preacher, raped, tortured, five, y...</td>\n",
       "      <td>[0.1011598, -0.014321938, 0.049756516, 0.08684...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  oh_label  \\\n",
       "0  @halalflaws @biebervalue @greenlinerzjm I read...       0.0   \n",
       "1  @ShreyaBafna3 Now you idiots claim that people...       0.0   \n",
       "2  RT @Mooseoftorment Call me sexist, but when I ...       1.0   \n",
       "3  @g0ssipsquirrelx Wrong, ISIS follows the examp...       1.0   \n",
       "4  RT @TRobinsonNewEra: http://t.co/nkkCbpcHEo Sa...       0.0   \n",
       "\n",
       "                                        Cleaned Text  Length  \\\n",
       "0  read context no change meaning history islamic...      54   \n",
       "1  idiot claim people tried stop becoming terrori...      86   \n",
       "2       rt call sexist go auto place rather talk guy      44   \n",
       "3   wrong isi follows example mohammed quran exactly      48   \n",
       "4  rt saudi preacher raped tortured five year old...      70   \n",
       "\n",
       "                                              Tokens  \\\n",
       "0  [read, context, no, change, meaning, history, ...   \n",
       "1  [idiot, claim, people, tried, stop, becoming, ...   \n",
       "2  [rt, call, sexist, go, auto, place, rather, ta...   \n",
       "3  [wrong, isi, follows, example, mohammed, quran...   \n",
       "4  [rt, saudi, preacher, raped, tortured, five, y...   \n",
       "\n",
       "                                            Word2Vec  \n",
       "0  [0.114670314, -0.0044393474, 0.06273181, 0.110...  \n",
       "1  [0.09785918, 0.0046663606, 0.057933852, 0.0922...  \n",
       "2  [0.12959903, -0.022027163, 0.08593789, 0.10656...  \n",
       "3  [0.10890402, 0.009343521, 0.04986832, 0.125583...  \n",
       "4  [0.1011598, -0.014321938, 0.049756516, 0.08684...  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet:  #MKR \"If I could score them a zero then I would because I'm a super slut\". #cheats #irritate #ratingsbonanza #uglycow http://t.co/vJv8DCRqcQ\n",
      "True Value:  Toxic\n",
      "Predicted Value:  Toxic\n"
     ]
    }
   ],
   "source": [
    "randomNumber = np.random.randint(0, X_LSTM.shape[0]+1)\n",
    "\n",
    "data = X_LSTM[randomNumber].reshape(1,-1)\n",
    "\n",
    "true_value = y_LSTM[randomNumber]\n",
    "\n",
    "pred_value = model.predict(data)\n",
    "pred_value = (pred_value > 0.5)\n",
    "\n",
    "tweet = dataset['Text'][randomNumber]\n",
    "\n",
    "mapper = {0 : 'Not Toxic', 1 : 'Toxic'}\n",
    "\n",
    "print('Tweet: ', tweet)\n",
    "print('True Value: ', mapper[int(true_value)])\n",
    "print('Predicted Value: ', mapper[int(pred_value[0][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Encoded Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>read</th>\n",
       "      <td>11009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context</th>\n",
       "      <td>10460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>11347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>change</th>\n",
       "      <td>7523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meaning</th>\n",
       "      <td>5340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>icantbreathe</th>\n",
       "      <td>3671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angle</th>\n",
       "      <td>8339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labours</th>\n",
       "      <td>11757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pacify</th>\n",
       "      <td>15553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>having</th>\n",
       "      <td>9869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15050 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Encoded Value\n",
       "Word                       \n",
       "read                  11009\n",
       "context               10460\n",
       "no                    11347\n",
       "change                 7523\n",
       "meaning                5340\n",
       "...                     ...\n",
       "icantbreathe           3671\n",
       "angle                  8339\n",
       "labours               11757\n",
       "pacify                15553\n",
       "having                 9869\n",
       "\n",
       "[15050 rows x 1 columns]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_df.set_index('Word', inplace=True)\n",
    "one_hot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_embedding(sentence):\n",
    "  sentence = sentence.split(' ')\n",
    "  # One hot representation of words\n",
    "  onehot_repr = [one_hot_df.loc[word][0] for word in sentence]\n",
    "  # Embedding the sentences\n",
    "  embedded_docs = pad_sequences([onehot_repr],padding='pre',maxlen=sent_length)\n",
    "  return embedded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(sentence):\n",
    "  print('Sentence Length: ', len(sentence))\n",
    "  sentence = cleanData(sentence)\n",
    "  print('Sentence Length: ', len(sentence))\n",
    "  print(sentence)\n",
    "  data_lstm = word_embedding(sentence)\n",
    "  print('Embeded Docs: ', data_lstm)\n",
    "  predicted_probability = model.predict(data_lstm)[0][0]\n",
    "  print('Predicted Probability: ', predicted_probability)\n",
    "  prediction = (predicted_probability >= 0.5)\n",
    "\n",
    "  return (mapper[int(prediction)], predicted_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Length:  8\n",
      "Sentence Length:  8\n",
      "feminist\n",
      "Embeded Docs:  [[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "  14978]]\n",
      "Predicted Probability:  0.40037426\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Not Toxic', 0.40037426)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predictions('feminist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@halalflaws @biebervalue @greenlinerzjm I read them in context.No change in meaning. The history of Islamic slavery. https://t.co/xWJzpSodGj'"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "           0,     0,     0,     0,     0,     0,     0,     0, 11009,\n",
    "       10460, 11347,  7523,  5340,  1914,  2393,  8811])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e147b052be5536a019399d7281fa07f9aa68d0dfdf21ead313763d9c98e78705"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
